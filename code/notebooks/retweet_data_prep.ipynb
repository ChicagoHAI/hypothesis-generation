{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/rosa/file_transfer/retweetedmore/data.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15419652       jonmchu    618097  259369375012888576  259443881366679553  \\\n",
      "0  19426551           nfl   5378940  402659656775901185  402816439913959424   \n",
      "1  27260086  justinbieber  47355342  394663265873436672  394663384010194944   \n",
      "2  27260086  justinbieber  47355347  379997011946508288  380003415394635776   \n",
      "3  14631115   AmazingPhil    645151  403996865051381760  404034318835539968   \n",
      "4  14193620  DALLASAUSTIN     84470  331259414352912384  331387374732988417   \n",
      "\n",
      "    8070    234   4504    119  Fri Oct 19 19:04:12 +0000 2012  ...  \\\n",
      "0   8265    779   4508    483  Tue Nov 19 04:48:37 +0000 2013  ...   \n",
      "1  60871  53387  40193  35237  Mon Oct 28 03:13:49 +0000 2013  ...   \n",
      "2  81108  73940  51524  48604  Tue Sep 17 15:55:22 +0000 2013  ...   \n",
      "3   7216    579   4810   1487  Fri Nov 22 21:22:13 +0000 2013  ...   \n",
      "4   5648      0     25      2  Mon May 06 04:09:33 +0000 2013  ...   \n",
      "\n",
      "  Ok# fine# :)# here# it# is# Behind# Scenes# for# Beauty^ and# a^ Beat^ with# choreographer# @NickDeMoura# and# @justinbieber# enjoy# !^ http://t.co/dTiIE45C^  \\\n",
      "0  Cam^ Newton# is# a# bad# ,# bad# man# .^ #That...                                                                                                              \n",
      "1  It's# here^ .# One# of# the# most# important# ...                                                                                                              \n",
      "2  It's# here# @MAEJORALI# @therealjuicyj# .# Now...                                                                                                              \n",
      "3  PHIL# IS# NOT# ON# FIRE# 5^ IS# HERE# !!!!# ht...                                                                                                              \n",
      "4  http://t.co/cwQ9Dxw2mG^ checkout# Orlando# jon...                                                                                                              \n",
      "\n",
      "   EXCLUSIVE# behind# the# scenes# video# of# @JustinBieber# '# s# world# record# breaking# video# Beauty^ &# a^ Beat^ !^ Check# it# out# .# http://t.co/dTiIE45C^  \\\n",
      "0  ICYMI# :# Cam^ Newton's# AMAZING# 14yd# scramb...                                                                                                                 \n",
      "1  #MusicMondays# is# here^ .^ #Recovery^ -# http...                                                                                                                 \n",
      "2              #lollydance^ https://t.co/coBazWRxiX^                                                                                                                 \n",
      "3  Just# had# a# chinese# feast# and# now# I'm# r...                                                                                                                 \n",
      "4  http://t.co/cwQ9Dxw2mG^ this# shit# is# crazy#...                                                                                                                 \n",
      "\n",
      "   ok# fine# :)# here# it# is# behind^ scenes^ for# beauty^ and# a^ beat^ with# choreographer# @nickdemoura# and# @justinbieber# enjoy# !^ http://t.co/dtiie45c^  \\\n",
      "0  cam^ newton# is# a# bad# ,# bad# man# .^ #that...                                                                                                               \n",
      "1  it's# here^ .# one# of# the# most# important# ...                                                                                                               \n",
      "2  it's# here# @maejorali# @therealjuicyj# .# now...                                                                                                               \n",
      "3  phil^ is^ not^ on^ fire^ 5^ is# here# !!!!# ht...                                                                                                               \n",
      "4  http://t.co/cwq9dxw2mg^ checkout# orlando# jon...                                                                                                               \n",
      "\n",
      "  exclusive# behind^ the# scenes^ video# of# @justinbieber# '# s# world# record# breaking# video# beauty^ &# a^ beat^ !^ check# it# out# .# http://t.co/dtiie45c^  \\\n",
      "0  icymi# :# cam^ newton's# amazing# 14yd# scramb...                                                                                                                \n",
      "1  #musicmondays# is# here^ .^ #recovery^ -# http...                                                                                                                \n",
      "2              #lollydance^ https://t.co/cobazwrxix^                                                                                                                \n",
      "3  just# had# a# chinese# feast# and# now# i'm# r...                                                                                                                \n",
      "4  http://t.co/cwq9dxw2mg^ this# shit# is# crazy#...                                                                                                                \n",
      "\n",
      "  Ok# fine# :)# here# it# is# Behind# Scenes# for# Beauty^ and# a^ Beat^ with# choreographer# [AT]# and# [AT]# enjoy# !^ [URL]^  \\\n",
      "0  Cam^ Newton# is# a# bad# ,# bad# man# .^ [HASH...                                                                              \n",
      "1  It's# here^ .# [NUM]# of# the# most# important...                                                                              \n",
      "2  It's# here# [AT]# [AT]# .# Now# everyone# do# ...                                                                              \n",
      "3  PHIL# IS# NOT# ON# FIRE# [NUM]^ IS# HERE# !!!!...                                                                              \n",
      "4  [URL]^ checkout# Orlando# jones# in# tainted# ...                                                                              \n",
      "\n",
      "  EXCLUSIVE# behind# the# scenes# video# of# [AT]# '# s# world# record# breaking# video# Beauty^ &# a^ Beat^ !^ Check# it# out# .# [URL]^  \\\n",
      "0  ICYMI# :# Cam^ Newton's# AMAZING# [NUM]# scram...                                                                                        \n",
      "1       [HASHTAG]# is# here^ .^ [HASHTAG]^ -# [URL]^                                                                                        \n",
      "2                                  [HASHTAG]^ [URL]^                                                                                        \n",
      "3  Just# had# a# chinese# feast# and# now# I'm# r...                                                                                        \n",
      "4          [URL]^ this# shit# is# crazy# go# OJ# !!#                                                                                        \n",
      "\n",
      "  ok# fine# :)# here# it# is# behind^ scenes^ for# beauty^ and# a^ beat^ with# choreographer# [at]# and# [at]# enjoy# !^ [url]^  \\\n",
      "0  cam^ newton# is# a# bad# ,# bad# man# .^ [hash...                                                                              \n",
      "1  it's# here^ .# [num]# of# the# most# important...                                                                              \n",
      "2  it's# here# [at]# [at]# .# now# everyone# do# ...                                                                              \n",
      "3  phil^ is^ not^ on^ fire^ [num]^ is# here# !!!!...                                                                              \n",
      "4  [url]^ checkout# orlando# jones# in# tainted# ...                                                                              \n",
      "\n",
      "  exclusive# behind^ the# scenes^ video# of# [at]# '# s# world# record# breaking# video# beauty^ &# a^ beat^ !^ check# it# out# .# [url]^  \\\n",
      "0  icymi# :# cam^ newton's# amazing# [num]# scram...                                                                                        \n",
      "1       [hashtag]# is# here^ .^ [hashtag]^ -# [url]^                                                                                        \n",
      "2                                  [hashtag]^ [url]^                                                                                        \n",
      "3  just# had# a# chinese# feast# and# now# i'm# r...                                                                                        \n",
      "4          [url]^ this# shit# is# crazy# go# oj# !!#                                                                                        \n",
      "\n",
      "  !# A^ E# R# O# V# P# N# P^ ^# &# D^ N^ P# N^ @^ &^ @# V^ ,^ U^  \\\n",
      "0          ^^ ^^ V^ D^ A# ,^ A# N# ,^ ## ## V^ ,^ U^               \n",
      "1  L# R# ,# $# P# D# R# A# N# P# O# L# R# V^ ,^ #...               \n",
      "2          L# R# @# @# ,# R# N# V# D# N# ,# ## #^ U^               \n",
      "3  ^# V^ R^ P^ ^^ $# V^ R^ ,# U# V# V# P^ O# V# D...               \n",
      "4                U^ V# ^# ^# P# A# N^ ,# A^ N# N# ,^               \n",
      "\n",
      "  A^ P^ D^ N^ N^ P# @^ ,# G# N# N# V# N# N# &^ D# N# ,# V^ O# T# ,^ U^  \n",
      "0  ^^ ,# ^^ Z# A# $# N# ,# O# V^ P# V# D^ $# ,^ ,...                    \n",
      "1                               ## V^ R# ,^ #^ ,^ U^                    \n",
      "2                                              #^ U^                    \n",
      "3  R# V^ D# A# N# &# R^ L# V# P^ A# N# P# ^^ V^ R...                    \n",
      "4                            U^ D# N^ V# A^ V# ^# ,^                    \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Now you can work with 'df', which contains the data from the CSV file\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ('user_id screen_name follower '\n",
    "'first_tid second_tid '\n",
    "'first_retweet second_retweet first_fav second_fav '\n",
    "'first_date second_date '\n",
    "'same same_mean '\n",
    "'first_text second_text first_token second_token '\n",
    "'first_tag second_tag '\n",
    "'first_normalized_token second_normalized_token '\n",
    "'first_diff second_diff '\n",
    "'first_nocase_diff second_nocase_diff '\n",
    "'first_normalized_diff second_normalized_diff '\n",
    "'first_normalized_nocase_diff second_normalized_nocase_diff '\n",
    "'first_tag_diff second_tag_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'screen_name', 'follower', 'first_tid', 'second_tid', 'first_retweet', 'second_retweet', 'first_fav', 'second_fav', 'first_date', 'second_date', 'same', 'same_mean', 'first_text', 'second_text', 'first_token', 'second_token', 'first_tag', 'second_tag', 'first_normalized_token', 'second_normalized_token', 'first_diff', 'second_diff', 'first_nocase_diff', 'second_nocase_diff', 'first_normalized_diff', 'second_normalized_diff', 'first_normalized_nocase_diff', 'second_normalized_nocase_diff', 'first_tag_diff', 'second_tag_diff']\n"
     ]
    }
   ],
   "source": [
    "print(column_names.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the column_names the column names of the dataframe\n",
    "df.columns = column_names.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam Newton is a bad, bad man. #ThatIsAll #NEvsCAR MUSSSSST-SEE: http://t.co/HuHIdT93wV\n",
      "Cam Newton is a bad , bad man . #ThatIsAll #NEvsCAR MUSSSSST-SEE : http://t.co/HuHIdT93wV\n",
      "Cam Newton is a bad , bad man . [HASHTAG] [HASHTAG] MUSSSSST-SEE : [URL]\n"
     ]
    }
   ],
   "source": [
    "# print first row\n",
    "# print(df.iloc[0])\n",
    "\n",
    "# first_retweet and second_retweet are useful to keep\n",
    "# first_text and second_text are useful to keep\n",
    "# Is first_fav okay to use?\n",
    "\n",
    "print(df['first_text'].iloc[0])\n",
    "print(df['first_token'].iloc[0])\n",
    "print(df['first_normalized_token'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a label column (0 or 1) based on which tweet was retweeted more\n",
    "df['label'] = (df['first_retweet'] < df['second_retweet']).astype(int)\n",
    "print(df['label'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5701 5702\n",
      "9121 1140 1142\n"
     ]
    }
   ],
   "source": [
    "# split df into train, val, and test, while keep the labels balanced\n",
    "label_0 = df[df['label'] == 0]\n",
    "label_1 = df[df['label'] == 1]\n",
    "print(len(label_0), len(label_1))\n",
    "# train = 80%, val = 10%, test = 10%\n",
    "train = pd.concat([label_0[:int(len(label_0)*0.8)], label_1[:int(len(label_1)*0.8)]])\n",
    "val = pd.concat([label_0[int(len(label_0)*0.8):int(len(label_0)*0.9)], label_1[int(len(label_1)*0.8):int(len(label_1)*0.9)]])\n",
    "test = pd.concat([label_0[int(len(label_0)*0.9):], label_1[int(len(label_1)*0.9):]])\n",
    "# shuffle the rows for each df\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "val = val.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output to csv\n",
    "# train.to_csv('../../data/retweet_train.csv', index=False)\n",
    "# val.to_csv('../../data/retweet_val.csv', index=False)\n",
    "# test.to_csv('../../data/retweet_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df(df):\n",
    "    dataset = {}\n",
    "\n",
    "    # dataset contains keys \"first_text\", \"second_text\", \"label\"\n",
    "    dataset['first_text'] = df['first_text'].tolist()\n",
    "    dataset['second_text'] = df['second_text'].tolist()\n",
    "    # label is \"first\" if first_retweet > second_retweet, \"second\" if second_retweet > first_retweet, \"same\" if equal\n",
    "    dataset['label'] = ['first' if a > b else 'second' if b > a else 'same' for a, b in zip(df['first_retweet'], df['second_retweet'])]\n",
    "\n",
    "    print(dataset.keys())\n",
    "    print(len(dataset['first_text']))\n",
    "    print(len(dataset['second_text']))\n",
    "    # print(len(dataset['label']))\n",
    "\n",
    "    # count number of first, second, same\n",
    "    print(dataset['label'].count('first'))\n",
    "    print(dataset['label'].count('second'))\n",
    "    # print(dataset['label'].count('same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['first_text', 'second_text', 'label'])\n",
      "9121\n",
      "9121\n",
      "4560\n",
      "4561\n",
      "dict_keys(['first_text', 'second_text', 'label'])\n",
      "1140\n",
      "1140\n",
      "570\n",
      "570\n",
      "dict_keys(['first_text', 'second_text', 'label'])\n",
      "1142\n",
      "1142\n",
      "571\n",
      "571\n"
     ]
    }
   ],
   "source": [
    "test_df(train)\n",
    "test_df(val)\n",
    "test_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
