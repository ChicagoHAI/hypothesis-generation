{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code repo path: /home/haokunliu/past-interaction-learning\n",
      "Code repo path: /home/haokunliu/past-interaction-learning\n",
      "Server: dsi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import jsonlines\n",
    "\n",
    "os.environ[\"CODE_REPO_PATH\"]=\"/home/haokunliu/past-interaction-learning\"\n",
    "os.environ[\"SERVER\"]='dsi'\n",
    "os.environ[\"PORT\"]='6379'\n",
    "code_repo_path = os.environ.get(\"CODE_REPO_PATH\")\n",
    "sys.path.append(f'{code_repo_path}/code')\n",
    "sys.path.append(f'{code_repo_path}/code/algorithm')\n",
    "\n",
    "from utils import create_directory\n",
    "from tasks import TASKS\n",
    "\n",
    "TASK_NAMES = list(TASKS.keys())\n",
    "TRAIN_SIZES = [10,25,50,100,200]\n",
    "HYP_SIZES = [3,20]\n",
    "ACC_PREFIX = {\n",
    "    'default': 'Averaged accuracy: ',\n",
    "    'knn': 'Averaged accuracy: ',\n",
    "    'knn_separate_steps': 'Averaged accuracy: ',\n",
    "    'filter_and_weight': 'Averaged accuracy: ',\n",
    "    'few_shot': 'Accuracy: ',\n",
    "    'zero_shot': 'Accuracy: ',\n",
    "    'RoBERTa': 'Accuracy: ',\n",
    "    'no_update': 'Test accuracy of best hypothesis:  ',\n",
    "    'upperbound': 'upperbound'\n",
    "}\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_acc(text, prefix='Averaged accuracy: '):\n",
    "    \"\"\"Extract numbers from a string using regular expressions.\"\"\"\n",
    "    if prefix == 'upperbound':\n",
    "        extracted_acc = re.findall(r'\\(if one hyp is correct\\):\\s\\d+\\.\\d+', text)\n",
    "        prefix = '(if one hyp is correct): ' \n",
    "    else:\n",
    "        extracted_acc = re.findall(fr'{prefix}\\d+\\.\\d+', text)\n",
    "    if len(extracted_acc)!= 1:\n",
    "        return 0.0\n",
    "    else:\n",
    "        extracted_acc = float(extracted_acc[0][len(prefix):])\n",
    "    return round(extracted_acc,3)\n",
    "\n",
    "def get_result_from_file(filename, method='default'):\n",
    "    with open(filename, 'r') as log_file:\n",
    "    # Read the entire contents of the file\n",
    "        log_contents = log_file.read()\n",
    "    log_acc = extract_acc(log_contents, prefix=ACC_PREFIX[method])\n",
    "    return log_acc\n",
    "\n",
    "def save_model_inf_results(prefix_folder, model_name, inference_method):\n",
    "    logs_folder = f'{code_repo_path}/{prefix_folder}/{inference_method}/{model_name}'\n",
    "    save_folder = f'{code_repo_path}/results_final'\n",
    "    create_directory(save_folder)\n",
    "    results_list = []\n",
    "    for task in TASK_NAMES:\n",
    "        for train_size in TRAIN_SIZES:\n",
    "            for hyp_size in HYP_SIZES:\n",
    "                log_file = f'{logs_folder}/{task}_train_{train_size}_hyp_{hyp_size}.txt'\n",
    "                if os.path.exists(log_file):\n",
    "                    log_acc = get_result_from_file(log_file, inference_method)\n",
    "                else:\n",
    "                    log_acc = 0.0\n",
    "                log_entry = {\n",
    "                    'inference_method': inference_method,\n",
    "                    'model_name': model_name,\n",
    "                    'task': task,\n",
    "                    'train_size': train_size,\n",
    "                    'hyp_size': hyp_size,\n",
    "                    \"acc\": log_acc\n",
    "                }\n",
    "                results_list.append(log_entry)\n",
    "    output_file_name = f'{save_folder}/{inference_method}_{model_name}.jsonl'\n",
    "    with jsonlines.open(output_file_name, mode='w') as writer:\n",
    "        for result_entry in results_list:\n",
    "            writer.write(result_entry)\n",
    "\n",
    "def save_few_shot_results(prefix_folder, model_name):\n",
    "    logs_folder = f'{code_repo_path}/{prefix_folder}/few_shot/{model_name}'\n",
    "    save_folder = f'{code_repo_path}/results_final'\n",
    "    create_directory(save_folder)\n",
    "    results_list = []\n",
    "    for task in TASK_NAMES:\n",
    "        for num_shot in ['zero_shot','few_shot']:\n",
    "            log_file = f'{logs_folder}/{task}_{num_shot}.txt'\n",
    "            if os.path.exists(log_file):\n",
    "                log_acc = get_result_from_file(log_file, num_shot)\n",
    "            else:\n",
    "                log_acc = 0.0\n",
    "            log_entry = {\n",
    "                'inference_method': num_shot,\n",
    "                'model_name': model_name,\n",
    "                'task': task,\n",
    "                \"acc\": log_acc\n",
    "            }\n",
    "            results_list.append(log_entry)\n",
    "    output_file_name = f'{save_folder}/few_shot_{model_name}.jsonl'\n",
    "    with jsonlines.open(output_file_name, mode='w') as writer:\n",
    "        for result_entry in results_list:\n",
    "            writer.write(result_entry)\n",
    "\n",
    "def save_no_update_results(prefix_folder, model_name):\n",
    "    logs_folder = f'{code_repo_path}/{prefix_folder}/no_update/{model_name}'\n",
    "    save_folder = f'{code_repo_path}/results_final'\n",
    "    create_directory(save_folder)\n",
    "    results_list = []\n",
    "    for task in TASK_NAMES:\n",
    "        for train_size in TRAIN_SIZES:\n",
    "            log_file = f'{logs_folder}/{task}_train_{train_size}.txt'\n",
    "            if os.path.exists(log_file):\n",
    "                log_acc = get_result_from_file(log_file, 'no_update')\n",
    "            else:\n",
    "                log_acc = 0.0\n",
    "            log_entry = {\n",
    "                'inference_method': 'no_update',\n",
    "                'model_name': model_name,\n",
    "                'task': task,\n",
    "                'train_size': train_size,\n",
    "                \"acc\": log_acc\n",
    "            }\n",
    "            results_list.append(log_entry)\n",
    "    output_file_name = f'{save_folder}/no_update_{model_name}.jsonl'\n",
    "    with jsonlines.open(output_file_name, mode='w') as writer:\n",
    "        for result_entry in results_list:\n",
    "            writer.write(result_entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_model_results_list = []\n",
    "for gen_model in ['turbo35_0613','claude_2', 'Mixtral-8x7B']:\n",
    "    for inf_model in ['turbo35_0613','claude_2', 'Mixtral-8x7B']:\n",
    "        for task in TASK_NAMES:\n",
    "            for hyp_size in HYP_SIZES:\n",
    "                for train_size in [200]:\n",
    "                    if gen_model == inf_model:\n",
    "                        log_file = f'{code_repo_path}/logs/default/{gen_model}/{task}_train_{train_size}_hyp_{hyp_size}.txt'\n",
    "                    else:\n",
    "                        log_file = f'{code_repo_path}/logs/ablation_default/{gen_model}-{inf_model}/{task}_train_{train_size}_hyp_{hyp_size}.txt'\n",
    "                    if os.path.exists(log_file):\n",
    "                        log_acc = get_result_from_file(log_file, 'default')\n",
    "                    else:\n",
    "                        log_acc = 0.0\n",
    "\n",
    "                    log_entry = {\n",
    "                        'inference_method': 'default',\n",
    "                        'generation_model': gen_model,\n",
    "                        'inference_model': inf_model,\n",
    "                        'task': task,\n",
    "                        'train_size': train_size,\n",
    "                        'hyp_size': hyp_size,\n",
    "                        \"acc\": log_acc\n",
    "                    }\n",
    "                    cross_model_results_list.append(log_entry)\n",
    "output_file_name = f'{code_repo_path}/results_final/cross_models.jsonl'\n",
    "with jsonlines.open(output_file_name, mode='w') as writer:\n",
    "    for result_entry in cross_model_results_list:\n",
    "        writer.write(result_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_results_list = []\n",
    "ood_path = f'{code_repo_path}/logs/OOD_hotel'\n",
    "for model_name in ['turbo35_0613','claude_2', 'Mixtral-8x7B']:\n",
    "    for inference_method in ['default', 'knn', 'knn_separate_steps', 'filter_and_weight']:\n",
    "        for hyp_size in HYP_SIZES:\n",
    "            for train_size in [200]:\n",
    "                log_file = f'{ood_path}/{model_name}/OOD_hotel_reviews_{inference_method}_train_{train_size}_hyp_{hyp_size}.txt'\n",
    "                if os.path.exists(log_file):\n",
    "                    log_acc = get_result_from_file(log_file, inference_method)\n",
    "                else:\n",
    "                    log_acc = 0.0\n",
    "\n",
    "                log_entry = {\n",
    "                    'inference_method': inference_method,\n",
    "                    'inference_model': model_name,\n",
    "                    'train_size': train_size,\n",
    "                    'hyp_size': hyp_size,\n",
    "                    \"acc\": log_acc\n",
    "                }\n",
    "                ood_results_list.append(log_entry)\n",
    "\n",
    "for train_size in [200,1000]:\n",
    "    log_file = f'{ood_path}/RoBERTa/OOD_hotel_reviews_RoBERTa_train_{train_size}.txt'\n",
    "    if os.path.exists(log_file):\n",
    "        log_acc = get_result_from_file(log_file, 'RoBERTa')\n",
    "    else:\n",
    "        log_acc = 0.0\n",
    "    log_entry = {\n",
    "        'inference_method': 'RoBERTa',\n",
    "        'inference_model': 'RoBERTa',\n",
    "        'train_size': train_size,\n",
    "        'hyp_size': None,\n",
    "        \"acc\": log_acc\n",
    "    }\n",
    "    ood_results_list.append(log_entry)\n",
    "\n",
    "for model_name in ['turbo35_0613','claude_2', 'Mixtral-8x7B']:\n",
    "    for few_shot in ['few_shot', 'zero_shot']:\n",
    "        log_file = f'{ood_path}/{model_name}/OOD_hotel_reviews_{few_shot}.txt'\n",
    "        if os.path.exists(log_file):\n",
    "            log_acc = get_result_from_file(log_file, few_shot)\n",
    "        else:\n",
    "            log_acc = 0.0\n",
    "        log_entry = {\n",
    "            'inference_method': few_shot,\n",
    "            'inference_model': model_name,\n",
    "            'train_size': None,\n",
    "            'hyp_size': None,\n",
    "            \"acc\": log_acc\n",
    "        }\n",
    "        ood_results_list.append(log_entry)\n",
    "output_file_name = f'{code_repo_path}/results_final/ood_reviews.jsonl'\n",
    "with jsonlines.open(output_file_name, mode='w') as writer:\n",
    "    for result_entry in ood_results_list:\n",
    "        writer.write(result_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "upperbound_results_list = []\n",
    "upperbound_path = f'{code_repo_path}/logs/upperbound'\n",
    "for model_name in ['turbo35_0613','claude_2', 'Mixtral-8x7B']:\n",
    "    for task in TASK_NAMES:\n",
    "        log_file = f'{upperbound_path}/{model_name}/{task}_train_200_hyp_20.txt'\n",
    "        if os.path.exists(log_file):\n",
    "            log_acc = get_result_from_file(log_file, 'upperbound')\n",
    "        else:\n",
    "            log_acc = 0.0\n",
    "\n",
    "        log_entry = {\n",
    "            'inference_method': 'upperbound',\n",
    "            'inference_model': model_name,\n",
    "            'task': task,\n",
    "            'train_size': 200,\n",
    "            'hyp_size': 20,\n",
    "            \"acc\": log_acc\n",
    "        }\n",
    "        upperbound_results_list.append(log_entry)\n",
    "output_file_name = f'{code_repo_path}/results_final/upperbound.jsonl'\n",
    "with jsonlines.open(output_file_name, mode='w') as writer:\n",
    "    for result_entry in upperbound_results_list:\n",
    "        writer.write(result_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n",
      "Directory '/home/haokunliu/past-interaction-learning/results_final' already exists.\n"
     ]
    }
   ],
   "source": [
    "prefix_folder = 'logs'\n",
    "for model_name in ['turbo35_0613','claude_2', 'Mixtral-8x7B']:\n",
    "    for inference_method in ['default', 'knn', 'knn_separate_steps', 'filter_and_weight','no_update']:\n",
    "        save_model_inf_results(prefix_folder,model_name,inference_method)\n",
    "    save_few_shot_results(prefix_folder,model_name)\n",
    "    save_no_update_results(prefix_folder,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
