{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import altair as alt\n",
    "import vl_convert as vlc\n",
    "from collections import defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shoe results (batched learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_acc(string):\n",
    "    # the line is \"Test accuracy of best hypothesis:  0.82\\n\"\n",
    "    return float(string.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no hypothesis baseline\n",
    "baseline_dir = '/data/rosa/work_in_progress/past-interaction-learning/print_log_tmp_debug/shoe/no_hypothesis_zero_shot/without_unknown'\n",
    "\n",
    "# batched\n",
    "batched_dir = '/data/rosa/work_in_progress/past-interaction-learning/print_log_tmp_debug/shoe/batched_inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to read test acc:  /data/rosa/work_in_progress/past-interaction-learning/print_log_tmp_debug/shoe/batched_inference/inference_model_turbo35_0613_generation_model_claude_2_train1_seed50_hypothesis5.txt\n",
      "claude 2:  defaultdict(<class 'list'>, {'avg_test_acc': [(1, 0.37666666666666665), (3, 0.4966666666666666), (6, 0.6000000000000001), (12, 0.8300000000000001), (25, 0.9133333333333334), (50, 0.93), (100, 0.82)]})\n",
      "llama 2 7b:  defaultdict(<class 'list'>, {'avg_test_acc': [(1, 0.49), (3, 0.30666666666666664), (6, 0.49333333333333335), (12, 0.35666666666666663), (25, 0.4066666666666667), (50, 0.34), (100, 0.28)]})\n",
      "turbo35 0613:  defaultdict(<class 'list'>, {'avg_test_acc': [(1, 0.4000000000000001), (3, 0.3233333333333333), (6, 0.36000000000000004), (12, 0.33), (25, 0.47333333333333333), (50, 0.3333333333333333), (100, 0.43999999999999995)]})\n"
     ]
    }
   ],
   "source": [
    "# get the data for plots\n",
    "results_directory = batched_dir\n",
    "models = ['claude_2', 'llama_2_7b', 'turbo35_0613']\n",
    "train_size = [1, 3, 6, 12, 25, 50, 100]\n",
    "seeds = [49, 50, 51]\n",
    "num_hypothesis = 5\n",
    "\n",
    "# get data for plots\n",
    "data = {}\n",
    "for model in models:\n",
    "    data[model] = defaultdict(list)\n",
    "\n",
    "for model in models:\n",
    "    for size in train_size:\n",
    "        test_acc_list = []\n",
    "        for seed in seeds:\n",
    "            try:\n",
    "                file_path = f\"{results_directory}/inference_model_turbo35_0613_generation_model_{model}_train{size}_seed{seed}_hypothesis{num_hypothesis}.txt\"\n",
    "                \n",
    "                # get the last three lines of the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    last_lines = lines[-3:]\n",
    "\n",
    "                # get accuracy numbers\n",
    "                test_acc = get_test_acc(last_lines[0])\n",
    "\n",
    "                # print('test_acc', test_acc)\n",
    "                # print('max_train_acc', max_train_acc)\n",
    "                # print('mean_train_acc', mean_train_acc)\n",
    "\n",
    "                # add to lists\n",
    "                test_acc_list.append(test_acc)\n",
    "\n",
    "                # print('test_acc', test_acc)\n",
    "            except:\n",
    "                print('failed to read test acc: ', file_path)\n",
    "                test_acc_list.append(0)\n",
    "        \n",
    "        # compute the average acc across seeds\n",
    "        avg_test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "\n",
    "        # add to data\n",
    "        data[model]['avg_test_acc'].append((size, avg_test_acc))\n",
    "\n",
    "        \n",
    "\n",
    "print('claude 2: ', data['claude_2'])\n",
    "print('llama 2 7b: ', data['llama_2_7b'])\n",
    "print('turbo35 0613: ', data['turbo35_0613'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.38\n",
      "test_acc:  0.38\n",
      "test_acc:  0.38\n",
      "test_acc:  0.16\n",
      "test_acc:  0.21\n",
      "test_acc:  0.15\n",
      "test_acc:  0.38\n",
      "test_acc:  0.38\n",
      "test_acc:  0.38\n",
      "baseline_data:  {'claude_2': 0.38000000000000006, 'llama_2_7b': 0.17333333333333334, 'turbo35_0613': 0.38000000000000006}\n"
     ]
    }
   ],
   "source": [
    "# get no hypothesis baseline\n",
    "baseline_data = {}\n",
    "\n",
    "for model in models:\n",
    "    acc_list = []\n",
    "    for seed in seeds:\n",
    "        file_path = f\"{baseline_dir}/inference_with_{model}_seed{seed}.txt\"\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            last_line = lines[-1]\n",
    "            test_acc = float(last_line.split()[-1])\n",
    "            acc_list.append(test_acc)\n",
    "            print('test_acc: ', test_acc)\n",
    "    avg_test_acc = sum(acc_list) / len(acc_list)\n",
    "    baseline_data[model] = avg_test_acc\n",
    "\n",
    "print('baseline_data: ', baseline_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-fb581ae69cfc4c5d94fe9792dcbe7360.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-fb581ae69cfc4c5d94fe9792dcbe7360.vega-embed details,\n",
       "  #altair-viz-fb581ae69cfc4c5d94fe9792dcbe7360.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-fb581ae69cfc4c5d94fe9792dcbe7360\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fb581ae69cfc4c5d94fe9792dcbe7360\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fb581ae69cfc4c5d94fe9792dcbe7360\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-22c8fca5ccd2824d0e3147bcca69aec1\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"model\", \"scale\": {\"domain\": [\"claude_2\", \"llama_2_7b\", \"turbo35_0613\", \"roberta\"], \"range\": [\"#88CCEE\", \"#44AA99\", \"#CC6677\", \"#DDCC77\"]}, \"type\": \"nominal\"}, \"strokeDash\": {\"field\": \"type\", \"scale\": {\"domain\": [\"avg_test_acc\", \"no_hypothesis\", \"finetuning\"], \"range\": [[0, 0], [2, 2], [4, 4]]}, \"type\": \"nominal\"}, \"x\": {\"field\": \"training examples\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy in Low Data Regime (Batched Learning, Shoe Dataset)\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-22c8fca5ccd2824d0e3147bcca69aec1\": [{\"training examples\": 1, \"accuracy\": 0.37666666666666665, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 3, \"accuracy\": 0.4966666666666666, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 6, \"accuracy\": 0.6000000000000001, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 12, \"accuracy\": 0.8300000000000001, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 25, \"accuracy\": 0.9133333333333334, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 50, \"accuracy\": 0.93, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 100, \"accuracy\": 0.82, \"type\": \"avg_test_acc\", \"model\": \"claude_2\"}, {\"training examples\": 1, \"accuracy\": 0.49, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 3, \"accuracy\": 0.30666666666666664, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 6, \"accuracy\": 0.49333333333333335, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 12, \"accuracy\": 0.35666666666666663, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 25, \"accuracy\": 0.4066666666666667, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 50, \"accuracy\": 0.34, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 100, \"accuracy\": 0.28, \"type\": \"avg_test_acc\", \"model\": \"llama_2_7b\"}, {\"training examples\": 1, \"accuracy\": 0.4000000000000001, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 3, \"accuracy\": 0.3233333333333333, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 6, \"accuracy\": 0.36000000000000004, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 12, \"accuracy\": 0.33, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 25, \"accuracy\": 0.47333333333333333, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 50, \"accuracy\": 0.3333333333333333, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 100, \"accuracy\": 0.43999999999999995, \"type\": \"avg_test_acc\", \"model\": \"turbo35_0613\"}, {\"training examples\": 1, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 3, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 6, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 12, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 25, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 50, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 100, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"claude_2\"}, {\"training examples\": 1, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 3, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 6, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 12, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 25, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 50, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 100, \"accuracy\": 0.17333333333333334, \"type\": \"no_hypothesis\", \"model\": \"llama_2_7b\"}, {\"training examples\": 1, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 3, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 6, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 12, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 25, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 50, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 100, \"accuracy\": 0.38000000000000006, \"type\": \"no_hypothesis\", \"model\": \"turbo35_0613\"}, {\"training examples\": 1, \"accuracy\": 0.17333333333333334, \"type\": \"finetuning\", \"model\": \"roberta\"}, {\"training examples\": 3, \"accuracy\": 0.17666666666666667, \"type\": \"finetuning\", \"model\": \"roberta\"}, {\"training examples\": 6, \"accuracy\": 0.18666666666666668, \"type\": \"finetuning\", \"model\": \"roberta\"}, {\"training examples\": 12, \"accuracy\": 0.18666666666666668, \"type\": \"finetuning\", \"model\": \"roberta\"}, {\"training examples\": 25, \"accuracy\": 0.18666666666666668, \"type\": \"finetuning\", \"model\": \"roberta\"}, {\"training examples\": 50, \"accuracy\": 0.18666666666666668, \"type\": \"finetuning\", \"model\": \"roberta\"}, {\"training examples\": 100, \"accuracy\": 1.0, \"type\": \"finetuning\", \"model\": \"roberta\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot with altair\n",
    "# plot claude results in dashed line and llama results in solid line\n",
    "# plot test acc, max train acc, and mean train acc in different colors\n",
    "# plot train size on x-axis\n",
    "\n",
    "claude_test_acc = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [t[1] for t in data['claude_2']['avg_test_acc']],\n",
    "    'type': 'avg_test_acc',\n",
    "    'model': 'claude_2',\n",
    "})\n",
    "\n",
    "llama_test_acc = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [t[1] for t in data['llama_2_7b']['avg_test_acc']],\n",
    "    'type': 'avg_test_acc',\n",
    "    'model': 'llama_2_7b',\n",
    "})\n",
    "\n",
    "turbo_test_acc = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [t[1] for t in data['turbo35_0613']['avg_test_acc']],\n",
    "    'type': 'avg_test_acc',\n",
    "    'model': 'turbo35_0613',\n",
    "})\n",
    "\n",
    "claude_baseline = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [baseline_data['claude_2']] * len(train_size),\n",
    "    'type': 'no_hypothesis',\n",
    "    'model': 'claude_2',\n",
    "})\n",
    "\n",
    "llama_baseline = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [baseline_data['llama_2_7b']] * len(train_size),\n",
    "    'type': 'no_hypothesis',\n",
    "    'model': 'llama_2_7b',\n",
    "})\n",
    "\n",
    "turbo_baseline = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [baseline_data['turbo35_0613']] * len(train_size),\n",
    "    'type': 'no_hypothesis',\n",
    "    'model': 'turbo35_0613',\n",
    "})\n",
    "\n",
    "roberta_baseline = pd.DataFrame({\n",
    "    'training examples': train_size,\n",
    "    'accuracy': [0.17333333333333334,\n",
    " 0.17666666666666667,\n",
    " 0.18666666666666668,\n",
    " 0.18666666666666668,\n",
    " 0.18666666666666668,\n",
    " 0.18666666666666668,\n",
    " 1.0],\n",
    "    'type': 'finetuning',\n",
    "    'model': 'roberta',\n",
    "})\n",
    "\n",
    "# Concatenate the data into a single DataFrame\n",
    "plot_data = pd.concat([\n",
    "        claude_test_acc,\n",
    "        llama_test_acc,\n",
    "        turbo_test_acc,\n",
    "        claude_baseline,\n",
    "        llama_baseline,\n",
    "        turbo_baseline,\n",
    "        roberta_baseline\n",
    "        ], \n",
    "    ignore_index=True)\n",
    "\n",
    "# Create Altair chart with color encoding\n",
    "chart = alt.Chart(plot_data).mark_line().encode(\n",
    "        x='training examples',\n",
    "        y='accuracy',\n",
    "        color=alt.Color('model:N', scale=alt.Scale(\n",
    "            domain = ['claude_2', 'llama_2_7b', 'turbo35_0613', 'roberta'],\n",
    "            range = ['#88CCEE', '#44AA99', '#CC6677', '#DDCC77']\n",
    "        )),\n",
    "        strokeDash=alt.StrokeDash('type:N', scale=alt.Scale(\n",
    "            domain = ['avg_test_acc', 'no_hypothesis', 'finetuning'],\n",
    "            range = [[0,0], [2,2], [4, 4]]\n",
    "        )),\n",
    "    ).properties(\n",
    "        title='Accuracy in Low Data Regime (Batched Learning, Shoe Dataset)',\n",
    "    )\n",
    "\n",
    "chart.configure_title(\n",
    "    fontSize=20,\n",
    "    font='Courier',\n",
    "    anchor='start',\n",
    "    color='gray'\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I want to add a data point for another model at (100, 0.913)\n",
    "# dot_chart = alt.Chart(pd.DataFrame({'training examples': [100], 'accuracy': [0.913]})).mark_point(color='black').encode(\n",
    "#     x='training examples',\n",
    "#     y='accuracy',\n",
    "#     color = '')\n",
    "\n",
    "# dot_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the test accuracy of supervised linear model, lin ucb, and ours on the shoe dataset (1k training examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin_ucb = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [26.4, 34.2, 39.2, 40.8],\n",
    "#     'method': 'Lin UCB'\n",
    "# })\n",
    "\n",
    "# supervised = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [56.0, 62.0, 82.0, 97.0],\n",
    "#     'method': 'Supervised Learning'\n",
    "# })\n",
    "\n",
    "# inductive_reasoning_greedy = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [76.1, 76.8, 73.4, 80.8],\n",
    "#     'method': 'Old algorithm + 0613 (greedy)'\n",
    "# })\n",
    "\n",
    "# inductive_reasoning_relevant = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [77.4, 82.2, 67.0, 81.1],\n",
    "#     'method': 'Old algorithm + 0613 (relevant)'\n",
    "# })\n",
    "\n",
    "# inductive_reasoning_bv = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [83.5, 83.2, 80.5, 82.8],\n",
    "#     'method': 'Old algorithm + 0613 (binary vote)'\n",
    "# })\n",
    "\n",
    "# new_greedy = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [81.0, 71.0, 69.3, 56.3],\n",
    "#     'method': 'New algorithm + 1106 (greedy)'\n",
    "# })\n",
    "\n",
    "# new_relevant = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [79.3, 69.3, 72.3, 70.7],\n",
    "#     'method': 'New algorithm + 1106 (relevant)'\n",
    "# })\n",
    "\n",
    "# new_bv = pd.DataFrame({\n",
    "#     'training examples': [100, 200, 500, 1000],\n",
    "#     'accuracy on unseen examples (%)': [81.7, 81.7, 77.3, 80.0],\n",
    "#     'method': 'New algorithm + 1106 (binary vote)'\n",
    "# })\n",
    "\n",
    "# # Concatenate the data into a single DataFrame\n",
    "# data = pd.concat([\n",
    "#                     # lin_ucb, \n",
    "#                     # supervised, \n",
    "#                     inductive_reasoning_greedy,\n",
    "#                     inductive_reasoning_relevant,\n",
    "#                     inductive_reasoning_bv,\n",
    "#                     new_greedy,\n",
    "#                     new_relevant,\n",
    "#                     new_bv,\n",
    "#                   ], \n",
    "#                   ignore_index=True)\n",
    "\n",
    "# # Create Altair chart with color encoding\n",
    "# chart = alt.Chart(data).mark_line().encode(\n",
    "#         x='training examples',\n",
    "#         y='accuracy on unseen examples (%)',\n",
    "#         color='method'\n",
    "#     ).properties(\n",
    "#         title='Avg Acc over 3 Seeds vs Train Size',\n",
    "#     )\n",
    "\n",
    "# chart.configure_title(\n",
    "#     fontSize=20,\n",
    "#     font='Courier',\n",
    "#     anchor='start',\n",
    "#     color='gray'\n",
    "# )\n",
    "\n",
    "# # Display the chart\n",
    "# chart\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
