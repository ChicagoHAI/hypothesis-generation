{
    "paper_id": "2001",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2024-07-18T18:03:30.261560Z"
    },
    "title": "\"Why is 'Chicago' deceptive?\" Towards Building Model-Driven Tutorials for Humans",
    "authors": [
        {
            "first": "Vivian",
            "middle": [],
            "last": "Lai",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Colorado",
                "location": {}
            },
            "email": "vivian.lai@colorado.edu"
        },
        {
            "first": "Han",
            "middle": [],
            "last": "Liu",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Colorado",
                "location": {}
            },
            "email": "han.liu@colorado.edu"
        },
        {
            "first": "Chenhao",
            "middle": [],
            "last": "Tan",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "University of Colorado",
                "location": {}
            },
            "email": "chenhao@chenhaot.com"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a training phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI.",
    "pdf_parse": {
        "paper_id": "2001",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a training phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Interpretable machine learning (ML) has attracted significant interest as ML models are used to support human decision making in societally critical domains such as justice systems and healthcare [13, 21, 41] . In these domains, full automation is often not desired and humans are the final decision makers for legal and ethical reasons. In fact, the Wisconsin Supreme Court ruled that \"a COMPAS risk assessment should not be used to determine the severity of a sentence or whether an offender is incarcerated\", but does not eliminate the use of ML models if \"judges be made aware of the limitations of risk assessment tools\" [40, 54] . Therefore, it is crucial to enhance human performance with the assistance of machine learning models, e.g., by explaining the recommended decisions.",
                "cite_spans": [
                    {
                        "start": 196,
                        "end": 200,
                        "text": "[13,",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 201,
                        "end": 204,
                        "text": "21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 205,
                        "end": 208,
                        "text": "41]",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 626,
                        "end": 630,
                        "text": "[40,",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 631,
                        "end": 634,
                        "text": "54]",
                        "ref_id": "BIBREF53"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "However, recent human-subject studies tend to show limited effectiveness of explanations in improving human performance [7, 23, 34, 62] . For instance, Lai and Tan [34] show that explanations alone only slightly improve human performance in deceptive review detection; Weerts et al. [62] similarly find that explanations do not improve human performance in predicting whether one's income exceeds 50,000 in the Adult dataset. These studies explain a machine prediction by revealing model internals, e.g., via attributing importance weights to features and then visualizing feature importance. We refer to such assistance as real-time assistance because they are provided as humans make individual decisions.",
                "cite_spans": [
                    {
                        "start": 120,
                        "end": 123,
                        "text": "[7,",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 124,
                        "end": 127,
                        "text": "23,",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 128,
                        "end": 131,
                        "text": "34,",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 132,
                        "end": 135,
                        "text": "62]",
                        "ref_id": "BIBREF61"
                    },
                    {
                        "start": 164,
                        "end": 168,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 283,
                        "end": 287,
                        "text": "[62]",
                        "ref_id": "BIBREF61"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "To understand such limited effectiveness, we argue that it is useful to distinguish two distinct modes in which ML models are being used: emulating and discovering. In tasks such as object recognition [11, 22] , datasets are crowdsourced because humans are considered the gold standard, and ML models are designed to emulate human intelligence. 1 In contrast, in the discovering mode, datasets are usually collected from observing social processes, e.g., whether a person commits crime on bail for bail decisions [28] and what the writer intention is for deceptive review detection [1, 47] . ML models can thus often identify patterns that are unsalient, unknown, and even counterintuitive to humans, and may even outperform humans in constrained datasets [28, 47, 56] . Notably, many critical policy decisions such as bail decisions resemble the discovering mode more than the emulating mode because policy decisions are usually challenging (to humans) in nature [29] .",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 205,
                        "text": "[11,",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 206,
                        "end": 209,
                        "text": "22]",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 513,
                        "end": 517,
                        "text": "[28]",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 582,
                        "end": 585,
                        "text": "[1,",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 586,
                        "end": 589,
                        "text": "47]",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 756,
                        "end": 760,
                        "text": "[28,",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 761,
                        "end": 764,
                        "text": "47,",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 765,
                        "end": 768,
                        "text": "56]",
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 964,
                        "end": 968,
                        "text": "[29]",
                        "ref_id": "BIBREF28"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "Studies on how explanations affect human performance tend to employ these challenging tasks for humans (the discovering mode for ML models) because humans need little assistance to perform tasks in the emulating mode (except for scalability). This observation highlights different roles of explanations in these two modes. In the emulating mode, explanations can help debug and identify biases and robustness issues in the models for future automation. In the discovering mode, if the patterns embedded in ML models can be elucidated for humans, they may enhance human knowledge and improve human decision making. 2 Moreover, it might help humans identify spurious patterns in ML models and account for potential mistakes to generalize beyond a constrained dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "To further illustrate the difficulty of interpreting explanations in the discovering mode, Fig. 1 (a) shows an example from a deceptive review detection task, where the goal is to distinguish deceptive reviews written by people who did not stay at the hotel from genuine ones. \"Chicago\" is highly associated with , where green words are associated with genuine reviews and red words are associated with deceptive reviews; b) participants are presented the actual label, the predicted label, and textual explanations for a review after choosing the label of the review in example-driven tutorials; c) a list of guidelines for identifying deceptive reviews extracted from scientific papers.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 96,
                        "end": 97,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "deceptive reviews because people are more likely to mention the city name instead of specific places when they imagine their experience. Such a pattern can be hard to comprehend for humans, especially when the highlights are shown as real-time assistance without any other information.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "Instead of throwing people in at the deep end directly with real-time assistance, we propose a novel training phase that can help humans understand the nature of a task and the patterns embedded in a model. This training step is analogous to offline coaching and can be complementary to real-time assistance in explaining machine predictions. We consider two types of model-driven tutorials: 1) guidelines extracted from scientific papers [39, 46, 47] (Fig. 1(c )), which reflects the current practices of science communication; 2) exampledriven tutorials where we select examples from the training data and present them along with explanations in the form of highlights (Fig. 1(a) & (b) ). We also develop a novel algorithm that incorporates spaced repetition to help humans understand the patterns in a machine learning model, and conduct an in-person user study to refine the design of our tutorials.",
                "cite_spans": [
                    {
                        "start": 439,
                        "end": 443,
                        "text": "[39,",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 444,
                        "end": 447,
                        "text": "46,",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 448,
                        "end": 451,
                        "text": "47]",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 458,
                        "end": 461,
                        "text": "1(c",
                        "ref_id": "FIGREF0"
                    },
                    {
                        "start": 677,
                        "end": 681,
                        "text": "1(a)",
                        "ref_id": "FIGREF0"
                    },
                    {
                        "start": 684,
                        "end": 687,
                        "text": "(b)",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "Our main contribution in this work is to design large-scale, randomized, pre-registered human-subject experiments to investigate whether tutorials provide useful training to humans, using the aforementioned deceptive review detection task as a testbed. We choose this task because 1) deceptive information including fake news is prevalent on the Internet [2, 19, 35, 45] and mechanical turkers can provide a reasonable proxy for humans facing this challenge compared to other tasks such as bail decisions and medical diagnosis that require domain expertise; 2) while humans struggle with detecting deception [6] , machine learning models are able to learn useful patterns in constrained settings (in particular, ML models achieve an accuracy of above 85% in our deceptive review detection task); 3) full automation might not be desired in this case because the government should not have the authority to automatically block information from individuals, and it is important to enhance human ability with a machine in the loop. Specifically, we focus on the following three research questions:",
                "cite_spans": [
                    {
                        "start": 355,
                        "end": 358,
                        "text": "[2,",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 359,
                        "end": 362,
                        "text": "19,",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 363,
                        "end": 366,
                        "text": "35,",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 367,
                        "end": 370,
                        "text": "45]",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 608,
                        "end": 611,
                        "text": "[6]",
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "\u2022 RQ1: Do model-driven tutorials improve human performance without any real-time assistance?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "\u2022 RQ2: How do varying levels of real-time assistance affect human performance after training?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "\u2022 RQ3: How do model complexity and explanation methods affect human performance with/without training? In all experiments, if training is provided, human subjects first go through a training phase with model-driven tutorials, and then enter the prediction phase to determine whether a review is deceptive or genuine. The prediction phase allows us to evaluate human performance after training.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "Our first experiment aims to compare the effectiveness of different model-driven tutorials. Ideally, we would hope that these tutorials can help humans understand the patterns embedded in the ML models well enough that they can perform decently in the prediction phase without any real-time assistance. Our results show that human performance after tutorials are always better than without training, and the differences are statistically significant for two types of tutorials. However, the improvement is relatively limited: human performance reaches \u223c60%, while the ML models are above 85%. Meanwhile, there is no statistically significant difference between human performance after any type of tutorial, which suggests that all model-driven tutorials are similarly effective.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "One possible reason for the limited improvement of human performance in Experiment 1 is that the patterns might be too complicated for humans to apply in the prediction phase without any real-time assistance. Therefore, our second experiment is designed to understand the effect of tutorials with real-time assistance. Inspired by Lai and Tan [34] , we develop a spectrum with varying levels of real-time assistance between full human agency and full automation (Fig. 2 ). Our results demonstrate that real-time assistance can indeed significantly improve human performance to above 70%. However, compared to Lai and Tan [34] , the best human performance is not significantly improved. 3 It suggests that given real-time assistance, tutorials are mainly useful in that humans can perform similarly well in the prediction phase with only signed highlights, thus retaining a higher level of human agency.",
                "cite_spans": [
                    {
                        "start": 343,
                        "end": 347,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 621,
                        "end": 625,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 468,
                        "end": 469,
                        "text": "2",
                        "ref_id": "FIGREF29"
                    }
                ],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "Finally, in order to understand how our results generalize to different kinds of models, we would like to examine the effect of model complexity and methods of deriving explanations. Our first two experiments use a linear SVM classifier because linear models are typically deemed interpretable, but deep learning models are increasingly prevalent because of their superior predictive power. While it is well recognized that deep learning models are more complex, it remains an open question how human performance changes with assistance from deep learning models (e.g., BERT) vs. simple models (e.g., linear SVM). Our results show that tutorials and explanations of simple models lead to better human performance than deep learning models, which highlights the tradeoff between model complexity and interpretability. We also show that for BERT, post-hoc signed explanations from LIME are more effective than built-in explanations derived from attention mechanisms. Moreover, tutorials are effective in improving human performance for both kinds of models compared to without training.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "Overall, our results show that model-driven tutorials can somewhat improve human performance with and without real-time assistance, and humans also find these tutorials useful. However, the limited improvement also points to future directions of human-centered interpretable machine learning. We highlight two implications here and present further discussions in the Discussion section. First, it is important to explain beyond the surface patterns and facilitate humans in reasoning about why a feature is important. A strategy is to develop interactive explanations that allow humans to explore the patterns in both the training and the prediction phase. Second, it is useful to bridge the gap between training and generalization in developing tutorials because the model behavior and performance in training data might differ from that on unseen data. The ability to understand this difference is crucial for humans to calibrate trust and generalize beyond the constrained dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "INTRODUCTION",
                "sec_num": null
            },
            {
                "text": "We start by introducing recent methods for interpretable ML, and then discuss experimental studies on human interaction with explanations and predictions derived from ML models. We end by summarizing related work on deception detection.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "RELATED WORK",
                "sec_num": null
            },
            {
                "text": "A battery of studies propose various algorithms to explain a machine prediction by uncovering model internals (also known as local explanations) [21] . Most relevant to our work is feature attribution that assigns an importance weight to each feature [37, 42, 50, 51] . For instance, Ribeiro et al. [50] propose LIME that fits a sparse linear model to approximate local machine predictions, and coefficients in this linear model are used as explanations. Lai et al. [33] compare the built-in and post-hoc explanations methods in text classification and show that different methods lead to very different explanations, in particular, deep learning models lead to explanations with less consistency than simple models such as linear SVM. Other popular approaches include 1) example-based [26, 27, 43, 52, 61] , e.g., counterfactual explanations find alternative examples that would have obtained a different prediction, and 2) rulebased [3, 20] that summarizes local rules (e.g., via decision trees). Notably, SP-LIME is an algorithm that selects examples to provide a global understanding of the model [50] , which aligns with our goal of generating tutorials. However, to the best of our knowledge, there have not been any human-subject experiments with such example-driven tutorials.",
                "cite_spans": [
                    {
                        "start": 145,
                        "end": 149,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 251,
                        "end": 255,
                        "text": "[37,",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 256,
                        "end": 259,
                        "text": "42,",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 260,
                        "end": 263,
                        "text": "50,",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 264,
                        "end": 267,
                        "text": "51]",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 299,
                        "end": 303,
                        "text": "[50]",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 466,
                        "end": 470,
                        "text": "[33]",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 786,
                        "end": 790,
                        "text": "[26,",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 791,
                        "end": 794,
                        "text": "27,",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 795,
                        "end": 798,
                        "text": "43,",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 799,
                        "end": 802,
                        "text": "52,",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 803,
                        "end": 806,
                        "text": "61]",
                        "ref_id": "BIBREF60"
                    },
                    {
                        "start": 935,
                        "end": 938,
                        "text": "[3,",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 939,
                        "end": 942,
                        "text": "20]",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 1101,
                        "end": 1105,
                        "text": "[50]",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Methods for interpretable machine learning",
                "sec_num": null
            },
            {
                "text": "The importance of human-subject experiments is increasingly recognized in understanding the effectiveness of explanations because they are ultimately used by humans. In addition to studies mentioned in the introduction, researchers have investigated other desiderata of explanations [5, 8, 17, 18, 32, 49, 65] . For instance, Binns et al. [5] examine perception of justice given multiple styles of explanations and conclude that there is no best approach to explaining algorithmic decisions. Cai et al. [8] show that a user-centered design improves human perception of an image-search tool's usefulness, but does not improve human performance. Green and Chen [17] find that humans underperformed a risk assessment tool even when presented with its predictions, and exhibited behaviors that could exacerbate biases against minority groups. Yin et al. [65] examine the effect of stated accuracy and observed accuracy on humans' trust in models, while Kunkel et al. [32] study the effect of explanations on trust in recommender systems. This line of work on trust also relates to the literature on appropriate reliance with general automation [36, 38] . Retaining human agency is particularly important in societally critical domains where consequences can be dire. Finally, Bansal et al. [4] provide feedback during decision making, which can be seen as a form of continuous learning. Our focus is to understand the effect of offline tutorials, which can be potentially combined with real-time assistance/feedback in practice. 4",
                "cite_spans": [
                    {
                        "start": 283,
                        "end": 286,
                        "text": "[5,",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 287,
                        "end": 289,
                        "text": "8,",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 290,
                        "end": 293,
                        "text": "17,",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 294,
                        "end": 297,
                        "text": "18,",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 298,
                        "end": 301,
                        "text": "32,",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 302,
                        "end": 305,
                        "text": "49,",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 306,
                        "end": 309,
                        "text": "65]",
                        "ref_id": "BIBREF64"
                    },
                    {
                        "start": 339,
                        "end": 342,
                        "text": "[5]",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 503,
                        "end": 506,
                        "text": "[8]",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 659,
                        "end": 663,
                        "text": "[17]",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 850,
                        "end": 854,
                        "text": "[65]",
                        "ref_id": "BIBREF64"
                    },
                    {
                        "start": 963,
                        "end": 967,
                        "text": "[32]",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 1140,
                        "end": 1144,
                        "text": "[36,",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 1145,
                        "end": 1148,
                        "text": "38]",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 1286,
                        "end": 1289,
                        "text": "[4]",
                        "ref_id": "BIBREF3"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human interaction with explanations and models",
                "sec_num": null
            },
            {
                "text": "Deception is a ubiquitous phenomenon and has been studied in many disciplines [60] . In psychology, deception is defined as an act that is intended to foster in another person a belief or understanding which the deceiver considers false [31] . Computer scientists have been developing machine learning models to identify deception in texts, images, and videos [1, 15, 16, 24, 47, 48, 63, 66] . An important challenge in studying deception is to obtain groundtruth labels because it is well recognized that humans struggle at detecting deception [6] . Ott et al. [47] created the first sizable dataset in deception detection by employing workers on Amazon Mechanical Turk to write imagined experiences in hotels.",
                "cite_spans": [
                    {
                        "start": 78,
                        "end": 82,
                        "text": "[60]",
                        "ref_id": "BIBREF59"
                    },
                    {
                        "start": 237,
                        "end": 241,
                        "text": "[31]",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 360,
                        "end": 363,
                        "text": "[1,",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 364,
                        "end": 367,
                        "text": "15,",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 368,
                        "end": 371,
                        "text": "16,",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 372,
                        "end": 375,
                        "text": "24,",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 376,
                        "end": 379,
                        "text": "47,",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 380,
                        "end": 383,
                        "text": "48,",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 384,
                        "end": 387,
                        "text": "63,",
                        "ref_id": "BIBREF62"
                    },
                    {
                        "start": 388,
                        "end": 391,
                        "text": "66]",
                        "ref_id": "BIBREF65"
                    },
                    {
                        "start": 545,
                        "end": 548,
                        "text": "[6]",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 562,
                        "end": 566,
                        "text": "[47]",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Deception detection",
                "sec_num": null
            },
            {
                "text": "As people increasingly rely on information on the Internet (e.g., online reviews for making purchase decisions [10, 57, 64, 68] ), deceptive information also becomes prevalent [9, 45, 53] . The issue of misinformation and fake news has also attracted significant attention from both the public and the research community [14, 19, 35, 59, 67] . Our work employs the deceptive review detection task in Ott et al. [46, 47] to investigate the effectiveness of model-driven tutorials. While this task is a constrained case of deception and may differ from intentionally malicious deception, it represents an important issue that people face on a daily basis and can potentially benefit from assistance from ML models.",
                "cite_spans": [
                    {
                        "start": 111,
                        "end": 115,
                        "text": "[10,",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 116,
                        "end": 119,
                        "text": "57,",
                        "ref_id": "BIBREF56"
                    },
                    {
                        "start": 120,
                        "end": 123,
                        "text": "64,",
                        "ref_id": "BIBREF63"
                    },
                    {
                        "start": 124,
                        "end": 127,
                        "text": "68]",
                        "ref_id": "BIBREF67"
                    },
                    {
                        "start": 176,
                        "end": 179,
                        "text": "[9,",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 180,
                        "end": 183,
                        "text": "45,",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 184,
                        "end": 187,
                        "text": "53]",
                        "ref_id": "BIBREF52"
                    },
                    {
                        "start": 321,
                        "end": 325,
                        "text": "[14,",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 326,
                        "end": 329,
                        "text": "19,",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 330,
                        "end": 333,
                        "text": "35,",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 334,
                        "end": 337,
                        "text": "59,",
                        "ref_id": "BIBREF58"
                    },
                    {
                        "start": 338,
                        "end": 341,
                        "text": "67]",
                        "ref_id": "BIBREF66"
                    },
                    {
                        "start": 411,
                        "end": 415,
                        "text": "[46,",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 416,
                        "end": 419,
                        "text": "47]",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Deception detection",
                "sec_num": null
            },
            {
                "text": "In this section, we introduce the preliminaries for our prediction task, machine learning models, and explanation methods. We then develop tutorials to help humans understand the embedded patterns in the models in the training phase. Finally, we present types of real-time assistance in the prediction phase. A demo is available at https://deception.machineintheloop.com.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "METHODS",
                "sec_num": null
            },
            {
                "text": "Dataset and prediction task. We employ the deceptive review detection task developed by Ott et al. [46, 47] , consisting of 800 genuine and 800 deceptive hotel reviews for 20 hotels in Chicago. The genuine reviews were extracted from TripAdvisor and the deceptive ones were written by turkers who were asked to imagine their experience. We use 80% of the reviews as the training set and the remaining 20% as the test set. We evaluate human performance based on their accuracy on sampled reviews from the test set. The task for both humans and ML models is to determine whether a review is deceptive or genuine based on the text.",
                "cite_spans": [
                    {
                        "start": 99,
                        "end": 103,
                        "text": "[46,",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 104,
                        "end": 107,
                        "text": "47]",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset, models, and explanations",
                "sec_num": null
            },
            {
                "text": "Models. We consider a linear SVM classifier with unigram bag-of-words as features, which represents a simple model, and BERT [12] , which represents a deep learning model with state-of-the-art performance in many NLP tasks. The hyperparameter for linear SVM was selected via 5-fold cross validation with the training set; BERT was fine-tuned on 70% of the reviews and the other 10% of the reviews in the training set were used as the development set for selecting hyperparameters. Table 1 shows their accuracy on the test set. Methods of deriving explanations. We explain a machine prediction by highlighting the most important 10 words. For linear SVM, we use the absolute value of coefficients to determine feature importance, and the highlights are signed because coefficients are either positive or negative. For BERT, we consider two methods following Lai et al. [33] : 1) BERT attention based on the built-in mechanism of Transformer [58] (specifically, feature importance is calculated using the average attention values of 12 heads used by the first token at the final layer; these highlights are unsigned because attention values range between 0 and 1); 2) BERT LIME, where feature importance comes from LIME by fitting a sparse linear model to approximate local model predictions (these highlights are signed as they come from coefficients in a linear model).",
                "cite_spans": [
                    {
                        "start": 125,
                        "end": 129,
                        "text": "[12]",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 868,
                        "end": 872,
                        "text": "[33]",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 940,
                        "end": 944,
                        "text": "[58]",
                        "ref_id": "BIBREF57"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 487,
                        "end": 488,
                        "text": "1",
                        "ref_id": "TABREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Dataset, models, and explanations",
                "sec_num": null
            },
            {
                "text": "Our main innovation in this work is to introduce a training phase with model-driven tutorials before humans interact with ML models. We consider the following two types of tutorials.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "Guidelines. We follow the current practice of science communication and summarize findings in scientific papers [46, 47, 39] as a list of guidelines. These guidelines are observations derived from the ML model (see \"Fig. 1(c )\") and paraphrased by us. A \"Next\" button is enabled after a 30-second timer.",
                "cite_spans": [
                    {
                        "start": 112,
                        "end": 116,
                        "text": "[46,",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 117,
                        "end": 120,
                        "text": "47,",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 121,
                        "end": 124,
                        "text": "39]",
                        "ref_id": "BIBREF38"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 221,
                        "end": 224,
                        "text": "1(c",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "Example-driven tutorials. Inspired by Ribeiro et al. [50] , another way to give humans a global sense of a model is to present a sequence of examples along with predicted labels and explanations of predictions. For each example in our tutorial, informed by our in-person user study, we first ask participants to determine the label of the example, and then reveal the actual label and the predicted label along with explanations in the form of highlights. The algorithm selects 10 examples that are representative of the patterns that the ML model identifies from the training set. 5 There could be genuine insights as well as spurious patterns. Ideally, these examples allow participants to understand the problem at hand and then apply the patterns, including correcting spurious ones, in the prediction phase. Fig. 1 (a)&(b) presents an example review after the label is chosen and the predicted label and its explanations are shown.",
                "cite_spans": [
                    {
                        "start": 53,
                        "end": 57,
                        "text": "[50]",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 818,
                        "end": 819,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "A \"Continue\" button is enabled after a 10-second timer. See the supplementary material for screenshots.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "We consider the following algorithms for example selection:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "\u2022 Random. 10 random examples are chosen.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "\u2022 SP-LIME. Ribeiro et al. [50] propose SP-LIME to select examples with features that provide great coverage in the training set. To do that, the global importance of each feature is defined as",
                "cite_spans": [
                    {
                        "start": 26,
                        "end": 30,
                        "text": "[50]",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "I j = \u2211 n i=1 W i j ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "where W i j is the importance of feature j in the i-th instance. Since we only highlight the top 10 features, W i j = 0 for any other features. Then, 10 examples are selected to maximize the following objective function: argmax S,|S|\u2264B \u2211 d j=1 1(\u2203i \u2208 S : W i j > 0)I j , where B = 10 and d represents the dimension of features. This objective function presents a weighted coverage problem over all features, and is thus submodular. A greedy algorithm provides a solution with a constant-factor approximation guarantee of 1 -1/e to the optimum [30] .",
                "cite_spans": [
                    {
                        "start": 543,
                        "end": 547,
                        "text": "[30]",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "\u2022 Spaced repetition (SR). We propose this algorithm to leverage insights from the education literature regarding the effectiveness of spaced repetition (e.g., on long-term retention) [25, 55] . Specifically, we develop the following novel objective function so that users can be exposed to important features repeatedly",
                "cite_spans": [
                    {
                        "start": 183,
                        "end": 187,
                        "text": "[25,",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 188,
                        "end": 191,
                        "text": "55]",
                        "ref_id": "BIBREF54"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": ": argmax S,|S|\u2264B \u2211 d j=1 U({W k j } 1\u2264k\u2264|S| )I j , where U({w k j } 1\u2264k\u2264|S| ) = 1(max({k,W k j > 0}) -min({k,W k j > 0}) \u2265 3).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "The key difference from SP-LIME is that the weight of a feature is included only if it is repeated in two examples with a gap of at least three.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "Finally, we consider the combination of guidelines and examples selected with spaced repetition by first showing the guidelines for 15 seconds, 10 examples selected with spaced repetition, and the guidelines again for 15 seconds.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Tutorial generation",
                "sec_num": null
            },
            {
                "text": "In addition to tutorials in the training phase, we introduce varying levels of real-time assistance in the prediction phase. Inspired by Lai and Tan [34] , we design six levels of real-time assistance, as illustrated in Fig. 2 .",
                "cite_spans": [
                    {
                        "start": 149,
                        "end": 153,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 225,
                        "end": 226,
                        "text": "2",
                        "ref_id": "FIGREF29"
                    }
                ],
                "eq_spans": [],
                "section": "Real-time assistance",
                "sec_num": null
            },
            {
                "text": "Full human agency Full automation Figure 2 . An adapted spectrum between full human agency and full automation from Lai and Tan [32] . The order approximates our intuition, but the distance does not reflect linear changes in machine influence. In particular, guidelines do not necessarily increase the influence of predicted labels. \u2022 No machine assistance. Participants are not exposed to any real-time machine assistance. \u2022 Unsigned highlights. Top 10 features are highlighted in shades of blue. The darker the color, the more important the feature. See Fig. 3 for an example. \u2022 Signed highlights. Top 10 features are highlighted in shades of green and red: green words are associated with genuine reviews, while red words are associated with deceptive reviews. The darker the color, the more important the feature. See Fig. 1 (a) for an example. 6\u2022 Signed highlights + predicted label. In addition to signed highlights, we display the predicted label. \u2022 Signed highlights + predicted label + guidelines. We additionally provide the option of revealing guidelines. \u2022 Signed highlights + predicted label + guidelines + accuracy statement. We further add an accuracy statement, \"It has an accuracy of approximately 86%\", emphasizing the strong performance of the ML model.",
                "cite_spans": [
                    {
                        "start": 128,
                        "end": 132,
                        "text": "[32]",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 41,
                        "end": 42,
                        "text": "2",
                        "ref_id": "FIGREF29"
                    },
                    {
                        "start": 561,
                        "end": 562,
                        "text": "3",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 827,
                        "end": 828,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Signed explanations + predicted label + guidelines + accuracy statement",
                "sec_num": null
            },
            {
                "text": "These six levels gradually increase the amount of information and prime users towards machine predictions. Ideally, we hope to retain human agency as much as possible while achieving strong human performance.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Signed explanations + predicted label + guidelines + accuracy statement",
                "sec_num": null
            },
            {
                "text": "To obtain a qualitative understanding of human interaction with model-driven tutorials, we conduct an in-person semistructured user study. This user study allows us to gather in-depth insights on how humans learn and apply our tutorials through interviews, as well as feedback on the interface before conducting large-scale, randomized experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "IN-PERSON USER STUDY",
                "sec_num": null
            },
            {
                "text": "We employ a concurrent think-aloud process with participants [44] . Each participant went through a tutorial and determined the label of 20 reviews from the test set. They were told to verbalize the reason before deciding on the label both in the training and the prediction phase with the following syntax: I think the review is predicted label because reason. After the prediction phase, we conducted an interview to gather general feedback on tutorials. We manually transcribed the audio recordings after an initial pass with the Google Cloud API.",
                "cite_spans": [
                    {
                        "start": 61,
                        "end": 65,
                        "text": "[44]",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "A total of 16 participants were recruited from mailing lists in our department: 3 were female and 13 were male, ranging Thematic analysis was undertaken to identify common themes in participants' think-aloud processes. Thematic codes were collectively coded by the first two authors.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "We summarize the key themes into the following three parts.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Tutorial training and application. 8 out of 8 participants with access to guidelines remembered a couple of \"rules\" and applied them in the prediction phase. P13 said (the number is randomly assigned), \"I believe it is deceptive based on rule No. one and No. three, if I remembered them correctly, it just describes its experience, and does not have a lot of details\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "7 out of 12 participants exposed to selected examples adopted pure memorization or pattern-matching during the prediction phase. Participants remembered key deceptive words such as \"chicago\" to help them decide the review label: P2 said, \"My husband is deceptive, I is deceptive, Chicago is deceptive\". Some participants were even able to generate similar theories to our guidelines without exposure to it. P14 commented, \"The review didn't have anything specific to offer\" before deciding that the respective review was deceptive. However, reasoning about the patterns is generally challenging. Quoting from P2, this is mainly because they \"can't seem to find a rhyme or reason for those words being genuine or deceptive\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Participants also created theories such as length of review when predicting. P8 remarked, \"no one would take that much time to write a review so it won't cross more than 5 lines\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Improvements on tutorials. Participants thought that the guidelines should be available during the prediction phase to better assist them. 4 out of 4 participants felt that they were unable to remember as there were too many guidelines to be memorized. P11 felt that \"the tutorial is helpful but it's just hard not being able to reference it\" and P9 said that he could \"keep checking if it is on the top right corner\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "12 out of 12 participants exposed to selected examples expressed confusion about why the features were highlighted as deceptive or genuine but made up their own reasonings for ease of memory. They felt that they would have learned better if some form of explanations were given to justify each feature's indication. P16 remarked that \"it would be nice if it can let me know why exactly it thinks the word is deceptive\" and P10 commented that on top of the current explanations in selected examples, \"more detailed explanation would be helpful\" to help understand.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Improvements on the interface. We found that some participants thought that deceptive reviews are written by an AI without reading the instructions, which is false. We thus introduced three additional questions for our large-scale experiments: 1) how are deceptive reviews defined in this study?;",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "2) identify the color that highlights a word; 3) reiterate the training process and ask user to answer true or false to ensure that the participants know which treatment they are exposed to. We also changed the flow of showing explanations in the training phase: users need to first determine the label for a review before the explanations, the actual label, and the predicted label are shown for at least 10 seconds. Refer to the video and detailed feedback in the supplementary material.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "As introduced in the Methods section, we hope to build tutorials that can help humans understand the embedded patterns in ML models, which can sometimes be unsalient, unknown, or even counterintuitive to humans. Ideally, humans reflect on these patterns from our tutorials and can apply them in their decision making without any further real-time assistance from ML models. Therefore, we start with RQ1: do tutorials improve human performance without any real-time assistance?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "EXPERIMENT 1: DO TUTORIALS IMPROVE HUMAN PER-FORMANCE WITHOUT ANY REAL-TIME ASSISTANCE?",
                "sec_num": null
            },
            {
                "text": "We consider the following treatments to examine the effectiveness of various tutorials proposed in the Methods section: ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "To evaluate human performance under different experimental setups, participants were recruited via Amazon Mechanical Turk and filtered to include only individuals residing in the United States, with at least 50 Human Intelligence Tasks (HITs) completed and 99% of HITs approved. Each participant is randomly assigned to one of the six conditions (five types of tutorials + control). We did not allow any repeated participation. We adopted this between-subject design because exposure to any type of tutorial cannot be undone.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "In our experiment, each participant finishes the following steps sequentially: 1) reading an explanation of the task and a consent form; 2) answering a few attention-check questions depending on the experimental condition assigned; 3) undergoing a set of tutorials if applicable (training phase); 4) predicting the labels of 20 randomly selected reviews in the test set (prediction phase); 5) completing an exit survey. Participants who failed the attention-check questions are automatically disqualified from the study. Based on feedback from our in-person user study, for each example in the tutorials, a participant first chooses genuine or deceptive without any assistance, and then the answer is revealed and the predicted label and explanations are shown (Fig. 1 (a)&(b)). In the exit survey, participants were asked to report basic demographic information, if the tutorial was helpful (yes or no), and feedback in free responses. 8 Each participant was compensated $2.50 and an additional $0.05 bonus for each correctly labeled test review. 80 subjects were recruited for each condition so that each review in the test set was labeled five times. In total 480 subjects completed Experiment 1. They were balanced on gender (224 females, 251 males, and 5 preferred not to answer). Refer to the supplementary material for additional information about experiments (e.g., education background, time taken).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 767,
                        "end": 768,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "To quantify human performance, we measure it by the percentage of correctly labeled instances by humans. In other words, the prediction phase provides an estimate of human accuracy through 20 samples. In addition to this objective metric, we also report subject perception of tutorial usefulness reported in the exit surveys.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "We first present human accuracy in the prediction phase, an objective measurement of tutorial effectiveness. Our results 7 The anonymized pre-registration document is available at https: //aspredicted.org/blind.php?x=v8f7zh. A minor inconsistency is that we did not experiment with \"guidelines + examples selected from SP-LIME\" as we hypothesized that SR is better. 8 Feedback from Turkers generally confirmed findings in the inperson user study. See the supplementary material for an analysis. suggest that tutorials are useful to some extent: all tutorials lead to better human performance (\u223c60%) than the control setup without any training (Fig. 4 ). To formally compare the treatments, we conduct an one-way ANOVA and find a statistically significant effect (\u03b7 2 = 0.033; p = 7.70 \u00d7 10 -3 ). We further use post-hoc Tukey's HSD test to identify pairs of experimental conditions in which human performance exhibits significant differences. The only statistically significant differences are guidelines vs. control (p = 1.75 \u00d7 10 -2 ) and random vs. control (p = 7.0 \u00d7 10 -3 ) (the difference between guide-lines+SR and control is borderline significant with p = 0.10).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 649,
                        "end": 650,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "In other words, our experiment results provide partial support to H1a, and reject all other hypotheses in Experiment 1. These results suggest that although tutorials provide somewhat useful training, different tutorials are similarly effective. The limited improvement in human performance across all tutorials indicates that the utility of tutorials is small. We hypothesized that it is too challenging for humans to remember all the patterns after a short tutorial (supported by feedback from in-person user study), which motivated Experiment 2 to understand the effect of real-time assistance in conjunction with tutorials. Another contributing factor certainly lies in the design of tutorials, which we will further discuss in the Discussion section.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "As for subjective perception of tutorial usefulness, we find that participants generally find our tutorials useful: 73.8% of 400 participants reported that the tutorial was useful (ex-cluding 80 participants in the control setup). Fig. 5 shows the results by types of tutorials. Among different treatments, participants in guidelines and guidelines + examples selected with SR find the tutorials most useful, as high as 90% in guidelines + examples selected with SR. Formally, post-hoc Tukey's HSD test shows that the differences between the following pairs are statistically different: guidelines vs. random (p = 0.048), random vs. SR+guidelines (p < 0.001), and SR vs. SR+guidelines (p = 0.003). The difference between SP-LIME and SR+guidelines is borderline significant with p = 0.078. These results suggest that tutorials provide strong positive effects in humans' subjective perception.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 236,
                        "end": 237,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Our second experiment is concerned with human performance with varying levels of real-time assistance after going through the training phase. While Experiment 1 suggests that tutorials provide somewhat useful training, the improvement is limited without any real-time assistance. We hypothesize that human performance could be further improved by introducing realtime assistance. We adapt a spectrum with varying levels of real-time assistance from Lai and Tan [34] (Fig. 2 ). Moving along the spectrum, the influence of the machine generally becomes greater on the human as more information from the model is presented. For instance, a statement of strong machine performance is likely to bias humans towards machine predictions. Lai and Tan [34] find that there exists a tradeoff between human performance and human agency, i.e., as the real-time assistance gives stronger priming along the spectrum, human performance improves and human agency decreases. Explanations such as highlighting important words can moderate this tradeoff when predicated labels are given.",
                "cite_spans": [
                    {
                        "start": 461,
                        "end": 465,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 743,
                        "end": 747,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 472,
                        "end": 473,
                        "text": "2",
                        "ref_id": "FIGREF29"
                    }
                ],
                "eq_spans": [],
                "section": "EXPERIMENT 2: HUMAN PERFORMANCE WITH VARYING REAL-TIME ASSISTANCE AFTER TUTORIALS",
                "sec_num": null
            },
            {
                "text": "It remains an open question how this tradeoff unfolds after training.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "EXPERIMENT 2: HUMAN PERFORMANCE WITH VARYING REAL-TIME ASSISTANCE AFTER TUTORIALS",
                "sec_num": null
            },
            {
                "text": "All conditions in Experiment 2 used the guidelines + selected examples with spaced repetition tutorial in the training phase because all tutorials are similarly effective and our participants find this one most useful in subjective perception. To examine how humans perform under different levels of real-time assistance from machine learning models, we consider the spectrum in Fig. 2 , inspired by Lai and Tan [34] .",
                "cite_spans": [
                    {
                        "start": 412,
                        "end": 416,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 384,
                        "end": 385,
                        "text": "2",
                        "ref_id": "FIGREF29"
                    }
                ],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "We hypothesize that 1) real-time assistance results in improved human performance, since it has been shown that highlights and predicted labels improve human performance [34] ; 2) signed highlights result in better human performance compared to unsigned highlights because signed highlights reveal information about directionality; 3) predicted labels result in better human performance compared to highlights alone; 4) guidelines and signed highlights might moderate the tradeoff between human performance and human agency while achieving the same effect as when an accuracy statement is shown.",
                "cite_spans": [
                    {
                        "start": 170,
                        "end": 174,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "To summarize, our hypotheses are as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "\u2022 (H2a) Real-time assistance leads to better human performance than no assistance. \u2022 (H2b) Signed highlights lead to better human performance than unsigned highlights. \u2022 (H2c) Predicted label leads to better human performance than highlights alone. \u2022 (H2d) Signed highlights + predicted label + guidelines + accuracy statement leads to the best performance. \u2022 (H2e) Signed highlights + predicted label + guidelines and Signed highlights + predicted label perform as well as Signed highlights + predicted label + guidelines + accuracy statement.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "These five hypotheses were pre-registered on AsPredicted.9 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "We adopted the same experimental design as stated in Experiment 1 except that real-assistance is provided in the prediction phase when applicable. In total 480 subjects completed the experiment (80 participants in each type of real-time assistance). They were balanced on gender (238 females, 237 males, and 5",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "preferred not to answer). Refer to the supplementary material for additional information about experiments (e.g., education background, time taken).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "Human performance is measured by the percentage of correctly predicted instances by humans, which provides an objective measure of human performance with real-time assistance. We also consider the percentage of humans whose performance exceeds machine performance for the corresponding 20 reviews in the prediction phase.10 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "We first present human accuracy in the prediction phase. Our results suggest that real-time assistance is indeed effective: all the levels of real-time assistance except unsigned highlights lead to better human performance than the setup without machine assistance in Fig. 6 . To formally compare the treatments, we conduct an one-way ANOVA and find a statistically significant effect (\u03b7 2 = 0.23; p = 5.15 \u00d7 10 -25 ). We further use post-hoc Tukey's HSD test to identify pairs of experimental conditions in which human performance exhibits significant differences. With the exception of no assistance vs. unsigned highlights (p = 0.67), differences in remaining setups compared to no assistance are all statistically significant (p < 0.001). Moreover, the difference between unsigned highlights and signed highlights is significant (p < 0.001), demonstrating the effectiveness of signed highlights. Finally, the difference between signed highlights and any other realtime assistance with stronger priming (signed highlights + predicted labels, signed highlights + predicted labels + guidelines, signed highlights + predicted labels + guidelines + accuracy statement) is not significant.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 273,
                        "end": 274,
                        "text": "6",
                        "ref_id": "FIGREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "In summary, our experimental results support H2a with the exception of unsigned highlights, H2b, H2e, and reject H2c and H2d in Experiment 2 (note that signed highlights + predicted label + guidelines + accuracy statement indeed leads to the best performance but the difference with other methods is not always statistically significant). These results suggest that signed highlights provide sufficient information for improving human performance, and we do not gain much from presenting additional information with stronger priming. While there is significant improvement in human performance with real-time assistance (from \u223c60% to \u223c70%), the improvement is still limited compared to the machine performance, which is above 85%. This improvement is similar to results reported in Lai and Tan [34] , which did not use any tutorials other than minimal examples to introduce the task. These observations taken together suggest that the utility of our tutorials mainly lies in that humans can perform well with only signed highlights, a type of real-time assistance with relatively weak priming.",
                "cite_spans": [
                    {
                        "start": 794,
                        "end": 798,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Another ambitious measurement is how frequent humans outperform the ML model. It was rare in Experiment 1 (2 of 480, 0.4%). With effective real-time assistance (i.e., signed highlights included), we find that 26 of 320 (8.1%, 20 times the percentage in Experiment 1) of our participants are able to outperform the ML model. The difference between 8.1% and 0.4% is statistically significant using chi-squared tests (p < 0.001). This observation suggests that with the help of tutorial and real-time assistance, there exists hope for a synergy of humans and AI outperforming AI alone. We hypothesize that facilitating hypothesis generation is important and present detailed discussions in the Discussion section.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "Our experiments so far are based on explanations (coefficients) from a linear SVM classifier. Meanwhile, deep learning models are being widely adopted because of their superior predictive power. However, it is also increasingly recognized that they might be more complex and harder to interpret for humans. Our final experiment investigates how model complexity and methods of deriving explanations relate to human performance and effect of training.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "EXPERIMENT 3: THE EFFECT OF MODEL COMPLEXITY AND METHODS OF DERIVING EXPLANATIONS",
                "sec_num": null
            },
            {
                "text": "Participants are exposed to two different treatments: presence of training and methods of deriving highlights. Where training is present, we use the selected examples with spaced repetition tutorial in this experiment. Note that example selection depends on the model and the explanation method (i.e., which features are considered important). In comparison, guidelines are static and are extracted from papers based on linear SVM, so they are not appropriate here. Based on results from Experiment 2, we adopted signed highlights as our real-time assistance in the prediction phase when applicable. 11To summarize, we consider the following setups to examine how humans perform when exposed to training and different methods of deriving explanations: We hypothesize that 1) SVM results in better performance compared to BERT, since it is a common assumption that linear models are more interpretable and it has been shown that SVM results in important features with lower entropy [33] ;",
                "cite_spans": [
                    {
                        "start": 981,
                        "end": 985,
                        "text": "[33]",
                        "ref_id": "BIBREF32"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "2) BERT LIME results in better performance compared to BERT attention because signed highlights can reveal more information about the underlying decision; 3) participants would perform better with training than without training. To summarize, our hypotheses in Experiment 3 are as follows:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "\u2022 (H3a) The simple model (SVM) leads to better human performance than the deep learning model (BERT). \u2022 (H3b) BERT LIME leads to better human performance than BERT attention. \u2022 (H3c) Training leads to better human performance than without training. These three hypotheses were pre-registered on AsPredicted. 12",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental treatments & hypotheses",
                "sec_num": null
            },
            {
                "text": "We adopted the same experimental design as in Experiment 1. In total 480 subjects completed the experiment (80 participants in each experimental setup). They were balanced on gender (239 females, 240 males, and 1 preferred not to answer). Refer to the supplementary material for additional information about experiments (e.g., education background, time taken).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "To quantify human performance, we measure it by the percentage of correctly predicted instances by humans. In addition to this objective metric, we also report subject perception of tutorial usefulness reported in the exit surveys (note that this is only applicable for the experimental setups with training).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental design",
                "sec_num": null
            },
            {
                "text": "We first present human accuracy in the prediction phase. Our results suggest that methods of deriving explanations make a significant difference (Fig. 7 ): 1) human performance is consistently better when important words derived from the linear SVM are highlighted as compared to deep models; 2) BERT //aspredicted.org/blind.php?x=vy794a. LIME leads to better human performance than BERT attention. It also reinforces the point that training leads to better human performance as compared to no training: humans achieve better performance with training with any kind of explanation methods. To formally compare the treatments, we conduct a two-way ANOVA and find a statistically significant effect of tutorials (\u03b7 2 = 0.049; p = 1.50 \u00d7 10 -7 ) and methods of deriving explanations (\u03b7 2 = 0.13; p = 4.66 \u00d7 10 -16 ). Differences among all pairs of treatments are also statistically significant using post-hoc Tukey's HSD test (p < 0.001). 13In other words, our experiment results provide support to all hypotheses in Experiment 3. These results suggest that tutorials are indeed useful in improving human performance, albeit improvement is still limited in the sense that human performance is \u223c70% after training with real-time assistance, echoing results in Experiment 2. It also suggests that simple models are preferred to deep learning models when serving as explanations to support human decision making. Between explanations derived from post-hoc and built-in methods from BERT, attention provides the least value for humans, again demonstrating the importance of signed highlights.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 151,
                        "end": 152,
                        "text": "7",
                        "ref_id": "FIGREF6"
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "The effectiveness of training for simple models is further validated by subjective perception of tutorial usefulness. Fig. 8 shows that participants are much more likely to find the tutorials derived from SVM explanations useful: 85% of our participants find it useful. The differences between the follow-ing pairs are statistically different using post-hoc Tukey's HSD test: SVM vs. BERT attention (p < 0.001) and SVM vs. BERT LIME (p < 0.001). Interestingly, with real-time assistance, humans also find the tutorials more useful compared to the same tutorial in Fig. 5 . These results underscore our findings in Experiment 3 that simple models provide more interpretable tutorials and explanations than deep models.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 123,
                        "end": 124,
                        "text": "8",
                        "ref_id": "FIGREF7"
                    },
                    {
                        "start": 569,
                        "end": 570,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": null
            },
            {
                "text": "In this paper, we conduct the first large-scale, randomized, preregistered human-subject experiments to investigate whether model-driven tutorials can help humans understand the patterns embedded in ML models and improve human performance. We find that tutorials can indeed improve human performance to some extent, with and without real-time assistance, and humans also find them useful. Moreover, real-time assistance is crucial for further improving human performance in such challenging tasks. Finally, we show that simple models like linear SVM generate more useful tutorials and explanations for humans than complex deep learning models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "Towards human-centered tutorials. Both quantitative results from our randomized experiments and qualitative feedback from in-person user study demonstrate that humans can benefit from model-driven tutorials, which suggests that developing model-driven tutorials is a promising direction for future work in human-centered interpretable machine learning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "However, the improvement in human performance remains limited compared to machine performance in the deceptive review detection task. In order to further advance the synergy between humans and AI, we need to develop human-centered tutorials. Many participants commented that they could not understand why certain words were deceptive or genuine (an example reason could be that imaginative writing does not cover specific details). These results highlight the importance of facilitating hypothesis generation in the tutorials. It is insufficient to highlight important features via feature attribution methods, and these tutorials need to also explain why some features are useful. While it is challenging to develop automatic methods that can propose theories about particular features, we might prompt humans to propose theories and evaluate them through the ML model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "Another reason that tutorials had limited improvement in human performance is that the tutorials failed to establish proper trust in machine predictions. It is important to highlight both strengths and caveats of ML models in the tutorials, echoing recent work on understanding trust [32, 65] . A challenge lies in how to bridge the gap between training and generalization in tutorials, i.e., model behavior and performance in the tutorials might differ from that in unseen data.",
                "cite_spans": [
                    {
                        "start": 284,
                        "end": 288,
                        "text": "[32,",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 289,
                        "end": 292,
                        "text": "65]",
                        "ref_id": "BIBREF64"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "Beyond static explanations. Another important direction is to design interactive explanations beyond static explanations such as simply highlighting important words. Interactive explanations allow humans to experiment with their hypothesis about feature importance. One strategy is to enable humans to inquire about the importance of any word in a review. An alternative strategy is to assess model predictions of counterfactual examples. For instance, humans can remove or add words/sentences in a review, which can help humans understand model behavior in new scenarios.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "Choice of tasks. We would like to highlight the importance of task choice in understanding human-AI interaction. Deception detection might simply be too challenging a task for humans, and a short tutorial is insufficient to help humans understand the patterns embedded in ML models. There may also exist significant variation between understanding text and interpreting images, because the former depends on culture and life experience, while the latter relies on basic visual cognition.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "We believe that it is important to study human-AI interaction in challenging tasks where human agency is important because the nature of explanations in decision making is distinct from that in debugging. While machines excel at identifying patterns from existing datasets, humans might be able to complement ML models by deriving theories and appropriately correcting machine predictions in unseen data, e.g., spotting mistakes when machines apply patterns (\"chicago\" becomes a specific comparison point for reviews about a hotel in New York City). So there exists hope for further advancing human performance in these challenging tasks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "Limitation of our samples. Our study is limited by our samples of human subjects. The in-person user study was conducted with university students who tend to have a computer science education, and large-scale, randomized, pre-registered experiments were conducted with Mechanical Turkers from the United States. While our samples are likely to face the challenges of deception on the Internet and would benefit from enhancements in deception detection, they may not be representative of the general population. The effectiveness of model-driven tutorials can also potentially depend on properties of the sample population. In general, we did not find any consistent differences between demographic groups based on age, gender, education background, and review experience (see the supplementary material). It is certainly possible that other demographic information could affect the effectiveness of tutorials. We leave that for future studies.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "It is important to point out that our setup employs a random split to obtain training and testing data, which is a standard assumption in supervised machine learning. While humans can ideally improve generalization in this case, humans might be more likely to correct generalization errors in machine learning models when the testing distribution differs from training. In that case, understanding the embedded patterns, especially spotting spurious ones, can help humans generalize these data-driven insights.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "In summary, our work highlights the promise of (automatically) building model-driven tutorials to help humans understand the patterns embedded in ML models, especially in challenging tasks. We hope to encourage future work on human-centered tutorials and explanations beyond static realtime assistance towards a synergy between humans and AI.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "You can skip the screen shots of tutorial interfaces if you choose to watch the supplementary video. To help you skim the video, here are the starting time for each type of tutorials:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "\u2022 Guidelines: 00:08 Fig. 12 -Fig. 17 shows the prediction phase interfaces for experiment 2. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 25,
                        "end": 27,
                        "text": "12",
                        "ref_id": "FIGREF12"
                    },
                    {
                        "start": 34,
                        "end": 36,
                        "text": "17",
                        "ref_id": "FIGREF17"
                    }
                ],
                "eq_spans": [],
                "section": "DISCUSSION",
                "sec_num": null
            },
            {
                "text": "Among our participants in Experiment 1, 69 were between 18 and 25, 265 were between 26 and 40, 121 were between 41 and 60, 22 were 61 and above, and 3 preferred not to answer. They had a range of education backgrounds, comprising some high school (3), high school graduate (54) , some college credit (124), trade/technical/vocational training (42), Bachelor's degree and above (253), and 4 prefered not to answer.",
                "cite_spans": [
                    {
                        "start": 273,
                        "end": 277,
                        "text": "(54)",
                        "ref_id": "BIBREF53"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiment Details",
                "sec_num": null
            },
            {
                "text": "Among our participants in Experiment 2, 64 were between 18 and 25, 270 were between 26 and 40, 116 were between 41 and 60, 26 were 61 and above, and 4 preferred not to answer. They had a range of education backgrounds, comprising some high school (3), high school graduate (44) , some college credit (120), trade/technical/vocational training (32), Bachelor's degree and above (278), and 3 prefered not to answer.",
                "cite_spans": [
                    {
                        "start": 273,
                        "end": 277,
                        "text": "(44)",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiment Details",
                "sec_num": null
            },
            {
                "text": "Among our participants in Experiment 3, 62 were between 18 and 25, 255 were between 26 and 40, 138 were between 41 and 60, 24 were 61 and above, and 1 preferred not to answer. They had a range of educational attainment, comprising some high school (1), high school graduate (51) , some college credit (111), trade/technical/vocational training (40), Bachelor's degree and above (274), and 3 prefered not to answer.",
                "cite_spans": [
                    {
                        "start": 274,
                        "end": 278,
                        "text": "(51)",
                        "ref_id": "BIBREF50"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiment Details",
                "sec_num": null
            },
            {
                "text": "We only kept participants that complete the full task and submit a unique survey code. Participants that do not comply with the criteria were not included.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiment Details",
                "sec_num": null
            },
            {
                "text": "Fig. 21 -Fig. 23 show the average time taken in each experiment. We calculated and filtered out outliers from each experiment respectively with an interquartile range. In Fig. 24 -Fig. 26 we show the average time taken during prediction phase in each experiment. Outliers were discarded after the same precedures. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 5,
                        "end": 7,
                        "text": "21",
                        "ref_id": "FIGREF30"
                    },
                    {
                        "start": 14,
                        "end": 16,
                        "text": "23",
                        "ref_id": "FIGREF34"
                    },
                    {
                        "start": 176,
                        "end": 178,
                        "text": "24",
                        "ref_id": "FIGREF30"
                    },
                    {
                        "start": 185,
                        "end": 187,
                        "text": "26",
                        "ref_id": "FIGREF30"
                    }
                ],
                "eq_spans": [],
                "section": "Experiment Details",
                "sec_num": null
            },
            {
                "text": "Free responses from turkers confirmed the findings in the qualitative study. Participants felt that tutorial was useful but could not understand why certain features are deceptive or genuine. One participant commented, \"Although I am an English major, the training really helped me to think and consider the nuances of language. I enjoy good writing but I often overlook attempts to manipulate or deceive the reader/audience. I felt this training was very beneficial\". Another participant remarked, \"I could not understand why words were chosen for the reason\".",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Analysis of Free Responses from Turkers",
                "sec_num": null
            },
            {
                "text": "The is no clear trend regarding gender, education background, review writing frequency, and age among experiments. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "HUMAN PERFORMANCE GROUPED BY DEMOGRAPHICS",
                "sec_num": null
            },
            {
                "text": "P11 was half way through the session and commented, \"I'm trying to think about this from a way of, like, are these reviews being generated by a computer, or are they, like, are all of these reviews from real people, and am I trying to tell if somebody's, like, lying about the review\". The interviewer then suggested to the participant to read the instructions in the dialogue boxes. P11 subsequently explained that he \"just didn't notice that because I was just reading the rules and skipped the box\". Similarly, P9 asked the interviewer, \"By deceptive review do you mean users typing a review for the sake of tarnishing reputation, or uplifting reputation, or are you referring to computer-generated reviews which are trying to deceive people\". Due to a couple of the above cases, we added additional attention-check questions to ensure that participants are aware of the definition of deceptive reviews. Refer to the outdated and updated attention-check design below. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "ATTENTION-CHECK DESIGN",
                "sec_num": null
            },
            {
                "text": "As a corollary, it is usually considered overfitting the dataset when machine learning models outperform humans in these tasks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "It is worth noting that these two modes represent two ends of a continuum, e.g., emulating experts lead to discoveries for novices.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We only discuss qualitative differences from[34], as these are separate experiments subject to different randomization processes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Although feedback (e.g., true labels) on real decisions such as bail decisions can take a long time to observe.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We chose 10 so that an experiment session finishes within a reasonable amount of time (30 minutes), and all examples happened to be classified correctly by the model (since machine performance is even better on the training set).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We use an attention check question to make sure that participants can distinguish red from green.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The anonymized pre-registration document is available at http: //aspredicted.org/blind.php?x=fi8kz8.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "We also pre-registered trust as a measure and present the results in the supplementary material for space reasons.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Since BERT performs better than linear SVM, only showing signed highlights also avoids the potential effect of predicted labels.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The anonymized pre-registration document is available at http:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "It is reduced to t-test for the training/no training treatment since the degree of freedom is 1.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "Acknowledgments. We thank helpful comments from anonymous reviewers. All experiments were approved by the University of Colorado IRB . This work was supported in part by NSF grants IIS-1837986, 1849931, and 1927322. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "acknowledgement",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Deception detection using a multimodal approach",
                "authors": [
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Abouelenien",
                        "suffix": ""
                    },
                    {
                        "first": "Veronica",
                        "middle": [],
                        "last": "P\u00e9rez-Rosas",
                        "suffix": ""
                    },
                    {
                        "first": "Rada",
                        "middle": [],
                        "last": "Mihalcea",
                        "suffix": ""
                    },
                    {
                        "first": "Mihai",
                        "middle": [],
                        "last": "Burzo",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of ICMI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mohamed Abouelenien, Veronica P\u00e9rez-Rosas, Rada Mihalcea, and Mihai Burzo. 2014. Deception detection using a multimodal approach. In Proceedings of ICMI.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Social media and fake news in the 2016 election",
                "authors": [
                    {
                        "first": "Hunt",
                        "middle": [],
                        "last": "Allcott",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Gentzkow",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Journal of Economic Perspectives",
                "volume": "31",
                "issue": "",
                "pages": "211--236",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Hunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the 2016 election. Journal of Economic Perspectives 31, 2 (2017), 211-236.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Survey and critique of techniques for extracting rules from trained artificial neural networks",
                "authors": [
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Andrews",
                        "suffix": ""
                    },
                    {
                        "first": "Joachim",
                        "middle": [],
                        "last": "Diederich",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [
                            "B"
                        ],
                        "last": "Tickle",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Knowledge-based systems",
                "volume": "8",
                "issue": "",
                "pages": "373--389",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert Andrews, Joachim Diederich, and Alan B Tickle. 1995. Survey and critique of techniques for extracting rules from trained artificial neural networks. Knowledge-based systems 8, 6 (1995), 373-389.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Beyond Accuracy: The Role of Mental Models in Human-AI Team Performance",
                "authors": [
                    {
                        "first": "Gagan",
                        "middle": [],
                        "last": "Bansal",
                        "suffix": ""
                    },
                    {
                        "first": "Besmira",
                        "middle": [],
                        "last": "Nushi",
                        "suffix": ""
                    },
                    {
                        "first": "Ece",
                        "middle": [],
                        "last": "Kamar",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [
                            "S"
                        ],
                        "last": "Walter S Lasecki",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Weld",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Horvitz",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the AAAI Conference on Human Computation and Crowdsourcing",
                "volume": "7",
                "issue": "",
                "pages": "2--11",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Walter S Lasecki, Daniel S Weld, and Eric Horvitz. 2019. Beyond Accuracy: The Role of Mental Models in Human-AI Team Performance. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol. 7. 2-11.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "It's Reducing a Human Being to a Percentage': Perceptions of Justice in Algorithmic Decisions",
                "authors": [
                    {
                        "first": "Reuben",
                        "middle": [],
                        "last": "Binns",
                        "suffix": ""
                    },
                    {
                        "first": "Max",
                        "middle": [],
                        "last": "Van Kleek",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Veale",
                        "suffix": ""
                    },
                    {
                        "first": "Ulrik",
                        "middle": [],
                        "last": "Lyngs",
                        "suffix": ""
                    },
                    {
                        "first": "Jun",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Nigel",
                        "middle": [],
                        "last": "Shadbolt",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Reuben Binns, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. 'It's Reducing a Human Being to a Percentage': Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 377.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Accuracy of deception judgments",
                "authors": [
                    {
                        "first": "Charles F Bond",
                        "middle": [],
                        "last": "Jr",
                        "suffix": ""
                    },
                    {
                        "first": "Bella",
                        "middle": [
                            "M"
                        ],
                        "last": "Depaulo",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Personality and social psychology Review",
                "volume": "10",
                "issue": "3",
                "pages": "214--234",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Charles F Bond Jr and Bella M DePaulo. 2006. Accuracy of deception judgments. Personality and social psychology Review 10, 3 (2006), 214-234.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "The role of explanations on trust and reliance in clinical decision support systems",
                "authors": [
                    {
                        "first": "Adrian",
                        "middle": [],
                        "last": "Bussone",
                        "suffix": ""
                    },
                    {
                        "first": "Simone",
                        "middle": [],
                        "last": "Stumpf",
                        "suffix": ""
                    },
                    {
                        "first": "O'",
                        "middle": [],
                        "last": "Dympna",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Sullivan",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Healthcare Informatics (ICHI), 2015 International Conference on",
                "volume": "",
                "issue": "",
                "pages": "160--169",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adrian Bussone, Simone Stumpf, and Dympna O'Sullivan. 2015. The role of explanations on trust and reliance in clinical decision support systems. In Healthcare Informatics (ICHI), 2015 International Conference on. IEEE, 160-169.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Human-centered tools for coping with imperfect algorithms during medical decision-making",
                "authors": [
                    {
                        "first": "Carrie",
                        "middle": [
                            "J"
                        ],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Reif",
                        "suffix": ""
                    },
                    {
                        "first": "Narayan",
                        "middle": [],
                        "last": "Hegde",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Hipp",
                        "suffix": ""
                    },
                    {
                        "first": "Been",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Smilkov",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Wattenberg",
                        "suffix": ""
                    },
                    {
                        "first": "Fernanda",
                        "middle": [],
                        "last": "Viegas",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [
                            "S"
                        ],
                        "last": "Corrado",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [
                            "C"
                        ],
                        "last": "Stumpe",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Others",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Carrie J Cai, Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel Smilkov, Martin Wattenberg, Fernanda Viegas, Greg S Corrado, Martin C Stumpe, and others. 2019. Human-centered tools for coping with imperfect algorithms during medical decision-making. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 4.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Online deception: Prevalence, motivation, and emotion",
                "authors": [
                    {
                        "first": "Avner",
                        "middle": [],
                        "last": "Caspi",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Gorsky",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "CyberPsychology & Behavior",
                "volume": "9",
                "issue": "1",
                "pages": "54--59",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Avner Caspi and Paul Gorsky. 2006. Online deception: Prevalence, motivation, and emotion. CyberPsychology & Behavior 9, 1 (2006), 54-59.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "The effect of word of mouth on sales: Online book reviews",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Judith",
                        "suffix": ""
                    },
                    {
                        "first": "Dina",
                        "middle": [],
                        "last": "Chevalier",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mayzlin",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Journal of marketing research",
                "volume": "43",
                "issue": "3",
                "pages": "345--354",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Judith A Chevalier and Dina Mayzlin. 2006. The effect of word of mouth on sales: Online book reviews. Journal of marketing research 43, 3 (2006), 345-354.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Imagenet: A large-scale hierarchical image database",
                "authors": [
                    {
                        "first": "Jia",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Dong",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    },
                    {
                        "first": "Li-Jia",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Fei-Fei",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "248--255",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition. 248-255.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Devlin",
                        "suffix": ""
                    },
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Kenton",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of NAACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Towards a rigorous science of interpretable machine learning",
                "authors": [
                    {
                        "first": "Finale",
                        "middle": [],
                        "last": "Doshi",
                        "suffix": ""
                    },
                    {
                        "first": "-",
                        "middle": [],
                        "last": "Velez",
                        "suffix": ""
                    },
                    {
                        "first": "Been",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1702.08608"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608 (2017).",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Fake TV news: Widespread and undisclosed",
                "authors": [
                    {
                        "first": "Diane",
                        "middle": [],
                        "last": "Farsetta",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Price",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "Center for Media and Democracy",
                "volume": "6",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Diane Farsetta and Daniel Price. 2006. Fake TV news: Widespread and undisclosed. Center for Media and Democracy 6 (2006).",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Syntactic stylometry for deception detection",
                "authors": [
                    {
                        "first": "Song",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Ritwik",
                        "middle": [],
                        "last": "Banerjee",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Song Feng, Ritwik Banerjee, and Yejin Choi. 2012. Syntactic stylometry for deception detection. In Proceedings of ACL (short papers).",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Detecting deceptive opinions with profile compatibility",
                "authors": [
                    {
                        "first": "Vanessa",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Feng",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Graeme",
                        "middle": [],
                        "last": "Hirst",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of IJCNLP",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vanessa Wei Feng and Graeme Hirst. 2013. Detecting deceptive opinions with profile compatibility. In Proceedings of IJCNLP.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Disparate interactions: An algorithm-in-the-loop analysis of fairness in risk assessments",
                "authors": [
                    {
                        "first": "Ben",
                        "middle": [],
                        "last": "Green",
                        "suffix": ""
                    },
                    {
                        "first": "Yiling",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the Conference on Fairness, Accountability, and Transparency",
                "volume": "",
                "issue": "",
                "pages": "90--99",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ben Green and Yiling Chen. 2019a. Disparate interactions: An algorithm-in-the-loop analysis of fairness in risk assessments. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 90-99.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "2019b. The principles and limits of algorithm-in-the-loop decision making",
                "authors": [
                    {
                        "first": "Ben",
                        "middle": [],
                        "last": "Green",
                        "suffix": ""
                    },
                    {
                        "first": "Yiling",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the ACM on Human-Computer Interaction",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ben Green and Yiling Chen. 2019b. The principles and limits of algorithm-in-the-loop decision making. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 50.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Fake news on Twitter during the 2016 US presidential election",
                "authors": [
                    {
                        "first": "Nir",
                        "middle": [],
                        "last": "Grinberg",
                        "suffix": ""
                    },
                    {
                        "first": "Kenneth",
                        "middle": [],
                        "last": "Joseph",
                        "suffix": ""
                    },
                    {
                        "first": "Lisa",
                        "middle": [],
                        "last": "Friedland",
                        "suffix": ""
                    },
                    {
                        "first": "Briony",
                        "middle": [],
                        "last": "Swire-Thompson",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Lazer",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Science",
                "volume": "363",
                "issue": "",
                "pages": "374--378",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nir Grinberg, Kenneth Joseph, Lisa Friedland, Briony Swire-Thompson, and David Lazer. 2019. Fake news on Twitter during the 2016 US presidential election. Science 363, 6425 (2019), 374-378.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Local rule-based explanations of black box decision systems",
                "authors": [
                    {
                        "first": "Riccardo",
                        "middle": [],
                        "last": "Guidotti",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Monreale",
                        "suffix": ""
                    },
                    {
                        "first": "Salvatore",
                        "middle": [],
                        "last": "Ruggieri",
                        "suffix": ""
                    },
                    {
                        "first": "Dino",
                        "middle": [],
                        "last": "Pedreschi",
                        "suffix": ""
                    },
                    {
                        "first": "Franco",
                        "middle": [],
                        "last": "Turini",
                        "suffix": ""
                    },
                    {
                        "first": "Fosca",
                        "middle": [],
                        "last": "Giannotti",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1805.10820"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, and Fosca Giannotti. 2018. Local rule-based explanations of black box decision systems. arXiv preprint arXiv:1805.10820 (2018).",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "A survey of methods for explaining black box models",
                "authors": [
                    {
                        "first": "Riccardo",
                        "middle": [],
                        "last": "Guidotti",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Monreale",
                        "suffix": ""
                    },
                    {
                        "first": "Salvatore",
                        "middle": [],
                        "last": "Ruggieri",
                        "suffix": ""
                    },
                    {
                        "first": "Franco",
                        "middle": [],
                        "last": "Turini",
                        "suffix": ""
                    },
                    {
                        "first": "Fosca",
                        "middle": [],
                        "last": "Giannotti",
                        "suffix": ""
                    },
                    {
                        "first": "Dino",
                        "middle": [],
                        "last": "Pedreschi",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "ACM computing surveys (CSUR)",
                "volume": "51",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and Dino Pedreschi. 2019. A survey of methods for explaining black box models. ACM computing surveys (CSUR) 51, 5 (2019), 93.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
                "authors": [
                    {
                        "first": "Kaiming",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangyu",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of ICCV",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of ICCV.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Rating Reliability and Bias in News Articles: Does AI Assistance Help Everyone",
                "authors": [
                    {
                        "first": "Dorit",
                        "middle": [],
                        "last": "Benjamin D Horne",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Nevo",
                        "suffix": ""
                    },
                    {
                        "first": "O'",
                        "middle": [],
                        "last": "John",
                        "suffix": ""
                    },
                    {
                        "first": "Jin-Hee",
                        "middle": [],
                        "last": "Donovan",
                        "suffix": ""
                    },
                    {
                        "first": "Sibel",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Adali",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Benjamin D Horne, Dorit Nevo, John O'Donovan, Jin-Hee Cho, and Sibel Adali. 2019. Rating Reliability and Bias in News Articles: Does AI Assistance Help Everyone?. In Proceedings of ICWSM.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Opinion spam and analysis",
                "authors": [
                    {
                        "first": "Nitin",
                        "middle": [],
                        "last": "Jindal",
                        "suffix": ""
                    },
                    {
                        "first": "Bing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2008,
                "venue": "Proceedings of WSDM",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nitin Jindal and Bing Liu. 2008. Opinion spam and analysis. In Proceedings of WSDM.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Spaced repetition promotes efficient and effective learning: Policy implications for instruction",
                "authors": [
                    {
                        "first": "Sean Hk",
                        "middle": [],
                        "last": "Kang",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Policy Insights from the Behavioral and Brain Sciences",
                "volume": "3",
                "issue": "",
                "pages": "12--19",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sean HK Kang. 2016. Spaced repetition promotes efficient and effective learning: Policy implications for instruction. Policy Insights from the Behavioral and Brain Sciences 3, 1 (2016), 12-19.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Examples are not enough, learn to criticize! criticism for interpretability",
                "authors": [
                    {
                        "first": "Been",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Rajiv",
                        "middle": [],
                        "last": "Khanna",
                        "suffix": ""
                    },
                    {
                        "first": "Oluwasanmi",
                        "middle": [
                            "O"
                        ],
                        "last": "Koyejo",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of NIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Been Kim, Rajiv Khanna, and Oluwasanmi O Koyejo. 2016. Examples are not enough, learn to criticize! criticism for interpretability. In Proceedings of NIPS.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "The bayesian case model: A generative approach for case-based reasoning and prototype classification",
                "authors": [
                    {
                        "first": "Been",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Cynthia",
                        "middle": [],
                        "last": "Rudin",
                        "suffix": ""
                    },
                    {
                        "first": "Julie",
                        "middle": [
                            "A"
                        ],
                        "last": "Shah",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of NIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Been Kim, Cynthia Rudin, and Julie A Shah. 2014. The bayesian case model: A generative approach for case-based reasoning and prototype classification. In Proceedings of NIPS.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Human decisions and machine predictions",
                "authors": [
                    {
                        "first": "Jon",
                        "middle": [],
                        "last": "Kleinberg",
                        "suffix": ""
                    },
                    {
                        "first": "Himabindu",
                        "middle": [],
                        "last": "Lakkaraju",
                        "suffix": ""
                    },
                    {
                        "first": "Jure",
                        "middle": [],
                        "last": "Leskovec",
                        "suffix": ""
                    },
                    {
                        "first": "Jens",
                        "middle": [],
                        "last": "Ludwig",
                        "suffix": ""
                    },
                    {
                        "first": "Sendhil",
                        "middle": [],
                        "last": "Mullainathan",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "The Quarterly Journal of Economics",
                "volume": "133",
                "issue": "",
                "pages": "237--293",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. 2017. Human decisions and machine predictions. The Quarterly Journal of Economics 133, 1 (2017), 237-293.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Prediction policy problems",
                "authors": [
                    {
                        "first": "Jon",
                        "middle": [],
                        "last": "Kleinberg",
                        "suffix": ""
                    },
                    {
                        "first": "Jens",
                        "middle": [],
                        "last": "Ludwig",
                        "suffix": ""
                    },
                    {
                        "first": "Sendhil",
                        "middle": [],
                        "last": "Mullainathan",
                        "suffix": ""
                    },
                    {
                        "first": "Ziad",
                        "middle": [],
                        "last": "Obermeyer",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "American Economic Review",
                "volume": "105",
                "issue": "",
                "pages": "491--495",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. 2015. Prediction policy problems. American Economic Review 105, 5 (2015), 491-95.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Submodular function maximization",
                "authors": [
                    {
                        "first": "Andreas",
                        "middle": [],
                        "last": "Krause",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Golovin",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Andreas Krause and Daniel Golovin. 2014. Submodular function maximization. (2014).",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Modalities and cues in the detection of deception",
                "authors": [
                    {
                        "first": "Valerie",
                        "middle": [],
                        "last": "Robert M Krauss",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "Geller",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Olson",
                        "suffix": ""
                    }
                ],
                "year": 1976,
                "venue": "Meeting of the American Psychological Association",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robert M Krauss, Valerie Geller, and Christopher Olson. 1976. Modalities and cues in the detection of deception. In Meeting of the American Psychological Association, Washington, DC.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems",
                "authors": [
                    {
                        "first": "Johannes",
                        "middle": [],
                        "last": "Kunkel",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Donkers",
                        "suffix": ""
                    },
                    {
                        "first": "Lisa",
                        "middle": [],
                        "last": "Michael",
                        "suffix": ""
                    },
                    {
                        "first": "Catalin-Mihai",
                        "middle": [],
                        "last": "Barbu",
                        "suffix": ""
                    },
                    {
                        "first": "J\u00fcrgen",
                        "middle": [],
                        "last": "Ziegler",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Johannes Kunkel, Tim Donkers, Lisa Michael, Catalin-Mihai Barbu, and J\u00fcrgen Ziegler. 2019. Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 487.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Many Faces of Feature Importance: Comparing Built-in and Post-hoc Feature Importance in Text Classification. In Proceedings of EMNLP",
                "authors": [
                    {
                        "first": "Vivian",
                        "middle": [],
                        "last": "Lai",
                        "suffix": ""
                    },
                    {
                        "first": "Jon",
                        "middle": [
                            "Z"
                        ],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "Chenhao",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vivian Lai, Jon Z. Cai, and Chenhao Tan. 2019. Many Faces of Feature Importance: Comparing Built-in and Post-hoc Feature Importance in Text Classification. In Proceedings of EMNLP.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection",
                "authors": [
                    {
                        "first": "Vivian",
                        "middle": [],
                        "last": "Lai",
                        "suffix": ""
                    },
                    {
                        "first": "Chenhao",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of FAT*",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Vivian Lai and Chenhao Tan. 2019. On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection. In Proceedings of FAT*.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "The science of fake news",
                "authors": [
                    {
                        "first": "Matthew",
                        "middle": [
                            "A"
                        ],
                        "last": "David Mj Lazer",
                        "suffix": ""
                    },
                    {
                        "first": "Yochai",
                        "middle": [],
                        "last": "Baum",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [
                            "J"
                        ],
                        "last": "Benkler",
                        "suffix": ""
                    },
                    {
                        "first": "Kelly",
                        "middle": [
                            "M"
                        ],
                        "last": "Berinsky",
                        "suffix": ""
                    },
                    {
                        "first": "Filippo",
                        "middle": [],
                        "last": "Greenhill",
                        "suffix": ""
                    },
                    {
                        "first": "Miriam",
                        "middle": [
                            "J"
                        ],
                        "last": "Menczer",
                        "suffix": ""
                    },
                    {
                        "first": "Brendan",
                        "middle": [],
                        "last": "Metzger",
                        "suffix": ""
                    },
                    {
                        "first": "Gordon",
                        "middle": [],
                        "last": "Nyhan",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Pennycook",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Rothschild",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [
                            "A"
                        ],
                        "last": "Schudson",
                        "suffix": ""
                    },
                    {
                        "first": "Cass",
                        "middle": [
                            "R"
                        ],
                        "last": "Sloman",
                        "suffix": ""
                    },
                    {
                        "first": "Emily",
                        "middle": [
                            "A"
                        ],
                        "last": "Sunstein",
                        "suffix": ""
                    },
                    {
                        "first": "Duncan",
                        "middle": [
                            "J"
                        ],
                        "last": "Thorson",
                        "suffix": ""
                    },
                    {
                        "first": "Jonathan",
                        "middle": [
                            "L"
                        ],
                        "last": "Watts",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zittrain",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Science",
                "volume": "359",
                "issue": "",
                "pages": "1094--1096",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David MJ Lazer, Matthew A Baum, Yochai Benkler, Adam J Berinsky, Kelly M Greenhill, Filippo Menczer, Miriam J Metzger, Brendan Nyhan, Gordon Pennycook, David Rothschild, Michael Schudson, Steven A. Sloman, Cass R. Sunstein, Emily A. Thorson, Duncan J. Watts, and Jonathan L. Zittrain. 2018. The science of fake news. Science 359, 6380 (2018), 1094-1096.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Trust in automation: Designing for appropriate reliance",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "John",
                        "suffix": ""
                    },
                    {
                        "first": "Katrina",
                        "middle": [
                            "A"
                        ],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "See",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "Human factors",
                "volume": "46",
                "issue": "",
                "pages": "50--80",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "John D Lee and Katrina A See. 2004. Trust in automation: Designing for appropriate reliance. Human factors 46, 1 (2004), 50-80.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Rationalizing neural predictions",
                "authors": [
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Lei",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    },
                    {
                        "first": "Tommi",
                        "middle": [],
                        "last": "Jaakkola",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of EMNLP",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2016. Rationalizing neural predictions. Proceedings of EMNLP (2016).",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "The dynamics of trust: Comparing humans to automation",
                "authors": [
                    {
                        "first": "Stephan",
                        "middle": [],
                        "last": "Lewandowsky",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Mundy",
                        "suffix": ""
                    },
                    {
                        "first": "Gerard",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "Journal of Experimental Psychology: Applied",
                "volume": "6",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Stephan Lewandowsky, Michael Mundy, and Gerard Tan. 2000. The dynamics of trust: Comparing humans to automation. Journal of Experimental Psychology: Applied 6, 2 (2000), 104.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Towards a general rule for identifying deceptive opinion spam",
                "authors": [
                    {
                        "first": "Jiwei",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Cardie",
                        "suffix": ""
                    },
                    {
                        "first": "Eduard",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1566--1576",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jiwei Li, Myle Ott, Claire Cardie, and Eduard Hovy. 2014. Towards a general rule for identifying deceptive opinion spam. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1566-1576.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Sent to Prison by a Software Program's Secret Algorithms",
                "authors": [
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Liptak",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adam Liptak. 2017. Sent to Prison by a Software Program's Secret Algorithms. (2017).",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "The mythos of model interpretability",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zachary C Lipton",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1606.03490"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Zachary C Lipton. 2016. The mythos of model interpretability. arXiv preprint arXiv:1606.03490 (2016).",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "A unified approach to interpreting model predictions",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Scott",
                        "suffix": ""
                    },
                    {
                        "first": "Su-In",
                        "middle": [],
                        "last": "Lundberg",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of NIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting model predictions. In Proceedings of NIPS.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations",
                "authors": [
                    {
                        "first": "Ramaravind",
                        "middle": [],
                        "last": "Kommiya Mothilal",
                        "suffix": ""
                    },
                    {
                        "first": "Amit",
                        "middle": [],
                        "last": "Sharma",
                        "suffix": ""
                    },
                    {
                        "first": "Chenhao",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of FAT*",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ramaravind Kommiya Mothilal, Amit Sharma, and Chenhao Tan. 2020. Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations. In Proceedings of FAT*.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Getting access to what goes on in people's heads?: reflections on the think-aloud technique",
                "authors": [
                    {
                        "first": "Janni",
                        "middle": [],
                        "last": "Nielsen",
                        "suffix": ""
                    },
                    {
                        "first": "Torkil",
                        "middle": [],
                        "last": "Clemmensen",
                        "suffix": ""
                    },
                    {
                        "first": "Carsten",
                        "middle": [],
                        "last": "Yssing",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "Proceedings of the second Nordic conference on Human-computer interaction",
                "volume": "",
                "issue": "",
                "pages": "101--110",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Janni Nielsen, Torkil Clemmensen, and Carsten Yssing. 2002. Getting access to what goes on in people's heads?: reflections on the think-aloud technique. In Proceedings of the second Nordic conference on Human-computer interaction. ACM, 101-110.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "Estimating the prevalence of deception in online review communities",
                "authors": [
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Cardie",
                        "suffix": ""
                    },
                    {
                        "first": "Jeff",
                        "middle": [],
                        "last": "Hancock",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Proceedings of WWW",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Myle Ott, Claire Cardie, and Jeff Hancock. 2012. Estimating the prevalence of deception in online review communities. In Proceedings of WWW.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Negative deceptive opinion spam",
                "authors": [
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Cardie",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [
                            "T"
                        ],
                        "last": "Hancock",
                        "suffix": ""
                    }
                ],
                "year": 2013,
                "venue": "Proceedings of NAACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Myle Ott, Claire Cardie, and Jeffrey T Hancock. 2013. Negative deceptive opinion spam. In Proceedings of NAACL.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Finding deceptive opinion spam by any stretch of the imagination",
                "authors": [
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "Claire",
                        "middle": [],
                        "last": "Cardie",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [
                            "T"
                        ],
                        "last": "Hancock",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In Proceedings of ACL.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Verbal and nonverbal clues for real-life deception detection",
                "authors": [
                    {
                        "first": "Ver\u00f3nica",
                        "middle": [],
                        "last": "P\u00e9rez-Rosas",
                        "suffix": ""
                    },
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Abouelenien",
                        "suffix": ""
                    },
                    {
                        "first": "Rada",
                        "middle": [],
                        "last": "Mihalcea",
                        "suffix": ""
                    },
                    {
                        "first": "Yao",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Mihai",
                        "middle": [],
                        "last": "Cj Linton",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Burzo",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2336--2346",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ver\u00f3nica P\u00e9rez-Rosas, Mohamed Abouelenien, Rada Mihalcea, Yao Xiao, CJ Linton, and Mihai Burzo. 2015. Verbal and nonverbal clues for real-life deception detection. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2336-2346.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Manipulating and measuring model interpretability",
                "authors": [
                    {
                        "first": "Forough",
                        "middle": [],
                        "last": "Poursabzi-Sangdeh",
                        "suffix": ""
                    },
                    {
                        "first": "Jake",
                        "middle": [
                            "M"
                        ],
                        "last": "Daniel G Goldstein",
                        "suffix": ""
                    },
                    {
                        "first": "Jennifer",
                        "middle": [
                            "Wortman"
                        ],
                        "last": "Hofman",
                        "suffix": ""
                    },
                    {
                        "first": "Hanna",
                        "middle": [],
                        "last": "Vaughan",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Wallach",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1802.07810"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Forough Poursabzi-Sangdeh, Daniel G Goldstein, Jake M Hofman, Jennifer Wortman Vaughan, and Hanna Wallach. 2018. Manipulating and measuring model interpretability. arXiv preprint arXiv:1802.07810 (2018).",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Why should i trust you?: Explaining the predictions of any classifier",
                "authors": [
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Tulio Ribeiro",
                        "suffix": ""
                    },
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "Carlos",
                        "middle": [],
                        "last": "Guestrin",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of KDD",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of KDD.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "Anchors: High-Precision Model-Agnostic Explanations",
                "authors": [
                    {
                        "first": "Marco",
                        "middle": [],
                        "last": "Tulio Ribeiro",
                        "suffix": ""
                    },
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "Carlos",
                        "middle": [],
                        "last": "Guestrin",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of AAAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2018. Anchors: High-Precision Model-Agnostic Explanations. In Proceedings of AAAI.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Efficient Search for Diverse Coherent Explanations",
                "authors": [
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Russell",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of FAT*",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chris Russell. 2019. Efficient Search for Diverse Coherent Explanations. In Proceedings of FAT*.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "Prevalence and mitigation of forum spamming",
                "authors": [
                    {
                        "first": "Youngsang",
                        "middle": [],
                        "last": "Shin",
                        "suffix": ""
                    },
                    {
                        "first": "Minaxi",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "Steven",
                        "middle": [],
                        "last": "Myers",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Proceedings IEEE INFOCOM",
                "volume": "",
                "issue": "",
                "pages": "2309--2317",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Youngsang Shin, Minaxi Gupta, and Steven Myers. 2011. Prevalence and mitigation of forum spamming. In 2011 Proceedings IEEE INFOCOM. IEEE, 2309-2317.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "State of Wisconsin, Plaintiff-Respondent",
                "authors": [],
                "year": 2016,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Supreme Court of Wisconsin. 2016. State of Wisconsin, Plaintiff-Respondent, v. Eric L. Loomis, Defendant-Appellant. (2016).",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "Enhancing human learning via spaced repetition optimization",
                "authors": [
                    {
                        "first": "Utkarsh",
                        "middle": [],
                        "last": "Behzad Tabibian",
                        "suffix": ""
                    },
                    {
                        "first": "Abir",
                        "middle": [],
                        "last": "Upadhyay",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "De",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Zarezade",
                        "suffix": ""
                    },
                    {
                        "first": "Manuel",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Gomez-Rodriguez",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the National Academy of Sciences",
                "volume": "116",
                "issue": "",
                "pages": "3988--3993",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Behzad Tabibian, Utkarsh Upadhyay, Abir De, Ali Zarezade, Bernhard Sch\u00f6lkopf, and Manuel Gomez-Rodriguez. 2019. Enhancing human learning via spaced repetition optimization. Proceedings of the National Academy of Sciences 116, 10 (2019), 3988-3993.",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "b55",
                "title": "The effect of wording on message propagation: Topic-and author-controlled natural experiments on Twitter",
                "authors": [
                    {
                        "first": "Chenhao",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "Lillian",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "Proceedings of ACL",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chenhao Tan, Lillian Lee, and Bo Pang. 2014. The effect of wording on message propagation: Topic-and author-controlled natural experiments on Twitter. In Proceedings of ACL.",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "b56",
                "title": "Effects of word-of-mouth versus traditional marketing: findings from an internet social networking site",
                "authors": [
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Trusov",
                        "suffix": ""
                    },
                    {
                        "first": "Randolph",
                        "middle": [
                            "E"
                        ],
                        "last": "Bucklin",
                        "suffix": ""
                    },
                    {
                        "first": "Koen",
                        "middle": [],
                        "last": "Pauwels",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "Journal of marketing",
                "volume": "73",
                "issue": "",
                "pages": "90--102",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Michael Trusov, Randolph E Bucklin, and Koen Pauwels. 2009. Effects of word-of-mouth versus traditional marketing: findings from an internet social networking site. Journal of marketing 73, 5 (2009), 90-102.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "b57",
                "title": "Attention is all you need",
                "authors": [
                    {
                        "first": "Ashish",
                        "middle": [],
                        "last": "Vaswani",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Shazeer",
                        "suffix": ""
                    },
                    {
                        "first": "Niki",
                        "middle": [],
                        "last": "Parmar",
                        "suffix": ""
                    },
                    {
                        "first": "Jakob",
                        "middle": [],
                        "last": "Uszkoreit",
                        "suffix": ""
                    },
                    {
                        "first": "Llion",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Aidan",
                        "middle": [
                            "N"
                        ],
                        "last": "Gomez",
                        "suffix": ""
                    },
                    {
                        "first": "\u0141ukasz",
                        "middle": [],
                        "last": "Kaiser",
                        "suffix": ""
                    },
                    {
                        "first": "Illia",
                        "middle": [],
                        "last": "Polosukhin",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Proceedings of NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Proceedings of NeurIPS.",
                "links": null
            },
            "BIBREF58": {
                "ref_id": "b58",
                "title": "The spread of true and false news online",
                "authors": [
                    {
                        "first": "Soroush",
                        "middle": [],
                        "last": "Vosoughi",
                        "suffix": ""
                    },
                    {
                        "first": "Deb",
                        "middle": [],
                        "last": "Roy",
                        "suffix": ""
                    },
                    {
                        "first": "Sinan",
                        "middle": [],
                        "last": "Aral",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Science",
                "volume": "359",
                "issue": "",
                "pages": "1146--1151",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science 359, 6380 (2018), 1146-1151.",
                "links": null
            },
            "BIBREF59": {
                "ref_id": "b59",
                "title": "Detecting lies and deceit: The psychology of lying and implications for professional practice",
                "authors": [
                    {
                        "first": "Aldert",
                        "middle": [],
                        "last": "Vrij",
                        "suffix": ""
                    }
                ],
                "year": 2000,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Aldert Vrij. 2000. Detecting lies and deceit: The psychology of lying and implications for professional practice. Wiley.",
                "links": null
            },
            "BIBREF60": {
                "ref_id": "b60",
                "title": "Counterfactual explanations without opening the black box: Automated decisions and the GDPR",
                "authors": [
                    {
                        "first": "Sandra",
                        "middle": [],
                        "last": "Wachter",
                        "suffix": ""
                    },
                    {
                        "first": "Brent",
                        "middle": [],
                        "last": "Mittelstadt",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Russell",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sandra Wachter, Brent Mittelstadt, and Chris Russell. 2017. Counterfactual explanations without opening the black box: Automated decisions and the GDPR.",
                "links": null
            },
            "BIBREF61": {
                "ref_id": "b61",
                "title": "A Human-Grounded Evaluation of SHAP for Alert Processing",
                "authors": [
                    {
                        "first": "J",
                        "middle": [
                            "P"
                        ],
                        "last": "Hilde",
                        "suffix": ""
                    },
                    {
                        "first": "Werner",
                        "middle": [],
                        "last": "Weerts",
                        "suffix": ""
                    },
                    {
                        "first": "Mykola",
                        "middle": [],
                        "last": "Van Ipenburg",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Pechenizkiy",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1907.03324"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Hilde JP Weerts, Werner van Ipenburg, and Mykola Pechenizkiy. 2019. A Human-Grounded Evaluation of SHAP for Alert Processing. arXiv preprint arXiv:1907.03324 (2019).",
                "links": null
            },
            "BIBREF62": {
                "ref_id": "b62",
                "title": "Distortion as a validation criterion in the identification of suspicious reviews",
                "authors": [
                    {
                        "first": "Guangyu",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Derek",
                        "middle": [],
                        "last": "Greene",
                        "suffix": ""
                    },
                    {
                        "first": "Barry",
                        "middle": [],
                        "last": "Smyth",
                        "suffix": ""
                    },
                    {
                        "first": "P\u00e1draig",
                        "middle": [],
                        "last": "Cunningham",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Proceedings of the First Workshop on Social Media Analytics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Guangyu Wu, Derek Greene, Barry Smyth, and P\u00e1draig Cunningham. 2010. Distortion as a validation criterion in the identification of suspicious reviews. In Proceedings of the First Workshop on Social Media Analytics.",
                "links": null
            },
            "BIBREF63": {
                "ref_id": "b63",
                "title": "The influence of user-generated content on traveler behavior: An empirical investigation on the effects of e-word-of-mouth to hotel online bookings",
                "authors": [
                    {
                        "first": "Qiang",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "Rob",
                        "middle": [],
                        "last": "Law",
                        "suffix": ""
                    },
                    {
                        "first": "Bin",
                        "middle": [],
                        "last": "Gu",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Computers in Human behavior",
                "volume": "27",
                "issue": "",
                "pages": "634--639",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qiang Ye, Rob Law, Bin Gu, and Wei Chen. 2011. The influence of user-generated content on traveler behavior: An empirical investigation on the effects of e-word-of-mouth to hotel online bookings. Computers in Human behavior 27, 2 (2011), 634-639.",
                "links": null
            },
            "BIBREF64": {
                "ref_id": "b64",
                "title": "Understanding the Effect of Accuracy on Trust in Machine Learning Models",
                "authors": [
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Yin",
                        "suffix": ""
                    },
                    {
                        "first": "Jennifer",
                        "middle": [
                            "Wortman"
                        ],
                        "last": "Vaughan",
                        "suffix": ""
                    },
                    {
                        "first": "Hanna",
                        "middle": [],
                        "last": "Wallach",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ming Yin, Jennifer Wortman Vaughan, and Hanna Wallach. 2019. Understanding the Effect of Accuracy on Trust in Machine Learning Models. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 279.",
                "links": null
            },
            "BIBREF65": {
                "ref_id": "b65",
                "title": "Comparison of deceptive and truthful travel reviews. Information and communication technologies in tourism",
                "authors": [
                    {
                        "first": "Kyung-Hyan",
                        "middle": [],
                        "last": "Yoo",
                        "suffix": ""
                    },
                    {
                        "first": "Ulrike",
                        "middle": [],
                        "last": "Gretzel",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "37--47",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kyung-Hyan Yoo and Ulrike Gretzel. 2009. Comparison of deceptive and truthful travel reviews. Information and communication technologies in tourism 2009 (2009), 37-47.",
                "links": null
            },
            "BIBREF66": {
                "ref_id": "b66",
                "title": "A Structured Response to Misinformation: Defining and Annotating Credibility Indicators in News Articles",
                "authors": [
                    {
                        "first": "Amy",
                        "middle": [
                            "X"
                        ],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Aditya",
                        "middle": [],
                        "last": "Ranganathan",
                        "suffix": ""
                    },
                    {
                        "first": "Sarah",
                        "middle": [
                            "Emlen"
                        ],
                        "last": "Metz",
                        "suffix": ""
                    },
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Appling",
                        "suffix": ""
                    },
                    {
                        "first": "Connie",
                        "middle": [
                            "Moon"
                        ],
                        "last": "Sehat",
                        "suffix": ""
                    },
                    {
                        "first": "Norman",
                        "middle": [],
                        "last": "Gilmore",
                        "suffix": ""
                    },
                    {
                        "first": "Nick",
                        "middle": [
                            "B"
                        ],
                        "last": "Adams",
                        "suffix": ""
                    },
                    {
                        "first": "Emmanuel",
                        "middle": [],
                        "last": "Vincent",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Robbins",
                        "suffix": ""
                    },
                    {
                        "first": "Ed",
                        "middle": [],
                        "last": "Bice",
                        "suffix": ""
                    },
                    {
                        "first": "Sandro",
                        "middle": [],
                        "last": "Hawke",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Karger",
                        "suffix": ""
                    },
                    {
                        "first": "An",
                        "middle": [
                            "Xiao"
                        ],
                        "last": "Mina",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of WWW (Companion)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Amy X Zhang, Aditya Ranganathan, Sarah Emlen Metz, Scott Appling, Connie Moon Sehat, Norman Gilmore, Nick B Adams, Emmanuel Vincent, Martin Robbins, Ed Bice, Sandro Hawke, David Karger, and An Xiao Mina. 2018. A Structured Response to Misinformation: Defining and Annotating Credibility Indicators in News Articles. In Proceedings of WWW (Companion).",
                "links": null
            },
            "BIBREF67": {
                "ref_id": "b67",
                "title": "The impact of e-word-of-mouth on the online popularity of restaurants: A comparison of consumer reviews and editor reviews",
                "authors": [
                    {
                        "first": "Ziqiong",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Qiang",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "Rob",
                        "middle": [],
                        "last": "Law",
                        "suffix": ""
                    },
                    {
                        "first": "Yijun",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "International Journal of Hospitality Management",
                "volume": "29",
                "issue": "",
                "pages": "694--700",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ziqiong Zhang, Qiang Ye, Rob Law, and Yijun Li. 2010. The impact of e-word-of-mouth on the online popularity of restaurants: A comparison of consumer reviews and editor reviews. International Journal of Hospitality Management 29, 4 (2010), 694-700.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "fig_num": "1",
                "num": null,
                "uris": null,
                "text": "Figure 1. Illustration of example-driven tutorials and guidelines shown to participants during the training phase: a) top 10 features of the review text are highlighted in green and red (signed highlights), where green words are associated with genuine reviews and red words are associated with deceptive reviews; b) participants are presented the actual label, the predicted label, and textual explanations for a review after choosing the label of the review in example-driven tutorials; c) a list of guidelines for identifying deceptive reviews extracted from scientific papers.",
                "type_str": "figure"
            },
            "FIGREF1": {
                "fig_num": "3",
                "num": null,
                "uris": null,
                "text": "Figure 3. Unsigned highlights for the example review in Fig. 1(a).",
                "type_str": "figure"
            },
            "FIGREF2": {
                "fig_num": null,
                "num": null,
                "uris": null,
                "text": "between age 20 and 35. All participants were engineering graduate students and most of them studied computer science. Participants were invited to the lab where the study occurred. Either a personal or a provided laptop was used. Participants were compensated between $15 and $20 for $10 every 30 minutes. Four types of tutorials (guidelines, examples selected with SP-LIME, examples selected with SR, guidelines + examples selected with SR) were randomly assigned to participants and each tutorial type had a sample size of 4.",
                "type_str": "figure"
            },
            "FIGREF4": {
                "fig_num": "45",
                "num": null,
                "uris": null,
                "text": "Figure 4. Human accuracy without any real-time assistance after different types of tutorials. Error bars represent standard errors. Human accuracy after tutorials is always better than that without any training. Differences are statistically significant between random and control, and guidelines and control based on post-hoc Tukey's HSD test.",
                "type_str": "figure"
            },
            "FIGREF5": {
                "fig_num": "6",
                "num": null,
                "uris": null,
                "text": "Figure 6. Human accuracy with varying levels of real-time assistance after training. Error bars represent standard errors. With the exception of unsigned highlights, human accuracy with real-time assistance is better than without real-time assistance. Differences between no assistance and any assistance with signed highlights are statistically significant based on post-hoc Tukey's HSD test.",
                "type_str": "figure"
            },
            "FIGREF6": {
                "fig_num": "7",
                "num": null,
                "uris": null,
                "text": "Figure 7. Human accuracy grouped by methods of deriving explanations. Error bars represent standard errors. SVM explanations lead to better human performance than explanations based on BERT. Training (second bar from the top in each method) also consistently improves human performance for all explanation methods.",
                "type_str": "figure"
            },
            "FIGREF7": {
                "fig_num": "8",
                "num": null,
                "uris": null,
                "text": "Figure 8. Human perception of tutorial usefulness. Error bars represent standard errors. Participants are more likely to find SVM tutorials useful (differences between (SVM, BERT attention) and (SVM, BERT LIME) are statistically significant using post-hoc Tukey's HSD test).",
                "type_str": "figure"
            },
            "FIGREF8": {
                "fig_num": "9",
                "num": null,
                "uris": null,
                "text": "Fig. 9 -Fig. 11 shows tutorial interfaces for Experiment 1.",
                "type_str": "figure"
            },
            "FIGREF9": {
                "fig_num": "9",
                "num": null,
                "uris": null,
                "text": "Figure 9. Experiment 1 tutorial: guidelines.",
                "type_str": "figure"
            },
            "FIGREF10": {
                "fig_num": "10",
                "num": null,
                "uris": null,
                "text": "Figure 10. Experiment 1 tutorial: selected examples. Selected examples of random, SP-LIME, and SR are captured in video submission.",
                "type_str": "figure"
            },
            "FIGREF11": {
                "fig_num": "11",
                "num": null,
                "uris": null,
                "text": "Figure 11. Experiment 1 tutorial: selected examples + guidelines. 'Reveal guidelines' shows a list of as illustrated in Fig. 9.",
                "type_str": "figure"
            },
            "FIGREF12": {
                "fig_num": "12",
                "num": null,
                "uris": null,
                "text": "Figure 12. Experiment 2 real-time assistance: no assistance.",
                "type_str": "figure"
            },
            "FIGREF13": {
                "fig_num": "13",
                "num": null,
                "uris": null,
                "text": "Figure 13. Experiment 2 real-time assistance: unsigned highlights.",
                "type_str": "figure"
            },
            "FIGREF14": {
                "fig_num": "14",
                "num": null,
                "uris": null,
                "text": "Figure 14. Experiment 2 real-time assistance: signed highlights.",
                "type_str": "figure"
            },
            "FIGREF15": {
                "fig_num": "15",
                "num": null,
                "uris": null,
                "text": "Figure 15. Experiment 2 real-time assistance: signed highlights + predicted label.",
                "type_str": "figure"
            },
            "FIGREF16": {
                "fig_num": "16",
                "num": null,
                "uris": null,
                "text": "Figure 16. Experiment 2 real-time assistance: signed highlights + predicted label + guidelines.",
                "type_str": "figure"
            },
            "FIGREF17": {
                "fig_num": "17",
                "num": null,
                "uris": null,
                "text": "Figure 17. Experiment 2 real-time assistance: signed highlights + predicted label + guidelines + accuracy statement.",
                "type_str": "figure"
            },
            "FIGREF18": {
                "fig_num": "18",
                "num": null,
                "uris": null,
                "text": "Fig. 18 -Fig. 20 shows examples in different methods deriving explanations for experiment 3.",
                "type_str": "figure"
            },
            "FIGREF19": {
                "fig_num": "18",
                "num": null,
                "uris": null,
                "text": "Figure 18. Experiment 3: top features from SVM are highlighted.",
                "type_str": "figure"
            },
            "FIGREF20": {
                "fig_num": "19",
                "num": null,
                "uris": null,
                "text": "Figure 19. Experiment 3: top features from BERT attention are highlighted.",
                "type_str": "figure"
            },
            "FIGREF21": {
                "fig_num": "20",
                "num": null,
                "uris": null,
                "text": "Figure 20. Experiment 3: top features from BERT LIME are highlighted.",
                "type_str": "figure"
            },
            "FIGREF22": {
                "fig_num": "212223",
                "num": null,
                "uris": null,
                "text": "Figure 21. Average time taken for each experimental setup in experiment 1.",
                "type_str": "figure"
            },
            "FIGREF23": {
                "fig_num": "242526",
                "num": null,
                "uris": null,
                "text": "Figure 24. Average time taken for the prediction phase in each experimental setup in experiment 1.",
                "type_str": "figure"
            },
            "FIGREF24": {
                "fig_num": null,
                "num": null,
                "uris": null,
                "text": "Figure Experiment 1: gender. Human accuracy grouped by experimental setups and gender.",
                "type_str": "figure"
            },
            "FIGREF25": {
                "fig_num": "30",
                "num": null,
                "uris": null,
                "text": "Figure 30. Experiment 1: age. Human accuracy grouped by experimental setups and age.",
                "type_str": "figure"
            },
            "FIGREF26": {
                "fig_num": "31",
                "num": null,
                "uris": null,
                "text": "Figure 31. Experiment 1: education background. Human accuracy grouped by experimental setups and education background.",
                "type_str": "figure"
            },
            "FIGREF27": {
                "fig_num": "32",
                "num": null,
                "uris": null,
                "text": "Figure 32. Experiment 1: review writing frequency. Human accuracy grouped by experimental setups and review writing frequency.",
                "type_str": "figure"
            },
            "FIGREF28": {
                "fig_num": "33",
                "num": null,
                "uris": null,
                "text": "Figure 33. Experiment 2: gender. Human accuracy grouped by experimental setups and gender.",
                "type_str": "figure"
            },
            "FIGREF29": {
                "fig_num": "2",
                "num": null,
                "uris": null,
                "text": "Figure Experiment 2: age. Human accuracy grouped by experimental setups and age.",
                "type_str": "figure"
            },
            "FIGREF30": {
                "fig_num": "2",
                "num": null,
                "uris": null,
                "text": "Figure Experiment 2: education background. Human accuracy grouped by experimental setups and education background.",
                "type_str": "figure"
            },
            "FIGREF31": {
                "fig_num": "36",
                "num": null,
                "uris": null,
                "text": "Figure 36. Experiment 2: review writing frequency. Human accuracy grouped by experimental setups and review writing frequency.",
                "type_str": "figure"
            },
            "FIGREF32": {
                "fig_num": "37",
                "num": null,
                "uris": null,
                "text": "Figure 37. Experiment 3: gender. Human accuracy grouped by experimental setups and gender.",
                "type_str": "figure"
            },
            "FIGREF33": {
                "fig_num": null,
                "num": null,
                "uris": null,
                "text": "Figure Experiment 3: age. Human accuracy grouped by experimental setups and age.",
                "type_str": "figure"
            },
            "FIGREF34": {
                "fig_num": "3",
                "num": null,
                "uris": null,
                "text": "Figure Experiment 3: education background. Human accuracy grouped by experimental setups and education background.",
                "type_str": "figure"
            },
            "FIGREF35": {
                "fig_num": "40",
                "num": null,
                "uris": null,
                "text": "Figure 40. Experiment 3: review writing frequency. Human accuracy grouped by experimental setups and review writing frequency.",
                "type_str": "figure"
            },
            "FIGREF36": {
                "fig_num": "41",
                "num": null,
                "uris": null,
                "text": "Figure 41. Outdated attention-check design. The outdated design does not allow participants to confirm on their answers. If they selected the wrong answer, they will be disqualified immediately.",
                "type_str": "figure"
            },
            "FIGREF37": {
                "fig_num": "42",
                "num": null,
                "uris": null,
                "text": "Figure 42. Updated attention-check design. The updated design allows participants to confirm on their answers.",
                "type_str": "figure"
            },
            "FIGREF38": {
                "fig_num": "47",
                "num": null,
                "uris": null,
                "text": "Fig. 47 and Fig. 48 show exit surveys for experimental setups in Experiment 3.",
                "type_str": "figure"
            },
            "FIGREF39": {
                "fig_num": "43",
                "num": null,
                "uris": null,
                "text": "Figure 43. Exit survey for control setup in Experiment 1.",
                "type_str": "figure"
            },
            "FIGREF40": {
                "fig_num": "44",
                "num": null,
                "uris": null,
                "text": "Figure 44. Exit survey for guidelines setup in Experiment 1.",
                "type_str": "figure"
            },
            "FIGREF41": {
                "fig_num": "45",
                "num": null,
                "uris": null,
                "text": "Figure 45. Exit survey for examples i.e., random, SP-LIME, and spaced repetition in experiment 1. Note that question 7a changes to the following: 'Was training (i.e. training reviews and list of guidelines) useful?' for SR+guidelines.",
                "type_str": "figure"
            },
            "FIGREF42": {
                "fig_num": "46",
                "num": null,
                "uris": null,
                "text": "Figure 46. Exit survey for experimental setup in Experiment 2.",
                "type_str": "figure"
            },
            "FIGREF43": {
                "fig_num": "47",
                "num": null,
                "uris": null,
                "text": "Figure 47. Exit survey for non-training experimental setups in Experiment 3.",
                "type_str": "figure"
            },
            "FIGREF44": {
                "fig_num": "48",
                "num": null,
                "uris": null,
                "text": "Figure 48. Exit survey for training experimental setups in Experiment 3.",
                "type_str": "figure"
            },
            "TABREF0": {
                "num": null,
                "content": "<table><tr><td>Model</td><td>Accuracy (%)</td></tr><tr><td>SVM</td><td>86.3</td></tr><tr><td>BERT</td><td>90.9</td></tr></table>",
                "text": "Accuracy of machine learning models on the test set.",
                "html": null,
                "type_str": "table"
            },
            "TABREF1": {
                "num": null,
                "content": "<table><tr><td>We hypothesize that 1) training is important for humans to</td></tr><tr><td>understand this task, since it has been shown that humans</td></tr><tr><td>struggle with deception detection [6]; 2) it would be easier for</td></tr><tr><td>participants to understand the patterns embedded in the ML</td></tr><tr><td>model situated with examples; 3) carefully chosen examples</td></tr><tr><td>provide more comprehensive coverage and can better familiar-</td></tr><tr><td>ize participants with the patterns [25, 55]; 4) guidelines and</td></tr><tr><td>examples have complementary effects in the training phase.</td></tr><tr><td>To summarize, our hypotheses in Experiment 1 are as follows:</td></tr></table>",
                "text": "Selected examples (with SP-LIME or SR) lead to better human performance than random examples. \u2022 (H1d) Examples selected with spaced repetition lead to better human performance those selected with SP-LIME. \u2022 (H1e) Guidelines + examples selected with SR lead to the best performance.These five hypotheses were pre-registered on AsPredicted.7",
                "html": null,
                "type_str": "table"
            },
            "TABREF4": {
                "num": null,
                "content": "<table><tr><td/><td/><td colspan=\"2\">Trust on correct/incorrect predictions</td><td/><td/></tr><tr><td/><td/><td/><td/><td>77.5</td><td/></tr><tr><td>Signed + predicted label</td><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td>61.1</td><td/><td/></tr><tr><td>Signed + predicted label</td><td/><td/><td colspan=\"2\">76.4</td><td/></tr><tr><td>+ guidelines</td><td/><td/><td>65.8</td><td/><td/></tr><tr><td>Signed + predicted label</td><td/><td/><td/><td>80.7</td><td/></tr><tr><td>+ guidelines + accuracy</td><td/><td/><td colspan=\"2\">70.5</td><td>Correct</td></tr><tr><td/><td/><td/><td/><td/><td>Incorrect</td></tr><tr><td>0</td><td>20</td><td>40</td><td>60</td><td>80</td><td>100</td></tr><tr><td/><td/><td>Trust(%)</td><td/><td/><td/></tr><tr><td colspan=\"6\">Figure 28. Human trust on correct / incorrect machine predictions in ex-</td></tr><tr><td colspan=\"6\">periment 2. Differences between correct predictions and incorrect pre-</td></tr><tr><td colspan=\"6\">dictions are statistically significant. These results suggest that human</td></tr><tr><td colspan=\"6\">have more trust in correct predictions than incorrect ones.</td></tr><tr><td/><td/><td/><td/><td/><td>Signed + predicted label</td><td>74.9</td></tr><tr><td/><td/><td/><td/><td/><td>Signed + predicted label + guidelines</td><td>74.9</td></tr><tr><td/><td/><td/><td/><td/><td>Signed + predicted label + guidelines + accuracy</td><td>78.9</td></tr><tr><td/><td/><td/><td/><td/><td>50</td><td>70</td><td>90</td></tr><tr><td/><td/><td/><td/><td/><td/><td>Trust (%)</td></tr></table>",
                "text": "Figure 27. Human trust on machine predictions in experiment 2. Differences between all pairs are not statistically significant. These results suggest that guidelines and accuracy statement do not increase human trust in machine learning models significantly.",
                "html": null,
                "type_str": "table"
            }
        }
    }
}