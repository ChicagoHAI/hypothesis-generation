{
    "paper_id": "2011",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2024-09-19T13:38:21.671600Z"
    },
    "title": "Automatic Detection of Machine Generated Text: A Critical Survey",
    "authors": [
        {
            "first": "Ganesh",
            "middle": [],
            "last": "Jawahar",
            "suffix": "",
            "affiliation": {},
            "email": "ganeshjwhr@gmail.com"
        },
        {
            "first": "Muhammad",
            "middle": [],
            "last": "Abdul-Mageed",
            "suffix": "",
            "affiliation": {},
            "email": "muhammad.mageed@ubc.ca"
        },
        {
            "first": "Laks",
            "middle": [
                "V S"
            ],
            "last": "Lakshmanan",
            "suffix": "",
            "affiliation": {},
            "email": ""
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Text generative models (TGMs) excel in producing text that matches the style of human language reasonably well. Such TGMs can be misused by adversaries, e.g., by automatically generating fake news and fake product reviews that can look authentic and fool humans. Detectors that can distinguish text generated by TGM from human written text play a vital role in mitigating such misuse of TGMs. Recently, there has been a flurry of works from both natural language processing (NLP) and machine learning (ML) communities to build accurate detectors for English. Despite the importance of this problem, there is currently no work that surveys this fast-growing literature and introduces newcomers to important research challenges. In this work, we fill this void by providing a critical survey and review of this literature to facilitate a comprehensive understanding of this problem. We conduct an in-depth error analysis of the state-of-the-art detector and discuss research directions to guide future work in this exciting area.",
    "pdf_parse": {
        "paper_id": "2011",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Text generative models (TGMs) excel in producing text that matches the style of human language reasonably well. Such TGMs can be misused by adversaries, e.g., by automatically generating fake news and fake product reviews that can look authentic and fool humans. Detectors that can distinguish text generated by TGM from human written text play a vital role in mitigating such misuse of TGMs. Recently, there has been a flurry of works from both natural language processing (NLP) and machine learning (ML) communities to build accurate detectors for English. Despite the importance of this problem, there is currently no work that surveys this fast-growing literature and introduces newcomers to important research challenges. In this work, we fill this void by providing a critical survey and review of this literature to facilitate a comprehensive understanding of this problem. We conduct an in-depth error analysis of the state-of-the-art detector and discuss research directions to guide future work in this exciting area.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Current state-of-the-art text generative models (TGMs) excel in producing text that approaches the style of human language, especially in terms of grammaticality, fluency, coherency, and usage of real world knowledge (Radford et al., 2019; Zellers et al., 2019; Keskar et al., 2019; Bakhtin et al., 2020; Brown et al., 2020) . TGMs are useful in a wide variety of applications, including story generation (Fan et al., 2018) , conversational response generation (Zhang et al., 2020) , code auto-completion (Solaiman et al., 2019) , and radiology report generation (Liu et al., 2019a) . However, TGMs can also be misused for fake news generation (Zellers et al., 2019; Brown et al., 2020; Uchendu et al., 2020) , fake product reviews generation (Adelani et al., 2020) , and spamming/phishing. (Weiss, 2019) . 1 Thus, it is important to build tools that can minimize the threats posed by the misuse of TGMs.",
                "cite_spans": [
                    {
                        "start": 217,
                        "end": 239,
                        "text": "(Radford et al., 2019;",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 240,
                        "end": 261,
                        "text": "Zellers et al., 2019;",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 262,
                        "end": 282,
                        "text": "Keskar et al., 2019;",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 283,
                        "end": 304,
                        "text": "Bakhtin et al., 2020;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 305,
                        "end": 324,
                        "text": "Brown et al., 2020)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 405,
                        "end": 423,
                        "text": "(Fan et al., 2018)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 461,
                        "end": 481,
                        "text": "(Zhang et al., 2020)",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 505,
                        "end": 528,
                        "text": "(Solaiman et al., 2019)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 563,
                        "end": 582,
                        "text": "(Liu et al., 2019a)",
                        "ref_id": null
                    },
                    {
                        "start": 644,
                        "end": 666,
                        "text": "(Zellers et al., 2019;",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 667,
                        "end": 686,
                        "text": "Brown et al., 2020;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 687,
                        "end": 708,
                        "text": "Uchendu et al., 2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 743,
                        "end": 765,
                        "text": "(Adelani et al., 2020)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 791,
                        "end": 804,
                        "text": "(Weiss, 2019)",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The commonly used approach to combat the threats posed by the misuse of TGMs is to formulate the problem of distinguishing text generated by TGMs and human written text as a classification task. The classifier, henceforth called detector, can be used to automatically remove machine generated text from online platforms such as social media, e-commerce, email clients, and government forums, when the intention of the TGM generated text is abuse. An ideal detector should be: (i) accurate, that is, good accuracy with a good trade-off for false positives and false negatives depending on the online platform (email client, social media) on which TGM is applied (Solaiman et al., 2019) ; (ii) data-efficient, that is, needs as few examples as possible from the TGM used by the attacker (Zellers et al., 2019) ; (iii) generalizable, that is, detects text generated by different modeling choices of the TGM used by the attacker such as model architecture, TGM training data, TGM conditioning prompt length, model size, and text decoding method (Solaiman et al., 2019; Bakhtin et al., 2020; Uchendu et al., 2020) ; and (iv) interpretable, that is, detector decisions need to be understandable to humans (Gehrmann et al., 2019) ; and (v) robust, that is, detector can handle adversarial examples (Wolff, 2020) . Given the importance of this problem, there has been a flurry of research recently from both NLP and ML communities on building useful detectors. However, there is currently no work that provides a literature review of existing detection works and highlight important research challenges.",
                "cite_spans": [
                    {
                        "start": 661,
                        "end": 684,
                        "text": "(Solaiman et al., 2019)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 785,
                        "end": 807,
                        "text": "(Zellers et al., 2019)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 1041,
                        "end": 1064,
                        "text": "(Solaiman et al., 2019;",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 1065,
                        "end": 1086,
                        "text": "Bakhtin et al., 2020;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 1087,
                        "end": 1108,
                        "text": "Uchendu et al., 2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 1199,
                        "end": 1222,
                        "text": "(Gehrmann et al., 2019)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 1291,
                        "end": 1304,
                        "text": "(Wolff, 2020)",
                        "ref_id": "BIBREF45"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "In this paper, we present a critical literature review of the existing detection research for English to aid understanding of this important area. We organize the survey to guide the reader seamlessly through a number of important aspects, as follows: First, we establish the background for the detection task, which includes TGMs, decoding methods for text generation, and social impacts of TGMs ( \u00a72). Second, we present various aspects of large-scale TGMs such as model architecture, training cost, and controllability ( \u00a73). Third, we present and discuss the various existing detectors in terms of their underlying methods ( \u00a74). Fourth, we provide a linguistically and computationally motivated analysis of key issues of the state-of-the-art detector ( \u00a75). Fifth, we discuss interesting future research directions that can help in building useful detectors ( \u00a76). Our main contributions are three-fold:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 We provide the first survey on the important, burgeoning area of detection of machine generated text from human written text.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 We develop an error analysis of current state-of-the-art detector, guided and illustrated by machine generated texts, to shed light on the limitations of existing detection work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "\u2022 Motivated by our analysis and existing challenges, we propose a rich and diverse set of research directions to guide future work in this exciting area.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Here, we provide the background for the problem of detecting machine generated text from human written text. Specifically, we introduce key concepts in training a TGM, generating text from a TGM, and social implications of using TGMs in practice. Existing detection datasets are discussed in Appendix.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Background",
                "sec_num": "2"
            },
            {
                "text": "TGM is typically a neural language model (NLM) trained to model the probability of a token given the previous tokens in a text sequence, i.e., p \u03b8 (x t |x 1 , . . . , x i , . . . , x t-1 ), with tokens coming from a vocabulary, x i \u2208 V. If x = (x 1 , . . . , x |x| ) represents the text sequence, p \u03b8 typically takes the form",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "p \u03b8 (x) = \u03a0 |x| t=1 p \u03b8 (x t |x 1 , . . . , x t-1",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "). If p * (x) denotes the reference distribution and D denotes a finite set of text sequences from p * , TGM estimates parameters \u03b8 by minimizing the following objective function:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "L(p \u03b8 , D) = - |D| j=1 |x (j) | t=1 log p \u03b8 (x (j) t |x (j) 1 , . . . , x (j) i , . . . , x (j)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "t-1 ).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "(1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "Notice that TGM can be a non-neural model (e.g., n-gram LM) and based on nontraditional LM objective (e.g., masked language modeling (Devlin et al., 2019; Song et al., 2019) ). In this survey, we focus primarily on TGMs for English that are neural and based on traditional LM objective, as they are successful in generating coherent paragraphs of English text.",
                "cite_spans": [
                    {
                        "start": 133,
                        "end": 154,
                        "text": "(Devlin et al., 2019;",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 155,
                        "end": 173,
                        "text": "Song et al., 2019)",
                        "ref_id": "BIBREF32"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training TGM",
                "sec_num": "2.1"
            },
            {
                "text": "Given a sub-sequence (prefix), x 1:k \u223c p * , the task of generating text from TGM is to use p \u03b8 to conditionally decode a continuation, xk+1:N \u223c p \u03b8 (.|x 1:k ) such that the resulting completion (x 1 , . . . , x k , xk+1 , . . . , xN ) resembles a sample from p * (Welleck et al., 2020) . In a news article generation task, the prefix can be headlines and the continuation can be the body of the news article. In a story generation task, the prefix can be beginning of a story and the continuation can be rest of the story. Since the computation of the optimal continuation (x k+1:N ) is not tractable with time complexity of O((N -k) (Holtzman et al., 2020) . Recently, Welleck et al., (2020) show that the degeneracy issues with beam search can be alleviated by training a TGM with the original TGM objective (Eq. ( 1)) augmented with an unlikelihood objective that assigns lower probabilities to unlikely generations. Stochastic methods: Stochastic decoding methods work by sampling from a model-dependent distribution at each time step, x t \u223c q(x t |x 1 , . . . , x t-1 , p \u03b8 ). In unrestricted sampling (also known as pure sampling), the chance of sampling a low-confidence token from the unreliable tail distribution is very high, leading to text that can be unrelated to prefix. To reduce the chance of sampling a lowconfidence token, sampling is limited to a subset of the vocabulary W \u2282 V at each time step. Let Z = x\u2208W p \u03b8 (x|x 1 , . . . , x t-1 ). If x t \u2208 W, q(x t |x 1 , . . . , x t-1 , p \u03b8 ) is set as p \u03b8 (x t |x 1 , . . . , x t-1 )/Z, otherwise set as 0. The two most effective stochastic decoding methods are top-k sampling (Fan et al., 2018) and top-p (or nucleus) sampling (Holtzman et al., 2020) . The top-k sampler limits sampling to the k most-probable tokens, that is, W is the size k subset of V that maximizes x\u2208W p \u03b8 (x|x 1 , . . . , x t-1 ).",
                "cite_spans": [
                    {
                        "start": 264,
                        "end": 286,
                        "text": "(Welleck et al., 2020)",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 635,
                        "end": 658,
                        "text": "(Holtzman et al., 2020)",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 671,
                        "end": 693,
                        "text": "Welleck et al., (2020)",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 1641,
                        "end": 1659,
                        "text": "(Fan et al., 2018)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 1692,
                        "end": 1715,
                        "text": "(Holtzman et al., 2020)",
                        "ref_id": "BIBREF18"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generating text from TGM",
                "sec_num": "2.2"
            },
            {
                "text": "The top-k sampler uses a constant value of k, which can be sub-optimal in different contexts, that is, generated text is limited to a subset of natural language distribution. For example, generic contexts (e.g., predicting noun) might require larger value of k, while other contexts (e.g., predicting prepositions) might require smaller value of k so that only useful candidate tokens are considered. The nucleus sampler overcomes the burden of considering only a fixed number of tokens by limiting sampling to the smallest set of tokens with total mass above a threshold p \u2208 [0, 1], i.e., W is the smallest subset with x\u2208W p \u03b8 (x|x 1 , . . . , x t-1 ) >= p. Thus, the number of candidate tokens considered varies dynamically depending on the context, and the resulting text is reasonably natural with less repetitions. Recently, Massarelli et al., (2020) show that top-k and top-p sampler tend to generate more nonfactual sentences, as corroborated by Wikipedia.",
                "cite_spans": [
                    {
                        "start": 830,
                        "end": 855,
                        "text": "Massarelli et al., (2020)",
                        "ref_id": "BIBREF24"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Generating text from TGM",
                "sec_num": "2.2"
            },
            {
                "text": "Bias: Unsurprisingly, a TGM can capture and amplify the societal biases (over-generalized beliefs about a particular group of people, e.g., Group X are bad drivers) present in the training data (Sun et al., 2019; Nadeem et al., 2020) . Solaiman et al., (2019) and Brown et al., (2020) show that TGMs reflect gender bias (e.g., favoring males over females), racial bias (e.g., favoring white over black people), and religious bias (e.g., favoring Christians over Muslims). Although TGMs can be used as a tool to study how patterns in the training data can translate to these unintended biases in the model outputs (Solaiman et al., 2019) , the biases can cause harm to the people in relevant groups in many ways (Crawford, 2017) . Beneficial usage: TGMs are used to create task-specific systems, such as question answering, reading comprehension, natural language inference, and machine translation (Radford et al., 2019; Brown et al., 2020) . TGMs can also be used to generate text that approximately matches the style of human language, which benefits applications such as story generation (Fan et al., 2018) , conversational response generation (Zhang et al., 2020) , code auto-completion (TabNine, 2020), and radiology report generation (Liu et al., 2019a) . Malicious usage: TGMs can have unfortunate uses by (even low-skilled) adversaries for malicious purposes, such as fake news generation (Zellers et al., 2019; Brown et al., 2020; Uchendu et al., 2020) , fake product reviews generation (Adelani et al., 2020) , and spamming/phishing (Weiss, 2019) . Humans can spot fake news articles (Brown et al., 2020) , fake product reviews (Adelani et al., 2020) , and fake comments (Weiss, 2019) generated by TGM only at chance level. To combat the threats posed by such adversaries, accurate models that can identify text generated by TGM from human written text need to be built. Such a model can have benevolent uses such as moderating content in vulnerable platforms including social media, email clients, government websites, and e-commerce websites. ",
                "cite_spans": [
                    {
                        "start": 194,
                        "end": 212,
                        "text": "(Sun et al., 2019;",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 213,
                        "end": 233,
                        "text": "Nadeem et al., 2020)",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 236,
                        "end": 263,
                        "text": "Solaiman et al., (2019) and",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 264,
                        "end": 284,
                        "text": "Brown et al., (2020)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 613,
                        "end": 636,
                        "text": "(Solaiman et al., 2019)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 711,
                        "end": 727,
                        "text": "(Crawford, 2017)",
                        "ref_id": null
                    },
                    {
                        "start": 898,
                        "end": 920,
                        "text": "(Radford et al., 2019;",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 921,
                        "end": 940,
                        "text": "Brown et al., 2020)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 1091,
                        "end": 1109,
                        "text": "(Fan et al., 2018)",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 1147,
                        "end": 1167,
                        "text": "(Zhang et al., 2020)",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 1240,
                        "end": 1259,
                        "text": "(Liu et al., 2019a)",
                        "ref_id": null
                    },
                    {
                        "start": 1397,
                        "end": 1419,
                        "text": "(Zellers et al., 2019;",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 1420,
                        "end": 1439,
                        "text": "Brown et al., 2020;",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 1440,
                        "end": 1461,
                        "text": "Uchendu et al., 2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 1496,
                        "end": 1518,
                        "text": "(Adelani et al., 2020)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 1543,
                        "end": 1556,
                        "text": "(Weiss, 2019)",
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 1594,
                        "end": 1614,
                        "text": "(Brown et al., 2020)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 1638,
                        "end": 1660,
                        "text": "(Adelani et al., 2020)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 1681,
                        "end": 1694,
                        "text": "(Weiss, 2019)",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Social impacts of TGMs",
                "sec_num": "2.3"
            },
            {
                "text": "In this section, we will discuss various aspects of large-scale TGMs. These TGMs act as threat models since they can be misused by a low-skilled adversary, e.g., by generating fake news and fake product reviews. Table 1 displays the summary of key characteristics of these TGMs along with the threats they pose (according to the original papers).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 218,
                        "end": 219,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Text generative models",
                "sec_num": "3"
            },
            {
                "text": "Model architecture: The model architecture underlying all the state-of-the-art TGMs is the transformer (Vaswani et al., 2017) . Compared to recurrent neural networks (RNNs) (Elman, 1990) , the transformer model does not have a bias to recent tokens and can learn long-range dependency information. The generation from TGMs such as GPT-2 which are based on transformer architecture tends to be grammatically correct, coherent, and uses world knowledge (Radford et al., 2019) . 2Training data: TGMs such as GPT-2, CTRL (Keskar et al., 2019) , and GPT-3 (Brown et al., 2020) have billions of parameters. They are generally trained using the language modeling objective on large amounts of raw text from a diverse set of sources (like Wikipedia, Reddit, and news sources). As an exception, GROVER (Zellers et al., 2019) is trained on millions of news article only. Such trained TGMs can also be fine-tuned on a domain-specific corpus for the LM task to generate text that matches the respective domain reasonably. For example, Adelani et al., (2020) fine-tune the GPT-2 model on the specific domain of product reviews to generate fake reviews, which mimics the style of a human review.",
                "cite_spans": [
                    {
                        "start": 103,
                        "end": 125,
                        "text": "(Vaswani et al., 2017)",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 173,
                        "end": 186,
                        "text": "(Elman, 1990)",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 451,
                        "end": 473,
                        "text": "(Radford et al., 2019)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 505,
                        "end": 538,
                        "text": "GPT-2, CTRL (Keskar et al., 2019)",
                        "ref_id": null
                    },
                    {
                        "start": 545,
                        "end": 571,
                        "text": "GPT-3 (Brown et al., 2020)",
                        "ref_id": null
                    },
                    {
                        "start": 793,
                        "end": 815,
                        "text": "(Zellers et al., 2019)",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model architecture, training data, training cost",
                "sec_num": "3.1"
            },
            {
                "text": "Training cost: Training TGMs with billions of parameters on millions of documents requires a huge computational budget (Zellers et al., 2019) , high energy cost (Strubell et al., 2019) , and long training time (Brown et al., 2020) . Unfortunately, it is not yet a standard practice to report financial (vs. energy vs. computational) budget in every research publication. This makes it hard for us to perform TGM training feasibility studies. One exception is the work done by Zellers et al., (2019) , where they explicitly mention that their proposed TGM model, GROVER, took two weeks of training with a cost of $25K (including the cost of data collection). We note that even though this may be an expensive budget, it is by no means outside the reach of even low-resource organizations, let alone nation states. The implication is that various entities of variable sizes and resource capabilities can practically deploy models for spreading disinformation using TGMs.",
                "cite_spans": [
                    {
                        "start": 119,
                        "end": 141,
                        "text": "(Zellers et al., 2019)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 161,
                        "end": 184,
                        "text": "(Strubell et al., 2019)",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 210,
                        "end": 230,
                        "text": "(Brown et al., 2020)",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 476,
                        "end": 498,
                        "text": "Zellers et al., (2019)",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model architecture, training data, training cost",
                "sec_num": "3.1"
            },
            {
                "text": "Controllable TGMs possess the ability to control the aspects of the generation such as topic and sentiment of the article. GPT-2 (Radford et al., 2019) and GPT-3 (Brown et al., 2020) assume the prefix to be any natural language text, which might be too coarse in controlling the generation in an explicit fashion.",
                "cite_spans": [
                    {
                        "start": 129,
                        "end": 151,
                        "text": "(Radford et al., 2019)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 156,
                        "end": 182,
                        "text": "GPT-3 (Brown et al., 2020)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Controllable generation",
                "sec_num": "3.2"
            },
            {
                "text": "Researchers have devised two ways to design a controllable TGM, which we now introduce.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Controllable generation",
                "sec_num": "3.2"
            },
            {
                "text": "Training with control tokens: The first way is to leverage meta-information about the article such as its author, date of creation, source domain and prepend this information as additional token(s) to the input sequence, before training the TGM. These tokens act as additional context for the article, allowing the TGM to learn the relation between the meta-information and the original article. Once trained, the TGM model can be controlled by prompting with the meta-information of users' interest. The first controllable TGM proposed is the GROVER model, which can generate a news article given the meta-information of the news article (such as headline, author, and date). The GROVER model can create trustworthy fake news that is harder for humans to identify than human written fake news and can thus pose a significant threat. Similar to the GROVER model, the CTRL model provides explicit control of particular aspects of the generated text by exploiting naturally occurring control codes (e.g., the URL for a news article) to condition the text (e.g., news article body). These control codes govern style (e.g., sports vs. politics, FOX sports vs. CNN sports), content (e.g., Wikipedia vs. books), and task-specific behavior (e.g., question answering vs. machine translation).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Controllable generation",
                "sec_num": "3.2"
            },
            {
                "text": "The second and the most recent way to design a controllable TGM is to combine a pretrained TGM like GPT-2 with one or more attribute classifiers (e.g., sentiment classifier) that guide text generation (Dathathri et al., 2020) . The attribute models measure the extent to which the desired attribute is encoded in a piece of text. At each timestep, GPT-2 updates its latent representations based on gradients from the attribute model for the text generated so far so as to increase the likelihood of the generated text having the desired attribute. The updated latents are used to compute a new next token distribution from which a token to be generated is sampled. The interesting property of this method is that the TGM model need not be retrained (unlike Adelani et al., (2020) work that need retraining of the GPT-2 model), thereby avoiding the significant cost of retraining.",
                "cite_spans": [
                    {
                        "start": 201,
                        "end": 225,
                        "text": "(Dathathri et al., 2020)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 749,
                        "end": 779,
                        "text": "(unlike Adelani et al., (2020)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Control using attribute classifier:",
                "sec_num": null
            },
            {
                "text": "In this section, we discuss various detectors for identifying machine generated text from human written text. To aid understanding of the literature, we organize the detectors according to the underlying methods on which they are based.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Detectors",
                "sec_num": "4"
            },
            {
                "text": "Bag-of-words classifier: Some detectors employ classical machine learning methods such as logistic regression to train a model from scratch to discriminate between text generated by TGM and human written text. Solaiman et al., (2019) use a simple baseline model that represents a document with tf-idf vector (unigrams and bigrams) on top of a logistic regression model to distinguish WebText articles (online web pages) from text generated using GPT-2 models. They study different sizes of GPT-2 models that vary in terms of number of parameters (117M, 345M, 762M, 1542M) and different sampling techniques (pure sampling, top-k sampling, and top-p sampling). They observe that generations from the larger GPT-2 models are difficult to detect compared to that of the smaller models, which indicates that the larger the TGM, the closer the style of the generated text with that of human written text. Top-k samples are easier to detect while nucleus samples are harder to detect. This result stems from the fact that top-k sampler typically over-generates common words, leaving statistical anomalies that are easily spotted by the detector (Ippolito et al., 2020) . Additionally, Solaiman et al., (2019) fine-tune the GPT-2 model on Amazon product reviews and show that the text generated by fine-tuned GPT-2 model is harder to detect as fine-tuned domain specific TGMs are more human-like than general purpose TGM (i.e., the original GPT-2 model).",
                "cite_spans": [
                    {
                        "start": 210,
                        "end": 233,
                        "text": "Solaiman et al., (2019)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 1138,
                        "end": 1161,
                        "text": "(Ippolito et al., 2020)",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1178,
                        "end": 1201,
                        "text": "Solaiman et al., (2019)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifiers trained from scratch",
                "sec_num": "4.1"
            },
            {
                "text": "Detecting machine configuration: Tay et al., (2020) study the extent to which different modeling choices (decoding method, TGM model size, prompt length) leave artifacts (detectable signatures that arise from modeling choices) in the generated text. They propose the task of identifying the TGM modeling choice given the text generated by TGM. They show that a classifier can be trained to predict the modeling choice well beyond the chance level, which ascertains that text generated by TGM may be more sensitive to TGM modeling choices than previously thought. They also find that the proposed detection task of identifying text generated by different TGM modeling choices is less harder than the task of identifying text generated by TGM from human written text along with different TGM modeling choices. They show that word order does not matter much as a bag-of-words detector performs very similar to detectors based on complex encoder (e.g., transformer). This result is consistent with the recent work done by Uchendu et al., (2020) , which shows that simple models (traditional ML models trained on psychological features and simple neural network architectures) perform well in three settings: (i) classify if two given articles are generated by the same TGM; (ii) classify if a given article is written by a human or a TGM (the original detection problem); (iii) identify the TGM that generated a given article (similar to Tay et al., (2020) ). For the original detection problem, the authors find that the text generated by the GPT-2 model to be hard to detect among several TGMs (see Appendix for the list of studied TGMs).",
                "cite_spans": [
                    {
                        "start": 33,
                        "end": 51,
                        "text": "Tay et al., (2020)",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 1018,
                        "end": 1040,
                        "text": "Uchendu et al., (2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 1434,
                        "end": 1452,
                        "text": "Tay et al., (2020)",
                        "ref_id": "BIBREF37"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Classifiers trained from scratch",
                "sec_num": "4.1"
            },
            {
                "text": "In the zero-shot classification setting, a pretrained TGM (for example, GPT-2, GROVER) is employed to detect generations from itself or similar models. The detector does not require supervised detection examples for further training (i.e., fine-tuning).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Zero-shot classifier",
                "sec_num": "4.2"
            },
            {
                "text": "Total log probability: Solaiman et al., (2019) present a baseline that uses TGM to evaluate total log probability, and thresholds based on this probability to make the prediction. For instance, text is predicted as machine generated if the overall likelihood of the text according to the GPT-2 model is closer to the mean likelihood over all machine generated texts than to the mean likelihood of human written texts. However, they find that this classifier performs poorly compared to the previously discussed logistic regression based classifier ( \u00a74.1).",
                "cite_spans": [
                    {
                        "start": 23,
                        "end": 46,
                        "text": "Solaiman et al., (2019)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Zero-shot classifier",
                "sec_num": "4.2"
            },
            {
                "text": "Giant Language model Test Room (GLTR) tool: The GLTR tool (Gehrmann et al., 2019) proposes a suite of baseline statistical methods that can highlight the distributional differences in text generated by GPT-2 model and human written text. Specifically, GLTR enables the study of a piece of text by visualizing per-token model probability, per-token rank in the predicted next token distribution, and entropy of the predicted next token distribution. Based on these visualizations, the tool clearly shows that TGMs over-generate from a limited subset of the true distribution of natural language. Indeed, rare word usage in text generated by GPT-2 model is markedly less compared to the human written text. The tool lets humans (including non-experts) to study a piece of text, but might be less effective in future once TGMs start generating text that lacks statistical anomalies.",
                "cite_spans": [
                    {
                        "start": 58,
                        "end": 81,
                        "text": "(Gehrmann et al., 2019)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Zero-shot classifier",
                "sec_num": "4.2"
            },
            {
                "text": "In this setup, a pretrained language model (e.g., BERT, RoBERTa (Liu et al., 2019b) ) is fine-tuned to detect text generated from itself or similar models. Unlike the zero-shot classification setup, the detector does require supervised detection examples for further training. GROVER detector: Zellers et al., (2019) propose a detector based on a linear classifier on top of GROVER model, which outperforms existing detectors (fastText (Bojanowski et al., 2017) and BERT (Devlin et al., 2019) ) and thereby conclude that the best models for generating neural disinformation are also the best at detecting their own generations. This result suggests the need to make generators such as GROVER and GPT-2 publicly available.3 Nevertheless, the authors do not experiment with BERT model to observe similar pattern that the BERT model also excels in detecting the text written by itself as the BERT detector and the BERT generator possess similar inductive bias. Uchendu et al., (2020) show that the off-the-shelf GROVER detector does not perform well in detecting text generated by TGMs other than the original GROVER model. The most interesting finding of this work is that fine-tuning using the RoBERTa model achieves higher accuracy than fine-tuning a GPT-2 model with equivalent capacity. This result might be due to the superior quality of the bidirectional representations inherent in the masked language modeling objective employed by the RoBERTa language model compared to the GPT-2 language model, which is limited by learning only unidirectional representation (left to right). This finding contradicts that of the GROVER work (Zellers et al., 2019) , where the authors conclude that the best models for detecting neural disinformation from a TGM is the TGM itself. Recently, Fagni et al., (2020) show that the RoBERTa detector establishes the state-of-the-art performance in spotting machine generated tweets from human written tweets accurately, outperforming both traditional ML models (e.g., bag-of-words) and complex neural network models (e.g., RNN, CNN) by a large margin. This interesting result indicates that the RoBERTa detector can generalize to publication sources unseen during its pretraining such as Twitter.",
                "cite_spans": [
                    {
                        "start": 64,
                        "end": 83,
                        "text": "(Liu et al., 2019b)",
                        "ref_id": null
                    },
                    {
                        "start": 294,
                        "end": 316,
                        "text": "Zellers et al., (2019)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 436,
                        "end": 461,
                        "text": "(Bojanowski et al., 2017)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 471,
                        "end": 492,
                        "text": "(Devlin et al., 2019)",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 958,
                        "end": 980,
                        "text": "Uchendu et al., (2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 1633,
                        "end": 1655,
                        "text": "(Zellers et al., 2019)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 1782,
                        "end": 1802,
                        "text": "Fagni et al., (2020)",
                        "ref_id": "BIBREF13"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Fine-tuning NLM",
                "sec_num": "4.3"
            },
            {
                "text": "The RoBERTa detector also outperforms existing detectors in spotting news articles generated by several TGMs (Uchendu et al., 2020) and product reviews generated by the GPT-2 model fine-tuned on Amazon product reviews (Adelani et al., 2020) .",
                "cite_spans": [
                    {
                        "start": 109,
                        "end": 131,
                        "text": "(Uchendu et al., 2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 218,
                        "end": 240,
                        "text": "(Adelani et al., 2020)",
                        "ref_id": "BIBREF0"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Fine-tuning NLM",
                "sec_num": "4.3"
            },
            {
                "text": "Apart from building a statistical model to detect online disinformation, one can build a system that can leverage human visual interpretation skills and common sense knowledge.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "Differences in human and machine detector: Ippolito et al., (2020) study the differences in the ability of humans and automated detectors to identify text generated by TGM. The authors observe: (i) human raters are good at noticing contradictions or semantic errors (e.g., incoherence) in text generated by TGM, which the automatic detectors are weak at, due to lack of deep semantic understanding; (ii) automatic detectors are good when text generated by TGM contains over-representation of high-likelihood words (caveat of top-k sampling as discussed in \u00a72.2), whereas the human raters are not good. Overall, automatic detectors are significantly better than human raters, but generalize poorly to text generated by unseen decoding methods.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "Supporting untrained humans: As seen before, the GLTR tool (Gehrmann et al., 2019) can aid humans by visualizing the properties of text such as unexpected and out-of-context words. The main advantage of GLTR is that it can facilitate untrained humans to accurately detect synthetic text (from 54% to 72% in terms of accuracy). However, GLTR flags machine generated easily but it is hard to be confident that the text is not machine generated. This result suggests the need for human-machine collaboration to solve the detection task (Solaiman et al., 2019) .",
                "cite_spans": [
                    {
                        "start": 59,
                        "end": 82,
                        "text": "(Gehrmann et al., 2019)",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 533,
                        "end": 556,
                        "text": "(Solaiman et al., 2019)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "Real or Fake Text (RoFT) tool: The RoFT tool (Dugan et al., 2020) focuses on evaluating human detection of text generated by TGM by asking humans to detect the sentence boundary at which the text transitions from human written text to machine generated text. The main assumption is that TGM successfully fools the human if the guess from the human is far from the true sentence boundary. Current TGMs can fool humans by one or two sentences. The core advantages of the RoFT tool include its engaging annotation interface, collection of user's explanation for their guess in free form text, and potential to scale to different textual domains as well as different TGM modeling choices. The main limitation of the tool is that the text shown to the humans can be rife with human generated sentences, and hence does not reflect an organic generation from a TGM.",
                "cite_spans": [
                    {
                        "start": 45,
                        "end": 65,
                        "text": "(Dugan et al., 2020)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "5 Issues with the state-of-the-art detector",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "In this section, we discuss open issues in the state-of-the-art detector based on the RoBERTa model, which has been shown to excel in detecting text generated by TGM based on news articles, product reviews, tweets, and web pages (see \u00a74.3). 4 We focus on the task of detecting text generated by the GPT-2 model from human written Amazon product reviews, a challenging task given the shortness of reviews. We employ the RoBERTa detector on the publicly available dataset, containing generations from the GPT-2 model (1542M parameters) based on pure, top-k and top-p sampling along with human written reviews (see Appendix for dataset details). In Figure 1 , we plot the accuracy of the detector w.r. Given that creation of large datasets for the detection task is hard (Zellers et al., 2019) , it is important to investigate whether the data-efficiency of the RoBERTa detector can be significantly improved. We manually inspect 100 randomly picked false positives (machine generated product review incorrectly predicted as human written product review) of the RoBERTa detector trained on 15K examples each from top-p generations and from human written reviews. 6 Below, we list down the error categories that we have identified and provide at least one example for each error category. Fluency: Among the false positive reviews, we find 73 reviews to be very fluent and can confuse even humans (1).",
                "cite_spans": [
                    {
                        "start": 768,
                        "end": 790,
                        "text": "(Zellers et al., 2019)",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 653,
                        "end": 654,
                        "text": "1",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(1) I loved this film. I can't really explain why, but when I first saw it it struck me as bizarre, almost oddball, but I quickly got over that and remembered that I love oddball films. This was an early 80's film. A great film to see on a gloomy rainy evening. This film is suspenseful and full of weirdness. Add this to your collection. Shortness: Out of these 73 identified fluent reviews, 27 reviews are very short, with a median of 24 words. We give two examples below:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(2) love it. best sweeper. (3) My favorite combo. Always works and usually cools my system to boot. So glad I got these instead of other brands. Factuality: We find 10 false positive reviews to contain factual errors.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(4) That movie got the stars and represents the best of this collection but there's better made Creature Movies as well including a 1960's remake of 'Dracula' with Kirk Douglas and Harrison Ford. (5) Just love Ben Affleck! He won't be missed in another very good movie. Worth watching especially if you like Ben! Review (4) on product 'Universal Studios Classic Monster Collection' contains the incorrect fact that Harrison Ford acted in 'Dracula' movie, and another review (5) on 'Runaway Jury' movie contains the incorrect fact that Ben Affleck acted in that movie. Spurious entities: In 4 false positive reviews, we find that the review contains novel entities unrelated to the domain of the product. For example, review (6) on 'Junkfood' musical product contains novel entity, 'grisberg', which is not associated with music domain.",
                "cite_spans": [
                    {
                        "start": 149,
                        "end": 199,
                        "text": "'Dracula' with Kirk Douglas and Harrison Ford. (5)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(6) another classic by grisberg, i love stevie she was one of the greatest r&b singers I know darwin halstead ment her so be a big fan please do yo self a favor and buy this dvd, its nice and it absolutly amazing this woman has a very yorfelt approch to r&b music Contradiction: We find one review (7) containing contradictions, where the subject (husband) is claimed to be not a big fan of a product but also as loving the same product.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(7) My husband likes his coffee black so he loves flavored coffee but is not a big fan of flavored coffee. ... Repetition: In two false positive reviews, the facts undergo repetition.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(8) Great movie, although took a while to see at first it held my interest and kept me interested, plus i thought it was extremly good. also it was very good. Common sense reasoning: We find one false positive review that describes an improbable event, that is, violates common sense reasoning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(9) ... I received both amazon Prime and a Walmart's for delivery and they both came on time. I love it and highly recommend it! The review (9) on a specific audio player product mentions that the user received the same product from two e-commerce companies simultaneously, which is most likely an improbable event. Typos and grammatical errors: There are 7 false positive reviews that possess typographical and grammatical errors (10) and (11). We note that such errors (especially spelling errors) are not unusual in online reviews, including those by humans.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(10) Once they are on they aren't wrinkled or lose they shape.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(11) Had to unplug thing to get the hard drive to work. Would rather have don batteries in the olden days.. Incoherence: There are 3 false positive reviews that seem incoherent. The movie review (12) switches the focus of the discourse between actors (Sophia and Duchovny) and story line in an incoherent fashion, which violates the theory of centering in discourse analysis (Grosz et al., 1995; Gehrmann et al., 2019) .",
                "cite_spans": [
                    {
                        "start": 375,
                        "end": 395,
                        "text": "(Grosz et al., 1995;",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 396,
                        "end": 418,
                        "text": "Gehrmann et al., 2019)",
                        "ref_id": "BIBREF15"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "(12) ... Sophia Loren plays 'Marion' a 'showgirl' that is picked on by the establishment for her wild style. ... Duchovny's character is also 'On the line' in the business world. ... The storyline is so intriguing and unpredictable. ... Sophia Loren's acting is just awesome and her wardrobe is just perfect! If you love sex and nud**y, you will be greatly pleased.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Human-machine collaboration",
                "sec_num": "4.4"
            },
            {
                "text": "In this section, we discuss a set of future research directions, which can help in building useful detectors.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Future Research Directions",
                "sec_num": "6"
            },
            {
                "text": "Existing detectors do not exploit auxiliary signals about the textual source.7 For example, the RoBERTa detector studied in \u00a75 ignores the auxiliary signals about the review (e.g., helpfulness) and the product (e.g., description). Such auxiliary signals can be complementary to linguistic signals from the textual source for the detection task (Hovy, 2016; Solaiman et al., 2019) . Given the rapidly evolving research in building intelligent TGMs that narrows the gap between machine and human distribution of natural language text, auxiliary signals could play a crucial role in mitigating the threats posed by TGMs.",
                "cite_spans": [
                    {
                        "start": 344,
                        "end": 356,
                        "text": "(Hovy, 2016;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 357,
                        "end": 379,
                        "text": "Solaiman et al., 2019)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Leveraging auxiliary signals",
                "sec_num": "6.1"
            },
            {
                "text": "Existing detectors have an assumption that the fake text is determined by the source (e.g., TGM) that generated the text. This assumption does not hold true in two practical scenarios: (i) real text autogenerated in a process similar to that of fake text, and (ii) adversaries creating fake text by modifying articles originating from legitimate human sources. Schuster et al., (2020) show that existing detectors perform poorly in these two scenarios as they rely too much on distributional features, which cannot help in distinguishing texts from similar sources. Hence, we call for more research on detectors that assess the veracity of machine generated text by consulting external sources, like knowledge bases (Thorne and Vlachos, 2018) and diffusion network (Vosoughi et al., 2018) , instead of relying only on the source.",
                "cite_spans": [
                    {
                        "start": 361,
                        "end": 384,
                        "text": "Schuster et al., (2020)",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 716,
                        "end": 742,
                        "text": "(Thorne and Vlachos, 2018)",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 765,
                        "end": 788,
                        "text": "(Vosoughi et al., 2018)",
                        "ref_id": "BIBREF41"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Assessing veracity of the text",
                "sec_num": "6.2"
            },
            {
                "text": "Existing detectors exhibit poor cross-domain accuracy, that is, they are not generalizable to different publication formats (Wikipedia, books, news sources) (Bakhtin et al., 2019) . Beyond publication formats and topics (e.g., politics, sports), the detector should also transfer to unseen TGM settings such as model architecture, different decoding methods (e.g., top-k, top-p), model size, different prefix lengths, and training data (Bakhtin et al., 2020; Uchendu et al., 2020) .",
                "cite_spans": [
                    {
                        "start": 157,
                        "end": 179,
                        "text": "(Bakhtin et al., 2019)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 436,
                        "end": 458,
                        "text": "(Bakhtin et al., 2020;",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 459,
                        "end": 480,
                        "text": "Uchendu et al., 2020)",
                        "ref_id": "BIBREF39"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Building generalizable detectors",
                "sec_num": "6.3"
            },
            {
                "text": "We discussed the importance of human raters pairing up with automatic detectors in \u00a74.4. A viable way for this collaboration is to make the decisions taken by the automatic detector interpretable (such as in GLTR) so that human raters can logically group (e.g., contradictions) the model decisions and humans can \"accept\", \"modify\", or \"reject\" these decisions. This calls for more research in building detectors that can provide explanations for its decisions, which are understandable to humans.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Building interpretable detectors",
                "sec_num": "6.4"
            },
            {
                "text": "Existing detectors are brittle, i.e., the detector decisions can vary significantly for even small changes in the text input. For example, Wolff (2020) shows that the RoBERTa detector can be attacked using simple schemes such as replacing characters with homoglyphs and misspelling some words. These two attacks reduce the detector's recall in text generated by TGM from 97.44% to 0.26% and 22.68% respectively. Therefore, it is important to study various adversarial attacks ranging from simple attacks (e.g., misspellings) to advanced attacks (e.g., universal attacks (Wallace et al., 2019) ) and create adversarial examples with an aim to characterize the vulnerabilities of the detector as well as to make the detector robust against various attacks.",
                "cite_spans": [
                    {
                        "start": 139,
                        "end": 151,
                        "text": "Wolff (2020)",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 570,
                        "end": 592,
                        "text": "(Wallace et al., 2019)",
                        "ref_id": "BIBREF42"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Building detectors robust to adversarial attacks",
                "sec_num": "6.5"
            },
            {
                "text": "Detectors able to tease apart machine generated text from human written text can play a vital role in mitigating misuse of TGMs such as in automatic creation of fake news and fake product reviews. Our categorization of existing detectors and related issues into classifiers trained from scratch, zero-shot classifiers, fine-tuning NLMs, and human-machine collaboration can help readers contextualize each detector w.r.t the fast-growing literature. We also hope that our computationally and linguistically motivated error analysis of the state-of-the-art detector can bring readers up to speed on many existing challenges in building useful detectors. Our rich and diverse set of research directions also have the potential to guide future work in this exciting area.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "7"
            },
            {
                "text": "Text generated by RNN can be more easily detected(Fagni et al., 2020), as such text is usually less grammatically correct and less coherent (based on our manual observations).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "The public release of TGM is a complex issue that warrants interdisciplinary considerations, including from policy and security groups. The authors of the GPT-2 model(Radford et al., 2018) initially kept their largest model private due to concerns about the potential for misuse. They released their largest model, eight months after publication of the article.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Concurrent with our work,Zhong et al., (2020) propose a detector that leverages factual and coherence structure underlying the text, which outperforms the RoBERTa detector in spotting machine generated text based on news articles and web pages. We also acknowledge that detectors fine-tuned on the state-of-the-art NLMs such as T5(Raffel et al., 2020), ELECTRA(Clark et al., 2020) might most likely outperform the RoBERTa detector in general.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Given that attackers can create synthetic text at scale using TGMs, 90% detection accuracy might not be a high accuracy.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "As seen in \u00a72.2 and \u00a74, top-p sampling produces good quality text that reasonably matches the style of human writing and is also harder to detect for humans. We leave the study of false negatives for future. Our annotation of 100 false positives can be accessed at: https://github.com/UBC-NLP/coling2020_machine_generated_text.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Concurrent with our work,Tan et al., (2020) propose a detector that spots machine generated news articles by utilizing news body, images, and captions associated with the news articles.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "We thank Ramya Rao Basava and Peter Sullivan for helpful discussions in the initial stage of the project. We gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada, Compute Canada (https://www.computecanada.ca), and UBC ARC-Sockeye (https://doi.org/10.14288/SOCKEYE).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgements",
                "sec_num": null
            },
            {
                "text": "Here, we will discuss existing detection datasets in the literature. Table 2 displays the statistics for all the detection datasets, which we will introduce now. WebText vs. GPT-2: The Generative Pre-trained Transformer 2 (GPT-2) model (Radford et al., 2019) is originally trained on WebText, a collection of online articles, sourced from high quality outbound links from Reddit. Solaiman et al., (2019) provide articles generated by GPT-2 based on pure, top-k, and top-p sampling methods. 8 Since online articles can come from different domains, this WebText dataset lets us study the generalizability of the detector with respect to the domain of the text. Amazon Product Reviews vs. GPT-2: Solaiman et al., (2019) finetuned the GPT-2 model on Amazon product reviews (Amazon, 2019) to make GPT-2 generate a product review that reasonably matches the style of Amazon product review. Similar to the WebText dataset, the authors provide reviews generated by GPT-2 based on pure, top-k, and top-p sampling methods. This review dataset makes the detection task challenging due to lack of context (reviews are short with a median of 115, 141 words for human and top-p machine reviews respectively). Tweets vs. Misc.: Social media platforms like Twitter has several bot user accounts, whose entire timeline is composed of tweets produced by models such as markov chain, RNN, LSTM (Hochreiter and Schmidhuber, 1997) , GPT-2, and several miscellaneous (unknown) models. Fagni et al., (2020) provide a collection of tweets from manually identified bot accounts and a collection of tweets from the humans imitated by the bot accounts. 10 This tweet dataset is challenging as the tweets are extremely short (median of 14, 16 words for human and machine tweets respectively). Unlike other datasets, this tweet dataset contains real machine generated texts posted in Twitter, which can directly measure the real world utility of the detector. Since these machine generated tweets encompass generations from different TGM models such as markov chain, LSTM, GPT-2 and miscellaneous models, this tweet dataset lets us study the generalizability of the detector with respect to the TGM that produced the text.GPT-3: The GPT-3 (Brown et al., 2020) model is trained on WebText, Wikipedia, Books and Common Crawl. The authors of the GPT-3 model provide generations of GPT-3 with top-p sampling. 11 Similar to the WebText dataset, this GPT-3 dataset lets us study the generalizability of the detector with respect to the domain of the text.Politics-News vs. Misc.: Uchendu et al., (2020) provide human written news articles related to politics category. Utilizing the title of the human written news article as prompt, the authors generate corresponding machine generated article from eight TGMs, which includes CTRL (Keskar et al., 2019) , GPT-1 (Radford et al., 2018) , GPT-2 (Radford et al., 2019) , GROVER (Zellers et al., 2019) , XLM (Conneau and Lample, 2019), XLNet (Yang et al., 2019) , PPLM (Dathathri et al., 2020) , and FAIR (Ng et al., 2019) . 12 Similar to the tweets dataset, this news dataset lets us study the generalizability of the detector with respect to the TGM that produced the text.",
                "cite_spans": [
                    {
                        "start": 236,
                        "end": 258,
                        "text": "(Radford et al., 2019)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 380,
                        "end": 403,
                        "text": "Solaiman et al., (2019)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 693,
                        "end": 716,
                        "text": "Solaiman et al., (2019)",
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 769,
                        "end": 783,
                        "text": "(Amazon, 2019)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 1375,
                        "end": 1409,
                        "text": "(Hochreiter and Schmidhuber, 1997)",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 1463,
                        "end": 1483,
                        "text": "Fagni et al., (2020)",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 2204,
                        "end": 2230,
                        "text": "GPT-3 (Brown et al., 2020)",
                        "ref_id": null
                    },
                    {
                        "start": 2545,
                        "end": 2567,
                        "text": "Uchendu et al., (2020)",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 2797,
                        "end": 2818,
                        "text": "(Keskar et al., 2019)",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 2827,
                        "end": 2849,
                        "text": "(Radford et al., 2018)",
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 2858,
                        "end": 2880,
                        "text": "(Radford et al., 2019)",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 2890,
                        "end": 2912,
                        "text": "(Zellers et al., 2019)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 2953,
                        "end": 2972,
                        "text": "(Yang et al., 2019)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 2980,
                        "end": 3004,
                        "text": "(Dathathri et al., 2020)",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 3016,
                        "end": 3033,
                        "text": "(Ng et al., 2019)",
                        "ref_id": "BIBREF26"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 75,
                        "end": 76,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Appendix -Existing detection datasets",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Humanand Machine-Based Detection",
                "authors": [
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Ifeoluwa Adelani",
                        "suffix": ""
                    },
                    {
                        "first": "Haotian",
                        "middle": [],
                        "last": "Mai",
                        "suffix": ""
                    },
                    {
                        "first": "Fuming",
                        "middle": [],
                        "last": "Fang",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Huy",
                        "suffix": ""
                    },
                    {
                        "first": "Junichi",
                        "middle": [],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "Isao",
                        "middle": [],
                        "last": "Yamagishi",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Echizen",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 34th International Conference on Advanced Information Networking and Applications",
                "volume": "2020",
                "issue": "",
                "pages": "1341--1354",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David Ifeoluwa Adelani, Haotian Mai, Fuming Fang, Huy H. Nguyen, Junichi Yamagishi, and Isao Echizen. 2020. Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human- and Machine-Based Detection. In Proceedings of the 34th International Conference on Advanced Information Networking and Applications, AINA-2020, volume 1151, pages 1341-1354.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Amazon Customer Reviews Dataset",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Amazon",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Amazon. 2019. Amazon Customer Reviews Dataset. https://s3.amazonaws.com/ amazon-reviews-pds/readme.html. Accessed on 09/05/2020.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Real or Fake? Learning to Discriminate Machine from Human Generated Text",
                "authors": [
                    {
                        "first": "Anton",
                        "middle": [],
                        "last": "Bakhtin",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Gross",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Yuntian",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Marc'aurelio",
                        "middle": [],
                        "last": "Ranzato",
                        "suffix": ""
                    },
                    {
                        "first": "Arthur",
                        "middle": [],
                        "last": "Szlam",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marc'Aurelio Ranzato, and Arthur Szlam. 2019. Real or Fake? Learning to Discriminate Machine from Human Generated Text. CoRR, abs/1906.03351.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Energy-Based Models for Text",
                "authors": [
                    {
                        "first": "Anton",
                        "middle": [],
                        "last": "Bakhtin",
                        "suffix": ""
                    },
                    {
                        "first": "Yuntian",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Gross",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Marc'aurelio",
                        "middle": [],
                        "last": "Ranzato",
                        "suffix": ""
                    },
                    {
                        "first": "Arthur",
                        "middle": [],
                        "last": "Szlam",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Anton Bakhtin, Yuntian Deng, Sam Gross, Myle Ott, Marc'Aurelio Ranzato, and Arthur Szlam. 2020. Energy- Based Models for Text. CoRR, abs/2004.10188.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Enriching Word Vectors with Subword Information",
                "authors": [
                    {
                        "first": "Piotr",
                        "middle": [],
                        "last": "Bojanowski",
                        "suffix": ""
                    },
                    {
                        "first": "Edouard",
                        "middle": [],
                        "last": "Grave",
                        "suffix": ""
                    },
                    {
                        "first": "Armand",
                        "middle": [],
                        "last": "Joulin",
                        "suffix": ""
                    },
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "135--146",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching Word Vectors with Subword Information. Transactions of the Association for Computational Linguistics, pages 135-146.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Language models are few-shot learners",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Tom",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Brown",
                        "suffix": ""
                    },
                    {
                        "first": "Nick",
                        "middle": [],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Melanie",
                        "middle": [],
                        "last": "Ryder",
                        "suffix": ""
                    },
                    {
                        "first": "Jared",
                        "middle": [],
                        "last": "Subbiah",
                        "suffix": ""
                    },
                    {
                        "first": "Prafulla",
                        "middle": [],
                        "last": "Kaplan",
                        "suffix": ""
                    },
                    {
                        "first": "Arvind",
                        "middle": [],
                        "last": "Dhariwal",
                        "suffix": ""
                    },
                    {
                        "first": "Pranav",
                        "middle": [],
                        "last": "Neelakantan",
                        "suffix": ""
                    },
                    {
                        "first": "Girish",
                        "middle": [],
                        "last": "Shyam",
                        "suffix": ""
                    },
                    {
                        "first": "Amanda",
                        "middle": [],
                        "last": "Sastry",
                        "suffix": ""
                    },
                    {
                        "first": "Sandhini",
                        "middle": [],
                        "last": "Askell",
                        "suffix": ""
                    },
                    {
                        "first": "Ariel",
                        "middle": [],
                        "last": "Agarwal",
                        "suffix": ""
                    },
                    {
                        "first": "Gretchen",
                        "middle": [],
                        "last": "Herbert-Voss",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Krueger",
                        "suffix": ""
                    },
                    {
                        "first": "Rewon",
                        "middle": [],
                        "last": "Henighan",
                        "suffix": ""
                    },
                    {
                        "first": "Aditya",
                        "middle": [],
                        "last": "Child",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [
                            "M"
                        ],
                        "last": "Ramesh",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Ziegler",
                        "suffix": ""
                    },
                    {
                        "first": "Clemens",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "Winter",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Hesse",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Mateusz",
                        "middle": [],
                        "last": "Sigler",
                        "suffix": ""
                    },
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Litwin",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Gray",
                        "suffix": ""
                    },
                    {
                        "first": "Jack",
                        "middle": [],
                        "last": "Chess",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "Clark",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Berner",
                        "suffix": ""
                    },
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Mccandlish",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Nee- lakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christo- pher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. CoRR, abs/2005.14165.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Electra: Pre-training text encoders as discriminators rather than generators",
                "authors": [
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Clark",
                        "suffix": ""
                    },
                    {
                        "first": "Minh-Thang",
                        "middle": [],
                        "last": "Luong",
                        "suffix": ""
                    },
                    {
                        "first": "Quoc",
                        "middle": [
                            "V"
                        ],
                        "last": "Le",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [
                            "D"
                        ],
                        "last": "Manning",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. 2020. Electra: Pre-training text encoders as discriminators rather than generators. In International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Cross-lingual Language Model Pretraining",
                "authors": [
                    {
                        "first": "Alexis",
                        "middle": [],
                        "last": "Conneau",
                        "suffix": ""
                    },
                    {
                        "first": "Guillaume",
                        "middle": [],
                        "last": "Lample",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "32",
                "issue": "",
                "pages": "7059--7069",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alexis Conneau and Guillaume Lample. 2019. Cross-lingual Language Model Pretraining. In Advances in Neural Information Processing Systems 32, pages 7059-7069.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "The trouble with bias",
                "authors": [],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kate Crawford. 2017. The trouble with bias. NIPS 2017 Keynote.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
                "authors": [
                    {
                        "first": "Sumanth",
                        "middle": [],
                        "last": "Dathathri",
                        "suffix": ""
                    },
                    {
                        "first": "Andrea",
                        "middle": [],
                        "last": "Madotto",
                        "suffix": ""
                    },
                    {
                        "first": "Janice",
                        "middle": [],
                        "last": "Lan",
                        "suffix": ""
                    },
                    {
                        "first": "Jane",
                        "middle": [],
                        "last": "Hung",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Frank",
                        "suffix": ""
                    },
                    {
                        "first": "Piero",
                        "middle": [],
                        "last": "Molino",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Yosinski",
                        "suffix": ""
                    },
                    {
                        "first": "Rosanne",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. 2020. Plug and Play Language Models: A Simple Approach to Controlled Text Generation. In International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
                "authors": [
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Devlin",
                        "suffix": ""
                    },
                    {
                        "first": "Ming-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Kenton",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Kristina",
                        "middle": [],
                        "last": "Toutanova",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference of the North American Chapter",
                "volume": "1",
                "issue": "",
                "pages": "4171--4186",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirec- tional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "RoFT: A Tool for Evaluating Human Detection of Machine-Generated Text",
                "authors": [
                    {
                        "first": "Liam",
                        "middle": [],
                        "last": "Dugan",
                        "suffix": ""
                    },
                    {
                        "first": "Daphne",
                        "middle": [],
                        "last": "Ippolito",
                        "suffix": ""
                    },
                    {
                        "first": "Arun",
                        "middle": [],
                        "last": "Kirubarajan",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Liam Dugan, Daphne Ippolito, Arun Kirubarajan, and Chris Callison-Burch. 2020. RoFT: A Tool for Evaluating Human Detection of Machine-Generated Text. CoRR, abs/2010.03070.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Finding structure in time",
                "authors": [
                    {
                        "first": "Jeffrey",
                        "middle": [
                            "L"
                        ],
                        "last": "Elman",
                        "suffix": ""
                    }
                ],
                "year": 1990,
                "venue": "Cognitive Science",
                "volume": "14",
                "issue": "2",
                "pages": "179--211",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jeffrey L. Elman. 1990. Finding structure in time. Cognitive Science, 14(2):179 -211.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "TweepFake: about Detecting Deepfake Tweets",
                "authors": [
                    {
                        "first": "Tiziano",
                        "middle": [],
                        "last": "Fagni",
                        "suffix": ""
                    },
                    {
                        "first": "Fabrizio",
                        "middle": [],
                        "last": "Falchi",
                        "suffix": ""
                    },
                    {
                        "first": "Margherita",
                        "middle": [],
                        "last": "Gambini",
                        "suffix": ""
                    },
                    {
                        "first": "Antonio",
                        "middle": [],
                        "last": "Martella",
                        "suffix": ""
                    },
                    {
                        "first": "Maurizio",
                        "middle": [],
                        "last": "Tesconi",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tiziano Fagni, Fabrizio Falchi, Margherita Gambini, Antonio Martella, and Maurizio Tesconi. 2020. TweepFake: about Detecting Deepfake Tweets. CoRR, abs/2008.00036.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Hierarchical Neural Story Generation",
                "authors": [
                    {
                        "first": "Angela",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Lewis",
                        "suffix": ""
                    },
                    {
                        "first": "Yann",
                        "middle": [],
                        "last": "Dauphin",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "889--898",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical Neural Story Generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889-898.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "GLTR: Statistical Detection and Visualization of Generated Text",
                "authors": [
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Gehrmann",
                        "suffix": ""
                    },
                    {
                        "first": "Hendrik",
                        "middle": [],
                        "last": "Strobelt",
                        "suffix": ""
                    },
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Rush",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
                "volume": "",
                "issue": "",
                "pages": "111--116",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sebastian Gehrmann, Hendrik Strobelt, and Alexander Rush. 2019. GLTR: Statistical Detection and Visualization of Generated Text. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 111-116.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Centering: A Framework for Modeling the Local Coherence of Discourse",
                "authors": [
                    {
                        "first": "Barbara",
                        "middle": [
                            "J"
                        ],
                        "last": "Grosz",
                        "suffix": ""
                    },
                    {
                        "first": "Aravind",
                        "middle": [
                            "K"
                        ],
                        "last": "Joshi",
                        "suffix": ""
                    },
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Weinstein",
                        "suffix": ""
                    }
                ],
                "year": 1995,
                "venue": "Computational Linguistics",
                "volume": "21",
                "issue": "2",
                "pages": "203--225",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A Framework for Modeling the Local Coherence of Discourse. Computational Linguistics, 21(2):203-225.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Long short-term memory",
                "authors": [
                    {
                        "first": "Sepp",
                        "middle": [],
                        "last": "Hochreiter",
                        "suffix": ""
                    },
                    {
                        "first": "J\u00fcrgen",
                        "middle": [],
                        "last": "Schmidhuber",
                        "suffix": ""
                    }
                ],
                "year": 1997,
                "venue": "Neural Comput",
                "volume": "9",
                "issue": "8",
                "pages": "1735--1780",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural Comput., 9(8):1735-1780.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "The Curious Case of Neural Text Degeneration",
                "authors": [
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Holtzman",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Buys",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Maxwell",
                        "middle": [],
                        "last": "Forbes",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The Curious Case of Neural Text Degeneration. In International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake Reviews -An Adversarial Study",
                "authors": [
                    {
                        "first": "Dirk",
                        "middle": [],
                        "last": "Hovy",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "volume": "2",
                "issue": "",
                "pages": "351--356",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dirk Hovy. 2016. The Enemy in Your Own Camp: How Well Can We Detect Statistically-Generated Fake Reviews -An Adversarial Study. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 351-356.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Automatic Detection of Generated Text is Easiest when Humans are Fooled",
                "authors": [
                    {
                        "first": "Daphne",
                        "middle": [],
                        "last": "Ippolito",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Duckworth",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Callison-Burch",
                        "suffix": ""
                    },
                    {
                        "first": "Douglas",
                        "middle": [],
                        "last": "Eck",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1808--1822",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch, and Douglas Eck. 2020. Automatic Detection of Gen- erated Text is Easiest when Humans are Fooled. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1808-1822.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation",
                "authors": [
                    {
                        "first": "Nitish",
                        "middle": [],
                        "last": "Shirish Keskar",
                        "suffix": ""
                    },
                    {
                        "first": "Bryan",
                        "middle": [],
                        "last": "Mccann",
                        "suffix": ""
                    },
                    {
                        "first": "Lav",
                        "middle": [
                            "R"
                        ],
                        "last": "Varshney",
                        "suffix": ""
                    },
                    {
                        "first": "Caiming",
                        "middle": [],
                        "last": "Xiong",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019. CTRL: A Conditional Transformer Language Model for Controllable Generation. CoRR, abs/1909.05858.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Clinically Accurate Chest X-Ray Report Generation",
                "authors": [
                    {
                        "first": "Guanxiong",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Tzu-Ming Harry",
                        "middle": [],
                        "last": "Hsu",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [
                            "A"
                        ],
                        "last": "Matthew",
                        "suffix": ""
                    },
                    {
                        "first": "Willie",
                        "middle": [],
                        "last": "Mcdermott",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Hung",
                        "middle": [],
                        "last": "Boag",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Weng",
                        "suffix": ""
                    },
                    {
                        "first": "Marzyeh",
                        "middle": [],
                        "last": "Szolovits",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Ghassemi",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the Machine Learning for Healthcare Conference",
                "volume": "106",
                "issue": "",
                "pages": "249--269",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Guanxiong Liu, Tzu-Ming Harry Hsu, Matthew B. A. McDermott, Willie Boag, Wei-Hung Weng, Peter Szolovits, and Marzyeh Ghassemi. 2019a. Clinically Accurate Chest X-Ray Report Generation. In Proceedings of the Machine Learning for Healthcare Conference, MLHC, volume 106, pages 249-269.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "A Robustly Optimized BERT Pretraining Approach",
                "authors": [
                    {
                        "first": "Yinhan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Naman",
                        "middle": [],
                        "last": "Goyal",
                        "suffix": ""
                    },
                    {
                        "first": "Jingfei",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Mandar",
                        "middle": [],
                        "last": "Joshi",
                        "suffix": ""
                    },
                    {
                        "first": "Danqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Omer",
                        "middle": [],
                        "last": "Levy",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Lewis",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    },
                    {
                        "first": "Veselin",
                        "middle": [],
                        "last": "Stoyanov",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b. RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR, abs/1907.11692.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "How Decoding Strategies Affect the Verifiability of Generated Text",
                "authors": [
                    {
                        "first": "Luca",
                        "middle": [],
                        "last": "Massarelli",
                        "suffix": ""
                    },
                    {
                        "first": "Fabio",
                        "middle": [],
                        "last": "Petroni",
                        "suffix": ""
                    },
                    {
                        "first": "Aleksandra",
                        "middle": [],
                        "last": "Piktus",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Rockt\u00e4schel",
                        "suffix": ""
                    },
                    {
                        "first": "Vassilis",
                        "middle": [],
                        "last": "Plachouras",
                        "suffix": ""
                    },
                    {
                        "first": "Fabrizio",
                        "middle": [],
                        "last": "Silvestri",
                        "suffix": ""
                    },
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Riedel",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rockt\u00e4schel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel. 2020. How Decoding Strategies Affect the Verifiability of Generated Text. CoRR, abs/1911.03587.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "StereoSet: Measuring stereotypical bias in pretrained language models",
                "authors": [
                    {
                        "first": "Moin",
                        "middle": [],
                        "last": "Nadeem",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Bethke",
                        "suffix": ""
                    },
                    {
                        "first": "Siva",
                        "middle": [],
                        "last": "Reddy",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Moin Nadeem, Anna Bethke, and Siva Reddy. 2020. StereoSet: Measuring stereotypical bias in pretrained lan- guage models. CoRR, abs/2004.09456.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Facebook FAIR's WMT19 news translation task submission",
                "authors": [
                    {
                        "first": "Nathan",
                        "middle": [],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "Kyra",
                        "middle": [],
                        "last": "Yee",
                        "suffix": ""
                    },
                    {
                        "first": "Alexei",
                        "middle": [],
                        "last": "Baevski",
                        "suffix": ""
                    },
                    {
                        "first": "Myle",
                        "middle": [],
                        "last": "Ott",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    },
                    {
                        "first": "Sergey",
                        "middle": [],
                        "last": "Edunov",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the Fourth Conference on Machine Translation",
                "volume": "2",
                "issue": "",
                "pages": "314--319",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, and Sergey Edunov. 2019. Facebook FAIR's WMT19 news translation task submission. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1), pages 314-319.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Improving Language Understanding by Generative Pre-Training",
                "authors": [
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Karthik",
                        "middle": [],
                        "last": "Narasimhan",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Tim Salimans, and Ilya Sutskever",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving Language Understand- ing by Generative Pre-Training. https://s3-us-west-2.amazonaws.com/openai-assets/ research-covers/language-unsupervised/language_understanding_paper.pdf.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Language Models are Unsupervised Multitask Learners",
                "authors": [
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Rewon",
                        "middle": [],
                        "last": "Child",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Luan",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Lan- guage Models are Unsupervised Multitask Learners. https://d4mucfpksywv.cloudfront. net/better-language-models/language_models_are_unsupervised_multitask_ learners.pdf.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "authors": [
                    {
                        "first": "Colin",
                        "middle": [],
                        "last": "Raffel",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Shazeer",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Roberts",
                        "suffix": ""
                    },
                    {
                        "first": "Katherine",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "Sharan",
                        "middle": [],
                        "last": "Narang",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Matena",
                        "suffix": ""
                    },
                    {
                        "first": "Yanqi",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [
                            "J"
                        ],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Journal of Machine Learning Research",
                "volume": "21",
                "issue": "140",
                "pages": "1--67",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News",
                "authors": [
                    {
                        "first": "Tal",
                        "middle": [],
                        "last": "Schuster",
                        "suffix": ""
                    },
                    {
                        "first": "Roei",
                        "middle": [],
                        "last": "Schuster",
                        "suffix": ""
                    },
                    {
                        "first": "Darsh",
                        "middle": [
                            "J"
                        ],
                        "last": "Shah",
                        "suffix": ""
                    },
                    {
                        "first": "Regina",
                        "middle": [],
                        "last": "Barzilay",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tal Schuster, Roei Schuster, Darsh J. Shah, and Regina Barzilay. 2020. The Limitations of Stylometry for Detect- ing Machine-Generated Fake News. Computational Linguistics.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Release Strategies and the Social Impacts of Language Models",
                "authors": [
                    {
                        "first": "Irene",
                        "middle": [],
                        "last": "Solaiman",
                        "suffix": ""
                    },
                    {
                        "first": "Miles",
                        "middle": [],
                        "last": "Brundage",
                        "suffix": ""
                    },
                    {
                        "first": "Jack",
                        "middle": [],
                        "last": "Clark",
                        "suffix": ""
                    },
                    {
                        "first": "Amanda",
                        "middle": [],
                        "last": "Askell",
                        "suffix": ""
                    },
                    {
                        "first": "Ariel",
                        "middle": [],
                        "last": "Herbert-Voss",
                        "suffix": ""
                    },
                    {
                        "first": "Jeff",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Jasmine",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, and Jasmine Wang. 2019. Release Strategies and the Social Impacts of Language Models. CoRR, abs/1908.09203.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation",
                "authors": [
                    {
                        "first": "Kaitao",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Xu",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Tie-Yan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "International Conference on Machine Learning",
                "volume": "",
                "issue": "",
                "pages": "5926--5936",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. MASS: Masked Sequence to Sequence Pre-training for Language Generation. In International Conference on Machine Learning, pages 5926-5936.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Energy and Policy Considerations for Deep Learning in NLP",
                "authors": [
                    {
                        "first": "Emma",
                        "middle": [],
                        "last": "Strubell",
                        "suffix": ""
                    },
                    {
                        "first": "Ananya",
                        "middle": [],
                        "last": "Ganesh",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Mccallum",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "3645--3650",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and Policy Considerations for Deep Learning in NLP. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3645-3650.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review",
                "authors": [
                    {
                        "first": "Tony",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Gaut",
                        "suffix": ""
                    },
                    {
                        "first": "Shirlyn",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxin",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Mai",
                        "middle": [],
                        "last": "Elsherief",
                        "suffix": ""
                    },
                    {
                        "first": "Jieyu",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Diba",
                        "middle": [],
                        "last": "Mirza",
                        "suffix": ""
                    },
                    {
                        "first": "Elizabeth",
                        "middle": [],
                        "last": "Belding",
                        "suffix": ""
                    },
                    {
                        "first": "Kai-Wei",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Wang",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "1630--1640",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, and William Yang Wang. 2019. Mitigating Gender Bias in Natural Language Processing: Literature Review. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1630-1640.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "TabNine. Autocompletion with deep learning",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Tabnine",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "TabNine. 2020. TabNine. Autocompletion with deep learning. https://tabnine.com/blog/deep. Ac- cessed on 04/22/2020.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News",
                "authors": [
                    {
                        "first": "Reuben",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "Bryan",
                        "middle": [
                            "A"
                        ],
                        "last": "Plummer",
                        "suffix": ""
                    },
                    {
                        "first": "Kate",
                        "middle": [],
                        "last": "Saenko",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Reuben Tan, Bryan A. Plummer, and Kate Saenko. 2020. Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News. CoRR, abs/2009.07698.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Reverse Engineering Configurations of Neural Text Generation Models",
                "authors": [
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Tay",
                        "suffix": ""
                    },
                    {
                        "first": "Dara",
                        "middle": [],
                        "last": "Bahri",
                        "suffix": ""
                    },
                    {
                        "first": "Che",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Clifford",
                        "middle": [],
                        "last": "Brunk",
                        "suffix": ""
                    },
                    {
                        "first": "Donald",
                        "middle": [],
                        "last": "Metzler",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Tomkins",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "275--279",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yi Tay, Dara Bahri, Che Zheng, Clifford Brunk, Donald Metzler, and Andrew Tomkins. 2020. Reverse Engi- neering Configurations of Neural Text Generation Models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 275-279.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Automated Fact Checking: Task Formulations, Methods and Future Directions",
                "authors": [
                    {
                        "first": "James",
                        "middle": [],
                        "last": "Thorne",
                        "suffix": ""
                    },
                    {
                        "first": "Andreas",
                        "middle": [],
                        "last": "Vlachos",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Proceedings of the 27th International Conference on Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "3346--3359",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "James Thorne and Andreas Vlachos. 2018. Automated Fact Checking: Task Formulations, Methods and Future Directions. In Proceedings of the 27th International Conference on Computational Linguistics, pages 3346- 3359.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Authorship Attribution for Neural Text Generation",
                "authors": [
                    {
                        "first": "Adaku",
                        "middle": [],
                        "last": "Uchendu",
                        "suffix": ""
                    },
                    {
                        "first": "Thai",
                        "middle": [],
                        "last": "Le",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Shu",
                        "suffix": ""
                    },
                    {
                        "first": "Dongwon",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adaku Uchendu, Thai Le, Kai Shu, and Dongwon Lee. 2020. Authorship Attribution for Neural Text Generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Attention is All you Need",
                "authors": [
                    {
                        "first": "Ashish",
                        "middle": [],
                        "last": "Vaswani",
                        "suffix": ""
                    },
                    {
                        "first": "Noam",
                        "middle": [],
                        "last": "Shazeer",
                        "suffix": ""
                    },
                    {
                        "first": "Niki",
                        "middle": [],
                        "last": "Parmar",
                        "suffix": ""
                    },
                    {
                        "first": "Jakob",
                        "middle": [],
                        "last": "Uszkoreit",
                        "suffix": ""
                    },
                    {
                        "first": "Llion",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Aidan",
                        "middle": [
                            "N"
                        ],
                        "last": "Gomez",
                        "suffix": ""
                    },
                    {
                        "first": "Lukasz",
                        "middle": [],
                        "last": "Kaiser",
                        "suffix": ""
                    },
                    {
                        "first": "Illia",
                        "middle": [],
                        "last": "Polosukhin",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "6000--6010",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems, pages 6000-6010.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "The spread of true and false news online",
                "authors": [
                    {
                        "first": "Soroush",
                        "middle": [],
                        "last": "Vosoughi",
                        "suffix": ""
                    },
                    {
                        "first": "Deb",
                        "middle": [],
                        "last": "Roy",
                        "suffix": ""
                    },
                    {
                        "first": "Sinan",
                        "middle": [],
                        "last": "Aral",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "Science",
                "volume": "359",
                "issue": "6380",
                "pages": "1146--1151",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science, 359(6380):1146-1151.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP",
                "authors": [
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Wallace",
                        "suffix": ""
                    },
                    {
                        "first": "Shi",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Nikhil",
                        "middle": [],
                        "last": "Kandpal",
                        "suffix": ""
                    },
                    {
                        "first": "Matt",
                        "middle": [],
                        "last": "Gardner",
                        "suffix": ""
                    },
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2153--2162",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019. Universal Adversarial Triggers for Attacking and Analyzing NLP. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2153- 2162.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Deepfake Bot Submissions to Federal Public Comment Websites Cannot Be Distinguished from Human Submissions",
                "authors": [
                    {
                        "first": "Max",
                        "middle": [],
                        "last": "Weiss",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Technology Science",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Max Weiss. 2019. Deepfake Bot Submissions to Federal Public Comment Websites Cannot Be Distinguished from Human Submissions. In Technology Science.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "Neural Text Generation With Unlikelihood Training",
                "authors": [
                    {
                        "first": "Sean",
                        "middle": [],
                        "last": "Welleck",
                        "suffix": ""
                    },
                    {
                        "first": "Ilia",
                        "middle": [],
                        "last": "Kulikov",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [],
                        "last": "Roller",
                        "suffix": ""
                    },
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Dinan",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Weston",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, and Jason Weston. 2020. Neural Text Generation With Unlikelihood Training. In International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Attacking Neural Text Detectors",
                "authors": [
                    {
                        "first": "Max",
                        "middle": [],
                        "last": "Wolff",
                        "suffix": ""
                    }
                ],
                "year": 2002,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Max Wolff. 2020. Attacking Neural Text Detectors. CoRR, abs/2002.11768.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "XL-Net: Generalized Autoregressive Pretraining for Language Understanding",
                "authors": [
                    {
                        "first": "Zhilin",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Zihang",
                        "middle": [],
                        "last": "Dai",
                        "suffix": ""
                    },
                    {
                        "first": "Yiming",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Jaime",
                        "middle": [],
                        "last": "Carbonell",
                        "suffix": ""
                    },
                    {
                        "first": "Russ",
                        "middle": [
                            "R"
                        ],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    },
                    {
                        "first": "Quoc V",
                        "middle": [],
                        "last": "Le",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "32",
                "issue": "",
                "pages": "5753--5763",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. XL- Net: Generalized Autoregressive Pretraining for Language Understanding. In Advances in Neural Information Processing Systems 32, pages 5753-5763.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Defending Against Neural Fake News",
                "authors": [
                    {
                        "first": "Rowan",
                        "middle": [],
                        "last": "Zellers",
                        "suffix": ""
                    },
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Holtzman",
                        "suffix": ""
                    },
                    {
                        "first": "Hannah",
                        "middle": [],
                        "last": "Rashkin",
                        "suffix": ""
                    },
                    {
                        "first": "Yonatan",
                        "middle": [],
                        "last": "Bisk",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "Farhadi",
                        "suffix": ""
                    },
                    {
                        "first": "Franziska",
                        "middle": [],
                        "last": "Roesner",
                        "suffix": ""
                    },
                    {
                        "first": "Yejin",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "9054--9065",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. 2019. Defending Against Neural Fake News. In Advances in Neural Information Processing Systems, pages 9054-9065.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation",
                "authors": [
                    {
                        "first": "Yizhe",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Siqi",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Michel",
                        "middle": [],
                        "last": "Galley",
                        "suffix": ""
                    },
                    {
                        "first": "Yen-Chun",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Brockett",
                        "suffix": ""
                    },
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Jingjing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Dolan",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
                "volume": "",
                "issue": "",
                "pages": "270--278",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020. DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Gen- eration. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270-278.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Neural Deepfake Detection with Factual Structure of Text",
                "authors": [
                    {
                        "first": "Wanjun",
                        "middle": [],
                        "last": "Zhong",
                        "suffix": ""
                    },
                    {
                        "first": "Duyu",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Zenan",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Ruize",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Nan",
                        "middle": [],
                        "last": "Duan",
                        "suffix": ""
                    },
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Jiahai",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Jian",
                        "middle": [],
                        "last": "Yin",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Wanjun Zhong, Duyu Tang, Zenan Xu, Ruize Wang, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. 2020. Neural Deepfake Detection with Factual Structure of Text. CoRR, abs/2010.07475.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "uris": null,
                "fig_num": null,
                "text": "RoBERTa detector:Solaiman et al., (2019) experiment with fine-tuning the RoBERTa language model for the detection task and establishes the state-of-the-art performance in identifying the web pages generated by the largest GPT-2 model with \u223c95% accuracy. The RoBERTa detector trained on top-p examples transfers well to examples from all the other decoding methods (pure and top-k). Regardless of the detector model's capacity, the detector performs well when trained on examples from the larger GPT-2 model and transfers well to examples generated by a smaller GPT-2 model. On the other hand, training on smaller GPT-2 model's outputs results in poor performance in classifying the larger GPT-2 model's outputs.",
                "type_str": "figure",
                "num": null
            },
            "FIGREF1": {
                "uris": null,
                "fig_num": "1",
                "text": "Figure 1: Detection accuracy of the RoBERTa detector w.r.t. number of training examples per class, averaged over ten random initializations.",
                "type_str": "figure",
                "num": null
            },
            "TABREF0": {
                "text": "set of partially decoded sequences, called hypotheses. At each time step, beam search creates new hypotheses by appending each token in the vocabulary to each existing hypothesis, scoring the resulting sequences using p * with time complexity of O((N -k)b|V|). In practice, these deterministic decoding methods depend highly on the underlying model probabilities and suffer from producing degenerate continuation, i.e., generic text often with repetitive tokens",
                "content": "<table/>",
                "type_str": "table",
                "html": null,
                "num": null
            },
            "TABREF1": {
                "text": "Summary of the characteristics of TGMs that can act as threat models. The last column corresponds to the threats discussed in the original paper.",
                "content": "<table><tr><td>TGM</td><td>training text sequence (x)</td><td>prefix (x 1:k )</td><td colspan=\"2\">continuation</td><td>decoding</td><td>threats</td></tr><tr><td/><td>(data size / params)</td><td/><td>(x k+1:N )</td><td/><td>method</td><td>discussed</td></tr><tr><td>GPT-2</td><td>fragments from WebText</td><td>starting of an article</td><td colspan=\"2\">rest of the article</td><td>top-k</td><td>NA</td></tr><tr><td>(Radford et</td><td>(collection of internet arti-</td><td>(e.g., few lines about</td><td colspan=\"2\">(e.g., rest of the re-</td><td/><td/></tr><tr><td>al., 2019)</td><td>cles) (40GB / 1.5B)</td><td>a research finding)</td><td colspan=\"2\">search finding)</td><td/><td/></tr><tr><td>GROVER</td><td>news article along with their</td><td>meta-</td><td>missing</td><td>meta-</td><td>top-p</td><td>trustworthy</td></tr><tr><td>(Zellers et</td><td>meta-information from Re-</td><td>information/body</td><td colspan=\"2\">information/body</td><td/><td>fake news</td></tr><tr><td>al., 2019)</td><td>alNews (120GB / 1.5B)</td><td>of a news article (e.g.,</td><td>in the prefix</td><td/><td/><td/></tr><tr><td/><td/><td>headline, author)</td><td/><td/><td/><td/></tr><tr><td>CTRL</td><td>control code (e.g., URL)</td><td>control code (e.g.,</td><td colspan=\"2\">article correspond-</td><td>greedy</td><td>NA</td></tr><tr><td>(Keskar et</td><td>followed by text (e.g., news</td><td>URL) with optionally</td><td colspan=\"2\">ing to the control</td><td>search with</td><td/></tr><tr><td>al., 2019)</td><td>article) from several do-</td><td>some strings of text</td><td>code</td><td/><td>repetition</td><td/></tr><tr><td/><td>mains (140GB / 1.6B)</td><td/><td/><td/><td>penalty</td><td/></tr><tr><td>Adelani et</td><td>product reviews (fine-tuning</td><td>product review (hu-</td><td>product</td><td>review</td><td>top-k</td><td>fake prod.</td></tr><tr><td>al., (2020)</td><td>GPT-2) (20GB / 0.1B)</td><td>man written)</td><td>(machine)</td><td/><td/><td>reviews</td></tr><tr><td>Dathathri et</td><td>no training and no fine-</td><td>beginning of a story</td><td colspan=\"2\">rest of the story or</td><td>top-k</td><td>NA</td></tr><tr><td>al., (2020)</td><td>tuning</td><td>or general articles</td><td>article</td><td/><td/><td/></tr><tr><td>GPT-3</td><td>fragments from Common-</td><td>three previous news</td><td colspan=\"2\">body of the pro-</td><td>top-p</td><td>fake news</td></tr><tr><td>(Brown et</td><td>Crawl (570GB / 175B)</td><td>articles and title of a</td><td colspan=\"2\">posed article</td><td/><td/></tr><tr><td>al., 2020)</td><td/><td>proposed article</td><td/><td/><td/><td/></tr></table>",
                "type_str": "table",
                "html": null,
                "num": null
            },
            "TABREF2": {
                "text": "t. number of training examples per class, averaged over ten random initializations to control for initialization effects. We observe that the RoBERTa detector needs several thousands of examples to reach high accuracy. Specifically, it has an impractical requirement of 200K, 15K and 50K training examples for performing at 90% accuracy on identifying pure, top-k and top-p examples respectively. 5",
                "content": "<table/>",
                "type_str": "table",
                "html": null,
                "num": null
            }
        }
    }
}